{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer SOMA - part 2\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component #2: SOMA  in order to understand interactome \n",
    "\n",
    "To measure shape, position, and size of the cell body -- the soma.    There are a variety of signals from which we could make this inference.  The two most promising are a composite signal including the residual from linear unmixing (`ch = [1, 4, 5,7]`) and a signal derived from the lysosome channel (`ch = 1`).\n",
    "\n",
    "Dependencies:\n",
    "The CYTOSOL inference rely on the NUCLEI AND SOMA inference.  Therefore all of the sub-cellular objects rely on this segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be organzied to explain the imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "# function for core algorithm\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, hole_filling\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters, img_as_float\n",
    "from skimage import morphology\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "# # package for io \n",
    "# from aicsimageio import AICSImage\n",
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "#import .infer_subc_2d.base\n",
    "from infer_subc_2d.base import *\n",
    "\n",
    "viewer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "# IMAGE PROCESSING Objective 2:  infer SOMA\n",
    "  [OUTLINE: Objective #2](#summary-of-objectives)\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel  1@4.0 ,5@1.0,7@1.0  (1,4,5, and 7:  6/28 pipeline)\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  scale to max 1.0\n",
    "- gaussian  Filter window 10  (gauss 10 -> median 5 : 6/28 pipeline)\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - watershed from NU, adaptive threshold, minimum cross-entropy\n",
    "  - threshold smoothing scale: 1 pixel\n",
    "  - threshold correction factor: .9 (more lenient)\n",
    "  - lower / upper bounds  (0.0000267,.2)\n",
    "  - 200 adaptive window\n",
    "  - log transformed thresholding\n",
    "  - fill holes\n",
    "    - NO discard objects on borde\n",
    "    \n",
    "\n",
    "- POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- mask of SOMA\n",
    "- mask of NU (contained by SOMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = Path( f\"{os.getenv('HOME')}/Projects/Imaging/mcz_subcell/data\")\n",
    "czi_img_folder = data_path/\"raw\"\n",
    "\n",
    "list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "\n",
    "img_file_list = list_img_files(czi_img_folder,'.czi')\n",
    "print(img_file_list[5])\n",
    "\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "img_data, meta_dict = read_input_image(test_img_name)\n",
    "\n",
    "raw_meta_data, ome_types = get_raw_meta_data(meta_dict)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n",
    "NU_labels = label(NU_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Segmentation on a 3 channel composite as per 3/20 pipeline from MCZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median filtering scale is ~ : [0.5804527163320905, 0.3194866073934927, 0.3194866073934927]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_data[1,:,:,:].copy() + \n",
    "                               1. * img_data[5,:,:,:].copy() + \n",
    "                               1. * img_data[7,:,:,:].copy() )\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "\n",
    "med_filter_size = 15  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "#\n",
    "struct_img = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                struct_img,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "log_image, d = log_transform( structure_img_smooth ) \n",
    "log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "\n",
    "edges = filters.scharr(log_image)\n",
    "\n",
    "composite_soma = intensity_normalization(  edges,  scaling_param=[0] ) + log_image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "    \n",
    "# # no mask\n",
    "# image_data = np.where(mask, image, np.nan)\n",
    "# image_data = np.where(mask, image, 0)\n",
    "\n",
    "\n",
    "\n",
    "#structure_img_smooth = raw_gaussian_filter2D\n",
    "# this is closer to the original \n",
    "bw, _bw_low_level = MO(composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive_window = 200\n",
    "# if adaptive_window % 2 == 0:\n",
    "#     adaptive_window += 1\n",
    "# local_threshold = filters.threshold_sauvola(\n",
    "#     log_image, window_size=adaptive_window\n",
    "# )\n",
    "\n",
    "\n",
    "# # this implimentation doesn't seem to be working despite the fact that I've borrowed from \n",
    "\n",
    "# image_data = log_image\n",
    "# volumetric = True\n",
    " \n",
    "# tolerance=max(np.min(np.diff(np.unique(image_data))) / 2, 0.5 / 65536)\n",
    "# tolerance=np.min(np.diff(np.unique(image_data))) / 2\n",
    "# tolerance = None\n",
    "# #th_method = \"Li\" #skimage.filters.threshold_li,\n",
    "# window_size = 200\n",
    "# th_method=filters.threshold_li\n",
    "    \n",
    "# local_threshold = cp_adaptive_threshold( image_data,\n",
    "#                                                                     th_method, #skimage.filters.threshold_li,\n",
    "#                                                                     volumetric,\n",
    "#                                                                     window_size, \n",
    "#                                                                     tolerance\n",
    "#                                                             )\n",
    "\n",
    "# threshold_correction_factor = 0.9\n",
    "# threshold_global = filters.threshold_li(image_data)\n",
    "# corrected_threshold = local_threshold.copy()*threshold_correction_factor\n",
    "\n",
    "# thresh_min, thresh_max = 0.0000267,.2\n",
    "\n",
    "\n",
    "# # Constrain the local threshold to be within [0.7, 1.5] * global_threshold. It's for the pretty common case\n",
    "# # where you have regions of the image with no cells whatsoever that are as large as whatever window you're\n",
    "# # using. Without a lower bound, you start having crazy threshold s that detect noise blobs. And same for\n",
    "# # very crowded areas where there is zero background in the window. You want the foreground to be all\n",
    "# # detected.\n",
    "# t_min = max(thresh_min, threshold_global * 0.7)\n",
    "# t_max = min(thresh_max, threshold_global * 1.5)\n",
    "\n",
    "# corrected_threshold[corrected_threshold < t_min] = t_min\n",
    "# corrected_threshold[corrected_threshold > t_max] = t_max\n",
    "\n",
    "\n",
    "# bw_adapt = image_data >= corrected_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " remove hole size  ~ : 6.3897321478698546 microns, scale:(0.5804527163320905, 0.07987165184837318, 0.07987165184837318)\n",
      " remove small objects  size  ~ : 3.594224333176793 microns, scale:(0.5804527163320905, 0.07987165184837318, 0.07987165184837318)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "width = 80  \n",
    "# discount z direction\n",
    "#segmented_soma = remove_small_objects(bw, min_size=width*width*1.5, connectivity=1, in_place=False)\n",
    "#removed_holes = morphology.remove_small_holes(bw, width ** 3 )\n",
    "\n",
    "#removed_holes = aicssegmentation.core.utils.hole_filling(bw_adapt, hole_min =0. , hole_max=width**2, fill_2d = True) \n",
    "removed_holes = aicssegmentation.core.utils.hole_filling(bw, hole_min =0. , hole_max=width**2, fill_2d = True) \n",
    "\n",
    "print(f\" remove hole size  ~ : { scale[1]*width} microns, scale:{scale}\")\n",
    "\n",
    "width = 45  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"slice_by_slice\" ,\n",
    "                                                         connectivity=1)\n",
    "print(f\" remove small objects  size  ~ : { scale[1]*width} microns, scale:{scale}\")\n",
    "\n",
    "#sobel_image = np.abs(ndi.sobel(struct_img))\n",
    "# watershed on the sobel limited by the mask\n",
    "# labels_out = watershed(\n",
    "#         image=np.abs(ndi.sobel(structure_img_composite)),\n",
    "#         markers=NU_labels,\n",
    "#         connectivity=np.ones((3, 3, 3), bool),\n",
    "#         mask=cleaned_img,\n",
    "#     )\n",
    "\n",
    "watershed_mask = np.logical_or(cleaned_img, NU_labels > 0)\n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=inverted_img,\n",
    "            markers=NU_labels,\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n",
    "\n",
    "# labels_out2 = watershed(\n",
    "#         image=filters.scharr(composite_soma),\n",
    "#         markers=NU_labels,\n",
    "#         connectivity=np.ones((3, 3, 3), bool),\n",
    "#         mask=cleaned_img,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viewer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#contour_img = [aicssegmentation.core.output_utils.generate_segmentation_contour(labels_out==l) for l in np.unique(labels_out)]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# def generate_segmentation_contour(im):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#     \"\"\"generate the contour of the segmentation\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#     bd = bd.astype(np.uint8)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#     bd[bd > 0] = 255\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m viewer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'viewer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#contour_img = [aicssegmentation.core.output_utils.generate_segmentation_contour(labels_out==l) for l in np.unique(labels_out)]\n",
    "# def generate_segmentation_contour(im):\n",
    "#     \"\"\"generate the contour of the segmentation\"\"\"\n",
    "\n",
    "#     bd = np.logical_xor(erosion(im > 0, selem=ball(1)), im > 0)\n",
    "\n",
    "#     bd = bd.astype(np.uint8)\n",
    "#     bd[bd > 0] = 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out [1]' at 0x1488dc430>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# viewer.add_image(\n",
    "#     struct_img,\n",
    "#     scale=scale \n",
    "# )\n",
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "#  viewer.add_labels(\n",
    "#     contour_img,\n",
    "#     scale=scale \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_SOMA1` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "\n",
    "def infer_SOMA1(struct_img, NU_labels,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "\n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    med_filter_size = 15   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    struct_img, d = log_transform( struct_img ) \n",
    "    struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "\n",
    "    struct_img += filters.scharr(struct_img) \n",
    "    struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.5\n",
    "\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    #                   # # this is not actually applied for this workflow,,,,\n",
    "    #                    # threshold_correction_factor = 0.9\n",
    "    #                    # thresh_min, thresh_max = 0.0000267,.2\n",
    "    #                    \n",
    "    #                    # threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "    #                    # out_p['threshold_factor'] = threshold_factor\n",
    "    #                    # out_p['thresh_min'] = thresh_min\n",
    "    #                    # out_p['thresh_max'] = thresh_max\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= width**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "\n",
    "    labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=1. - struct_img,\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  labels_out, out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "['SO_object']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_data[1,:,:,:].copy() + \n",
    "                               1. * img_data[5,:,:,:].copy() + \n",
    "                               1. * img_data[7,:,:,:].copy() )\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "struct_img = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA1(struct_img.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SO_object']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'SO_label' at 0x183763ac0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    SO_object,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #2\n",
    "\n",
    "Segmentation on a 4 channel composite as per 6/22 CellProfiler pipeline from MCZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian filtering width (2D) is ~ : 0.6389732147869854 microns, scale:(0.5804527163320905, 0.07987165184837318, 0.07987165184837318)\n",
      "gaussian filtering width (3d) is ~ : [1.1008187175429014, 8.0, 8.0] pixels; :[0.6389732147869854, 0.6389732147869854, 0.6389732147869854] microns\n",
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "#composite_channels = [1,2,3,4] # andy's best guess but maybe need to scale channel 1 (lysosomes) mega\n",
    "#composite_channels = range(img_data.shape[0]-1)\n",
    "composite_channels\n",
    "\n",
    "\n",
    "\n",
    "gaussian_smoothing_sigma = 8\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "gaussian_smoothing_sigma_3D = [gaussian_smoothing_sigma*scale[2]/x  for x in scale]\n",
    "\n",
    "\n",
    "print(f\"gaussian filtering width (2D) is ~ : { scale[1]*gaussian_smoothing_sigma} microns, scale:{scale}\")\n",
    "print(f\"gaussian filtering width (3d) is ~ : {gaussian_smoothing_sigma_3D} pixels; :{[x*y for x,y in zip(scale,gaussian_smoothing_sigma_3D)]} microns\")\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(img_data[1,:,:,:]) #  [0.0, 8]\n",
    "#truncate_intensity = raw_soma.mean()+raw_soma.std()*3\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "raw_soma_linear = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n",
    "\n",
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "struct_img = raw_soma_linear.copy()\n",
    "# non-linear scaling for the aggregate tested below\n",
    "# # scale_parameters = [[0.0, 24.5],\n",
    "# #                                     [0.0, 35.0],\n",
    "# #                                     [0.5, 15.0],\n",
    "# #                                     [1.5, 10.0]]\n",
    "# # hold_it = []\n",
    "\n",
    "# smooth1 = aicssegmentation.core.pre_processing_utils.edge_preserving_smoothing_3d(\n",
    "#                                     struct_img,\n",
    "#                                     numberOfIterations = 10,\n",
    "#                                     conductance = 1.2,\n",
    "#                                     timeStep = 0.0625,\n",
    "#                                     spacing= list(scale) )\n",
    "\n",
    "\n",
    "# smoothing with gaussian filter\n",
    "# 3D alternative: image_smoothing_gaussian_3d(...)\n",
    "gaussian_smoothing_sigma = 3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "med_filter_size = 9\n",
    "#structure_img_median = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "\n",
    "structure_img_median = median_filter_slice_by_slice( \n",
    "                                                                struct_img,\n",
    "                                                                size=med_filter_size )\n",
    "\n",
    "# log_image, d = log_transform( sc_median ) \n",
    "# log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   structure_img_median,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "edges = filters.scharr(struct_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'NU_labels' at 0x17c88cfd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(scale)\n",
    "\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    NU_labels,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 0.022594163479725156\n",
      "the standard deviation of intensity of the stack: 0.035176025031434015\n",
      "0.9999 percentile of the stack intensity is: 0.562098829807297\n",
      "minimum intensity of the stack: 6.00946325238002e-09\n",
      "maximum intensity of the stack: 1.0\n",
      "suggested upper range is 15.5, which is 0.5678225514669525\n",
      "suggested lower range is 0.5, which is 0.0050061509640081485\n",
      "So, suggested parameter for normalization is [0.5, 15.5]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "mean intensity of the stack: 0.02121846708738522\n",
      "the standard deviation of intensity of the stack: 0.03109671695313\n",
      "0.9999 percentile of the stack intensity is: 0.49197553144795597\n",
      "minimum intensity of the stack: 0.005571961371672658\n",
      "maximum intensity of the stack: 0.7053786193844717\n",
      "suggested upper range is 15.5, which is 0.5032175798609002\n",
      "suggested lower range is 0.5, which is 0.005670108610820219\n",
      "So, suggested parameter for normalization is [0.5, 15.5]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "mean intensity of the stack: 0.021218103928360828\n",
      "the standard deviation of intensity of the stack: 0.03191390281334251\n",
      "0.9999 percentile of the stack intensity is: 0.5208109846958499\n",
      "minimum intensity of the stack: 0.005015915674606106\n",
      "maximum intensity of the stack: 0.7679201869925036\n",
      "suggested upper range is 16.0, which is 0.5318405489418411\n",
      "suggested lower range is 0.5, which is 0.005261152521689572\n",
      "So, suggested parameter for normalization is [0.5, 16.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ##########################################################################\n",
    "# PARAMETERS:\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img) #  [0.5, 12.5]\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(structure_img_smooth) # [0.5, 9.0]\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(structure_img_median) # [0.5, 9.0]\n",
    "# [0.0, 23.5]\n",
    "\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "intensity_norm_param = [0]\n",
    "gaussian_smoothing_sigma = 5\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "#structure_img_smooth = raw_gaussian_filter2D\n",
    "# this is closer to the original \n",
    "bw, _bw_low_level = MO(structure_img_smooth, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.25, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "width = 5  \n",
    "# discount z direction\n",
    "#segmented_soma = remove_small_objects(bw, min_size=width*width*1.5, connectivity=1, in_place=False)\n",
    "removed_holes = morphology.remove_small_holes(bw, width ** 3 )\n",
    "\n",
    "width = 6  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**3, \n",
    "                                                         method = \"3D\", #\"slice_by_slice\" \n",
    "                                                         connectivity=1)\n",
    "\n",
    "#sobel_image = np.abs(ndi.sobel(struct_img))\n",
    "# watershed on the sobel limited by the mask\n",
    "\n",
    "\n",
    "labels_out = watershed(\n",
    "        image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "        markers=NU_labels,\n",
    "        connectivity=np.ones((3, 3, 3), bool),\n",
    "        mask=cleaned_img,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out [1]' at 0x193b5beb0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels_out = watershed(\n",
    "        image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "        markers=NU_labels,\n",
    "        connectivity=np.ones((3, 3, 3), bool),\n",
    "        mask=cleaned_img,\n",
    "    )\n",
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    cleaned_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_SOMA2` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "\n",
    "def infer_SOMA2(struct_img, NU_labels,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.25\n",
    "\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= width**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  labels_out, out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "['SO_object']\n",
      "['SO_label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "#struct_img = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA2(raw_soma_linear.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object2'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "# test: does this export work?\n",
    "object_name = 'SO_label2'\n",
    "SO_label_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #3\n",
    "\n",
    "Segmentation on the log-scaled Lysosome signal and aggressively filling holes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n",
      "WARNING: In /Users/svc-dashboard/D/P/ITKPythonPackage/ITK-source/ITK/Modules/Filtering/AnisotropicSmoothing/include/itkAnisotropicDiffusionImageFilter.hxx, line 77\n",
      "GradientAnisotropicDiffusionImageFilter (0x7faf991960e0): Anisotropic diffusion unstable time step: 0.0625\n",
      "Stable time step for this image must be smaller than 0.00499198\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'istruct_img_smooth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m struct_img_smooth \u001b[39m=\u001b[39m aicssegmentation\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mpre_processing_utils\u001b[39m.\u001b[39medge_preserving_smoothing_3d(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                     struct_img_raw,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                     numberOfIterations \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                     conductance \u001b[39m=\u001b[39m \u001b[39m1.2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                                     timeStep \u001b[39m=\u001b[39m \u001b[39m0.0625\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                     spacing\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scale) )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# resulted in some negative pixels\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/02_infer_soma.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m struct_img_smooth \u001b[39m=\u001b[39m intensity_normalization(  istruct_img_smooth, scaling_param\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m] )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'istruct_img_smooth' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1]\n",
    "\n",
    "struct_img_raw = intensity_normalization(  img_data[1,:,:,:].copy(), scaling_param=[0] )\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "# PRE=PROCESSING\n",
    "#####################\n",
    "# struct_img_smooth = aicssegmentation.core.pre_processing_utils.edge_preserving_smoothing_3d(\n",
    "#                                     struct_img_raw,\n",
    "#                                     numberOfIterations = 10,\n",
    "#                                     conductance = 1.2,\n",
    "#                                     timeStep = 0.0625,\n",
    "#                                     spacing= list(scale) )\n",
    "# # resulted in some negative pixels\n",
    "#struct_img_smooth = intensity_normalization(  struct_img_smooth, scaling_param=[0] )\n",
    "struct_img_smooth = struct_img_raw\n",
    "med_filter_size = 3   \n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img_smooth2 = median_filter_slice_by_slice( \n",
    "                                                                struct_img_smooth,\n",
    "                                                                size=med_filter_size  )\n",
    "out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "struct_img_smooth3 = image_smoothing_gaussian_slice_by_slice(   struct_img_smooth2,\n",
    "                                                                                                    sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                    truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                )\n",
    "out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "\n",
    "log_image, d = log_transform( struct_img_smooth2 ) \n",
    "\n",
    "composite_img = intensity_normalization( log_image + filters.scharr(log_image),  scaling_param=[0] )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "local_adjust = 0.5\n",
    "\n",
    "struct_obj, _bw_low_level = MO(log_image, \n",
    "                                            global_thresh_method='ave', \n",
    "                                            object_minArea=low_level_min_size, \n",
    "                                            extra_criteria=True,\n",
    "                                            local_adjust= local_adjust, \n",
    "                                            return_object=True,\n",
    "                                            dilate=True)\n",
    "\n",
    "out_p[\"local_adjust\"] = local_adjust \n",
    "\n",
    "# # this is not actually applied for this workflow,,,,\n",
    "# threshold_correction_factor = 0.9\n",
    "# thresh_min, thresh_max = 0.0000267,.2\n",
    "\n",
    "# threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "# out_p['threshold_factor'] = threshold_factor\n",
    "# out_p['thresh_min'] = thresh_min\n",
    "# out_p['thresh_max'] = thresh_max\n",
    "\n",
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "hole_max = 100  \n",
    "# discount z direction\n",
    "struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "out_p['hole_max'] = hole_max\n",
    "\n",
    "small_object_max = 55\n",
    "struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                        min_size= width**3, \n",
    "                                                        method = \"slice_by_slice\" ,\n",
    "                                                        connectivity=1)\n",
    "out_p['small_object_max'] = small_object_max\n",
    "\n",
    "\n",
    "# labels_out = watershed(\n",
    "#             connectivity=np.ones((3, 3,3), bool),\n",
    "#             image=1. - log_image,\n",
    "#             markers=NU_labels,\n",
    "#             mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "#             )\n",
    "# labels_out1 = watershed(\n",
    "#             connectivity=np.ones((3, 3,3), bool),\n",
    "#             image=np.abs(filters.scharr(log_image)),\n",
    "#             markers=NU_labels,\n",
    "#             mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "#             )\n",
    "labels_out1b = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=np.abs(filters.sobel(log_image)),\n",
    "            markers=NU_labels,\n",
    "            mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "            )\n",
    "\n",
    "# labels_out2 = watershed(\n",
    "#             connectivity=np.ones((3, 3,3), bool),\n",
    "#             image=composite_img,\n",
    "#             markers=NU_labels,\n",
    "#             mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "#             )\n",
    "\n",
    "\n",
    "\n",
    "# labels_out3 = watershed(\n",
    "#             connectivity=np.ones((3, 3,3), bool),\n",
    "#             image=log_image,\n",
    "#             markers=NU_labels,\n",
    "#             mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "#             )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out1b [1]' at 0x18ef4b4f0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    composite_img,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    struct_obj,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    log_image,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "# viewer.add_labels(\n",
    "#     labels_out,\n",
    "#     scale=scale\n",
    "# )\n",
    "# viewer.add_labels(\n",
    "#     labels_out1,\n",
    "#     scale=scale\n",
    "# )\n",
    "# viewer.add_labels(\n",
    "#     labels_out2,\n",
    "#     scale=scale\n",
    "# )\n",
    "viewer.add_labels(\n",
    "    labels_out1b,\n",
    "    scale=scale\n",
    ")\n",
    "# viewer.add_labels(\n",
    "#     labels_out3,\n",
    "#     scale=scale\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_SOMA3` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_SOMA3(struct_img, NU_labels,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    struct_img, d = log_transform( struct_img ) \n",
    "    struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "\n",
    "    struct_img += filters.scharr(struct_img) \n",
    "    struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.5\n",
    "\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    hole_max = 100  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 55\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= width**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  labels_out, out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SO_object']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    }
   ],
   "source": [
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "#struct_img = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA3(raw_soma_linear.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object3'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST POST-PROCESSING\n",
    "\n",
    "Find the label with the brightest florescence..\n",
    "\n",
    "Keep the Nuclei with that label.  \n",
    "Mask all the other nuclei.\n",
    "\n",
    "re-label the soma with watershed using the single.\n",
    "\n",
    "\n",
    "also try:\n",
    "    find the center of mass of each nuclei.  Use those as seeds for the soma...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# keep the \"SOMA\" which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_flourescence = [ struct_img[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_flourescence)]\n",
    "keep_label, total_flourescence\n",
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        composite_soma,\n",
    "        scale=scale,\n",
    "        blending='additive',\n",
    "        colormap='magenta',\n",
    "    )\n",
    "\n",
    "else:\n",
    "    viewer.add_image(\n",
    "        composite_soma,\n",
    "        scale=scale \n",
    "    )\n",
    "\n",
    "viewer.add_image(\n",
    "    log_image,\n",
    "    scale=scale \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
