{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***soma*** -  1Ô∏è‚É£ \n",
    "(üö®üö®üö®üö® Steps 2-9 depend on establishing a good solution here.)\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: ‚úÖ Infer sub-cellular component soma in order to understand interactome \n",
    "\n",
    ">> WARNING:  THIS DOES NOT WORK WELL\n",
    "\n",
    "To measure shape, position, and size of the cell body -- the soma.    There are a variety of signals from which we could make this inference.  The two most promising are a composite signal including the residual from linear unmixing (e.g. `ch = [1, 4, 5,7]`) and a signal derived from the lysosome channel (`ch = 1`).    In all procdures scaling the intensities to find the lower florescence signals at the edge of the soma against baseline is employed.  \n",
    "\n",
    "In the long term we can build of a database of \"ground truth\" by sourcing additional markers which can be iteratively improved.  For example using the Allen Cell \"Label Free\" segmentation results should provide a good corroboration or constraints to the procedures outlined below.  \n",
    "\n",
    "A first possible _workflow_ is illustrated below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_czi_image,\n",
    "                                                                    read_input_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray)\n",
    "\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROXI_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LIPID_CH ,\n",
    "                                                                    RESIDUAL_CH )                                                                    \n",
    "from infer_subc_2d.utils.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING  OBJECTIVE :  infer ***soma***\n",
    " \n",
    "> #### Note:  we are using the Nuclei of the brightest cell to aid in inferring the Soma and Cytosol objects.   Because we do NOT have a direct cell membrane / soma signal this is the trickiest and potentially problematic part of the overall sub-cellular component inference.   The Soma (via the Cytosol mask) will be used to define ALL subsequent sub-cellular Objects.\n",
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default parameters, including  \"optimal\" Z\n",
    "\n",
    "takes ~ 4 seconds to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ch_to_agg = ( LYSO_CH ,\n",
    "                        MITO_CH ,\n",
    "                        GOLGI_CH ,\n",
    "                        PEROXI_CH ,\n",
    "                        ER_CH ,\n",
    "                        LIPID_CH )\n",
    "                            \n",
    "nuc_ch = NUC_CH\n",
    "optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred nuclei object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "\n",
    "# raw_nuclei = img_2D[0].copy()\n",
    "# NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING PROTOTYPE, Objective 2:  infer ***soma***\n",
    "\n",
    ">WORKFLOW #1  - modified MCZ 3/20\n",
    "\n",
    "Segmentation on a 3 channel composite as per 3/20 pipeline from MCZ\n",
    "Summary - Starting with a linear combination of three signals,  the signal is smoothed and non-linearly combined (logrithmic and edge detected) for thresholding. \n",
    "## summary of steps\n",
    "\n",
    "‚û°Ô∏è INPUT\n",
    "- multi-channel sum (4*1,5,7)\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "- ne-noise and somoothe\n",
    "- log transform inensities\n",
    "- scale to max 1.0\n",
    "- create non-linear aggregate of log-intensity + scharr filtered \n",
    "\n",
    "CORE PROCESSING\n",
    "- mask object segmentation at bottom\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT ‚û°Ô∏è \n",
    "- mask of SOMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_2D[LYSO_CH].copy() + \n",
    "                               1. * img_2D[ER_CH].copy() + \n",
    "                               1. * img_2D[RESIDUAL_CH].copy() )\n",
    "\n",
    "\n",
    "nuc_img_raw = img_2D[NUC_CH].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _raw_soma_MCZ(img_in):\n",
    "    \"\"\" define soma image\n",
    "    \"\"\"\n",
    "    SOMA_W = (4.,1.,1.)\n",
    "    SOMA_CH = (LYSO_CH,ER_CH,RESIDUAL_CH) #LYSO, ER, RESIDUAL\n",
    "    img_out = np.zeros_like(img_in[0]).astype(np.double)\n",
    "    for w,ch in zip(SOMA_W,SOMA_CH):\n",
    "        img_out += w*img_in[ch]\n",
    "    return img_out\n",
    "\n",
    "_struct_img_raw = _raw_soma_MCZ(img_2D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "#\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "med_filter_size = 15  \n",
    "\n",
    "\n",
    "################# part 1\n",
    "raw_soma_linear = min_max_intensity_normalization(struct_img_raw.copy())\n",
    "\n",
    "struct_img = median_filter_slice_by_slice(raw_soma_linear, size=med_filter_size)\n",
    "\n",
    "\n",
    "structure_img_smooth = ndi.gaussian_filter( struct_img,\n",
    "                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                mode=\"nearest\", \n",
    "                                                                                truncate=gaussian_smoothing_truncate_range,\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "# NON-Linear aggregation\n",
    "log_image, d = log_transform( structure_img_smooth ) \n",
    "log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "edges = filters.scharr(log_image)\n",
    "\n",
    "composite_soma = intensity_normalization(  edges,  scaling_param=[0] ) + log_image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _non_linear_soma_transform_MCZ(in_img):\n",
    "    \"\"\" non-linear distortion to fill out soma\n",
    "    log + edge of smoothed composite\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # non-Linear processing\n",
    "    log_img, d = log_transform( in_img.copy() ) \n",
    "    log_img = min_max_intensity_normalization(  log_img )\n",
    "    return min_max_intensity_normalization(  filters.scharr(log_img) )  + log_img\n",
    "\n",
    "_composite_soma = _non_linear_soma_transform_MCZ(structure_img_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################# part 2 Nuclei pre=process\n",
    "nuc_img_raw = img_2D[0].copy() \n",
    "# median filter in 2D / convert to float 0-1.   get rid of the \"residual\"\n",
    "nuclei = min_max_intensity_normalization(nuc_img_raw)\n",
    "\n",
    "med_filter_size = 4   \n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "nuclei = median_filter_slice_by_slice( \n",
    "                                                                nuclei,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "gaussian_smoothing_sigma = 1.34\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "                                                                                            sigma=gaussian_smoothing_sigma,\n",
    "                                                                                            truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                            )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "low_level_min_size =  100\n",
    "\n",
    "################# part 1\n",
    "\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n",
    "\n",
    "################# part 2 : nuclei thresholding\n",
    "#struct_obj = struct_img > filters.threshold_li(struct_img)\n",
    "threshold_factor = 0.9 #from cellProfiler\n",
    "thresh_min = .1\n",
    "thresh_max = 1.\n",
    "NU_object = apply_log_li_threshold(nuclei, threshold_factor=threshold_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "\n",
    "hole_width = 5  \n",
    "# # wrapper to remoce_small_objects\n",
    "NU_object = remove_small_holes(NU_object, hole_width ** 2 )\n",
    "\n",
    "small_object_max = 45\n",
    "NU_object = size_filter_2D(NU_object, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "NU_label = label(NU_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# 2D \n",
    "hole_width = 40\n",
    "#removed_holes = remove_small_holes(bw, hole_width ** 2 )\n",
    "removed_holes = hole_filling(bw, hole_min =0 , hole_max=hole_width**2, fill_2d = True) \n",
    "\n",
    "\n",
    "small_object_max = 45\n",
    "cleaned_img = size_filter_2D(removed_holes, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "# limit the labeling to where we have soma or NUclear signal\n",
    "# watershed_mask = np.logical_or(cleaned_img, NU_labels > 0)\n",
    "watershed_mask = cleaned_img \n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "labels_out = watershed(\n",
    "            inverted_img,\n",
    "            markers=NU_label,\n",
    "            connectivity=np.ones((1, 3,3), bool),\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _masked_inverted_watershed(img_in,markers, mask):\n",
    "    \"\"\"wrapper for watershed on inverted image and masked\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    watershed_mask = cleaned_img \n",
    "    inverted_img = 1. - composite_soma\n",
    "\n",
    "    labels_out = watershed(\n",
    "                1. - img_in,\n",
    "                markers=markers,\n",
    "                connectivity=np.ones((1, 3,3), bool),\n",
    "                mask=mask,\n",
    "                )\n",
    "    return labels_out\n",
    "\n",
    "_labels_out = _masked_inverted_watershed(composite_soma,NU_label, cleaned_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 768, 768), (1, 768, 768))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_out.shape, NU_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST- POST_PROCESSING\n",
    "###################\n",
    "# keep the \"SOMA\" label which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ raw_soma_linear[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "keep_label\n",
    "\n",
    "soma_out = np.zeros_like(labels_out)\n",
    "soma_out[labels_out==keep_label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_max_label(raw_signal: np.ndarray, labels_in: np.ndarray):\n",
    "    \"\"\" keep only the label with the maximum raw signal\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    all_labels = np.unique(labels_in)[1:]\n",
    "\n",
    "    total_signal = [ raw_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    labels_max = np.zeros_like(labels_out)\n",
    "    labels_max[labels_out==keep_label] = 1\n",
    "    return labels_max\n",
    "\n",
    "_soma_out = _choose_max_label(raw_soma_linear,labels_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'soma_out' at 0x178f85df0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    soma_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '_soma_out' at 0x178d1f8b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    NU_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_labels(\n",
    "    _soma_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '_labels_out' at 0x17942c5b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(\n",
    "    _labels_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_infer_soma` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer soma.  \n",
    "\n",
    "> NOTE:  although it takes the parameters as input, they are all \"hard coded\" below, and the function returns the parameters in the same `defaultdict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 1. infer_soma\n",
    "##########################\n",
    "\n",
    "\n",
    "def _infer_soma(in_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer soma from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of soma    \n",
    "    \"\"\"\n",
    "\n",
    "    struct_img = _raw_soma_MCZ(in_img)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    ################# part 1- soma\n",
    "\n",
    "    struct_img = min_max_intensity_normalization(struct_img)\n",
    "    \n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    # Linear-ish processing\n",
    "    med_filter_size = 15   \n",
    "    struct_img = median_filter_slice_by_slice(struct_img, size=med_filter_size)\n",
    "\n",
    "    gaussian_smoothing_sigma = 1.34\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice( struct_img,\n",
    "                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                )\n",
    "\n",
    "    struct_img_non_lin = _non_linear_soma_transform_MCZ(struct_img)\n",
    "\n",
    "    ################# part 2 - nuclei\n",
    "    nuclei = min_max_intensity_normalization(in_img[NUC_CH].copy() )\n",
    "\n",
    "    med_filter_size = 4   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    nuclei = median_filter_slice_by_slice( \n",
    "                                                                    nuclei,\n",
    "                                                                    size=med_filter_size  )\n",
    "\n",
    "    gaussian_smoothing_sigma = 1.34\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "                                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                )\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 100\n",
    "    # \"Masked Object Thresholding\" - 3D capable\n",
    "    struct_obj, _bw_low_level = MO(struct_img_non_lin, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    ################# part 2 : nuclei thresholding\n",
    "    #struct_obj = struct_img > filters.threshold_li(struct_img)\n",
    "    threshold_factor = 0.9 #from cellProfiler\n",
    "    thresh_min = .1\n",
    "    thresh_max = 1.\n",
    "    nuclei_object = apply_log_li_threshold(nuclei, threshold_factor=threshold_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "\n",
    "\n",
    "    hole_width = 5  \n",
    "    # # wrapper to remoce_small_objects\n",
    "    #nuclei_object = remove_small_holes(nuclei_object, hole_width ** 2 )\n",
    "    nuclei_object = hole_filling(nuclei_object, hole_min=0, hole_max=hole_width**2, fill_2d=True)\n",
    "\n",
    "    small_object_max = 45\n",
    "    nuclei_object = size_filter_2D(nuclei_object, \n",
    "                                                                min_size= small_object_max**2, \n",
    "                                                                connectivity=1)\n",
    "\n",
    "\n",
    "    nuclei_labels = label(nuclei_object)\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # 2D \n",
    "    hole_max = 40  \n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0 , hole_max=hole_max**2, fill_2d = True) \n",
    "    #struct_obj = remove_small_holes(struct_obj, hole_max ** 2 )\n",
    "\n",
    "\n",
    "    small_object_max = 45\n",
    "    struct_obj = size_filter_2D(struct_obj, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "    labels_out = _masked_inverted_watershed(struct_img, nuclei_labels, struct_obj) # np.logical_or(struct_obj, NU_labels > 0)\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    soma_out = _choose_max_label(struct_img,labels_out)\n",
    "\n",
    "    return soma_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# TEST `_infer_soma`  function defined above\n",
    "\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SO_label =  _infer_SOMA(img_2D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# TEST `infer_soma` exported functions\n",
    "\n",
    "\n",
    "##\n",
    "`infer_som a` procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles.soma import infer_soma\n",
    "\n",
    "soma_mask =  infer_SOMA(img_2D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'SO_label' at 0x16f813370>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    soma_mask,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
