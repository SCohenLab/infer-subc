{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***soma*** -  1Ô∏è‚É£ \n",
    "\n",
    "> WARNING: (üö®üö®üö®üö® Steps 2-9 depend on establishing a good solution here.)\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: \n",
    "### ‚úÖ Infer sub-cellular component soma in order to understand interactome \n",
    "\n",
    ">> WARNING:  THIS DOES NOT WORK WELL\n",
    "\n",
    "To measure shape, position, and size of the cell body -- the soma.    There are a variety of signals from which we could make this inference.  The two most promising are a composite signal including the residual from linear unmixing (e.g. `ch = [1, 4, 5,7]`) and a signal derived from the lysosome channel (`ch = 1`).    In all procdures scaling the intensities to find the lower florescence signals at the edge of the soma against baseline is employed.  \n",
    "\n",
    "In the long term we can build of a database of \"ground truth\" by sourcing additional markers which can be iteratively improved.  For example using the Allen Cell \"Label Free\" segmentation results should provide a good corroboration or constraints to the procedures outlined below.  \n",
    "\n",
    "A first possible _workflow_ is illustrated below.\n",
    "\n",
    "### IMAGE PROCESSING  OBJECTIVE :  infer ***soma***\n",
    " \n",
    "> #### Note:  we are using the Nuclei of the brightest cell to aid in inferring the Soma and Cytosol objects.   Because we do NOT have a direct cell membrane / soma signal this is the trickiest and potentially problematic part of the overall sub-cellular component inference.   The Soma (via the Cytosol mask) will be used to define ALL subsequent sub-cellular Objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preamble\n",
    "\n",
    "1. imports\n",
    "2. setup\n",
    "3. choose_Z\n",
    "\n",
    "> the contents of the preamble are reduncant with [00.2_extract_optimal_Z.ipynb](./00.2_extract_optimal_Z.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_czi_image,\n",
    "                                                                    list_image_files)\n",
    "\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROXI_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LIPID_CH ,\n",
    "                                                                    RESIDUAL_CH )                                                                    \n",
    "from infer_subc_2d.utils.img import *\n",
    "\n",
    "from infer_subc_2d.organelles import fixed_get_optimal_Z_image, fixed_find_optimal_Z, find_optimal_Z\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHOOZE Z-SLICE\n",
    "\n",
    "Lets find the slice with the most overall intensity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing _optimal_ z-slice::: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ch_to_agg = ( LYSO_CH ,\n",
    "                        MITO_CH ,\n",
    "                        GOLGI_CH ,\n",
    "                        PEROXI_CH ,\n",
    "                        ER_CH ,\n",
    "                        LIPID_CH )\n",
    "                            \n",
    "nuc_ch = NUC_CH\n",
    "optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing _optimal_ z-slice::: 8\n"
     ]
    }
   ],
   "source": [
    "# TEST other both extract Z methods\n",
    "img_2D = select_z_from_raw(img_data, optimal_Z)\n",
    "img_2D = fixed_get_optimal_Z_image(img_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  infer ***soma***\n",
    "\n",
    ">WORKFLOW #1  - modified MCZ 3/20\n",
    "\n",
    "Segmentation on a 3 channel composite as per 3/20 pipeline from MCZ\n",
    "Summary - Starting with a linear combination of three signals,  the signal is smoothed and non-linearly combined (logrithmic and edge detected) for thresholding. \n",
    "## summary of steps\n",
    "\n",
    "‚û°Ô∏è INPUT\n",
    "- multi-channel sum (4*1,5,7)\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "- ne-noise and somoothe\n",
    "- log transform inensities\n",
    "- scale to max 1.0\n",
    "- create non-linear aggregate of log-intensity + scharr filtered \n",
    "\n",
    "CORE PROCESSING\n",
    "- mask object segmentation at bottom\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT ‚û°Ô∏è \n",
    "- mask of SOMA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_2D[LYSO_CH].copy() + \n",
    "                               1. * img_2D[ER_CH].copy() + \n",
    "                               1. * img_2D[RESIDUAL_CH].copy() )\n",
    "\n",
    "\n",
    "nuc_img_raw = img_2D[NUC_CH].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _raw_soma_MCZ(img_in):\n",
    "    \"\"\" define soma image\n",
    "    \"\"\"\n",
    "    SOMA_W = (4.,1.,1.)\n",
    "    SOMA_CH = (LYSO_CH,ER_CH,RESIDUAL_CH) #LYSO, ER, RESIDUAL\n",
    "    img_out = np.zeros_like(img_in[0]).astype(np.double)\n",
    "    for w,ch in zip(SOMA_W,SOMA_CH):\n",
    "        img_out += w*img_in[ch]\n",
    "    return img_out\n",
    "\n",
    "_struct_img_raw = _raw_soma_MCZ(img_2D)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING prototype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "#\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "med_filter_size = 15  \n",
    "\n",
    "################# part 1\n",
    "raw_soma_linear = min_max_intensity_normalization(struct_img_raw.copy())\n",
    "\n",
    "struct_img = median_filter_slice_by_slice(raw_soma_linear, size=med_filter_size)\n",
    "\n",
    "structure_img_smooth = ndi.gaussian_filter( struct_img,\n",
    "                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                mode=\"nearest\", \n",
    "                                                                                truncate=gaussian_smoothing_truncate_range,\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "# NON-Linear aggregation\n",
    "log_image, d = log_transform( structure_img_smooth ) \n",
    "log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "edges = filters.scharr(log_image)\n",
    "\n",
    "composite_soma = intensity_normalization(  edges,  scaling_param=[0] ) + log_image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _non_linear_soma_transform_MCZ(in_img):\n",
    "    \"\"\" non-linear distortion to fill out soma\n",
    "    log + edge of smoothed composite\n",
    "    \"\"\"\n",
    "    # non-Linear processing\n",
    "    log_img, d = log_transform( in_img.copy() ) \n",
    "    log_img = min_max_intensity_normalization(  log_img )\n",
    "    return min_max_intensity_normalization(  filters.scharr(log_img) )  + log_img\n",
    "\n",
    "_composite_soma = _non_linear_soma_transform_MCZ(structure_img_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################# part 2 Nuclei pre=process\n",
    "nuc_img_raw = img_2D[0].copy() \n",
    "# median filter in 2D / convert to float 0-1.   get rid of the \"residual\"\n",
    "nuclei = min_max_intensity_normalization(nuc_img_raw)\n",
    "\n",
    "med_filter_size = 4   \n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "nuclei = median_filter_slice_by_slice( \n",
    "                                                                nuclei,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "gaussian_smoothing_sigma = 1.34\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "                                                                                            sigma=gaussian_smoothing_sigma,\n",
    "                                                                                            truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                            )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _masked_object_thresh(\n",
    "    structure_img_smooth: np.ndarray, th_method: str, cutoff_size: int, th_adjust: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    wrapper for applying Masked Object Thresholding with just two parameters via `MO` from `aicssegmentation`\n",
    "    Parameters\n",
    "    ------------\n",
    "    structure_img_smooth: np.ndarray\n",
    "        a 3d image\n",
    "    th_method: \n",
    "         which method to use for calculating global threshold. Options include:\n",
    "         \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").\n",
    "         \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n",
    "    cutoff_size: \n",
    "        Masked Object threshold `size_min`\n",
    "    th_adjust: \n",
    "        Masked Object threshold `local_adjust`\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "        np.ndimage \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    struct_obj = MO(\n",
    "        structure_img_smooth,\n",
    "        global_thresh_method=th_method,\n",
    "        object_minArea=cutoff_size,\n",
    "        extra_criteria=True,\n",
    "        local_adjust=th_adjust,\n",
    "        return_object=False,\n",
    "        dilate=True,\n",
    "    )\n",
    "    return struct_obj\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "low_level_min_size =  100\n",
    "\n",
    "################# part 1\n",
    "bw = _masked_object_thresh(composite_soma, \n",
    "                                                th_method='ave', \n",
    "                                                cutoff_size=low_level_min_size, \n",
    "                                                th_adjust= 0.5)\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "# bw, _bw_low_level = MO(composite_soma, \n",
    "#                                                 global_thresh_method='ave', \n",
    "#                                                 object_minArea=low_level_min_size, \n",
    "#                                                 extra_criteria=True,\n",
    "#                                                 local_adjust= 0.5, \n",
    "#                                                 return_object=True,\n",
    "#                                                 dilate=True)\n",
    "                                                \n",
    "\n",
    "################# part 2 : nuclei thresholding\n",
    "#struct_obj = struct_img > filters.threshold_li(struct_img)\n",
    "thresh_factor = 0.9 #from cellProfiler\n",
    "thresh_min = .1\n",
    "thresh_max = 1.\n",
    "NU_object = apply_log_li_threshold(nuclei, thresh_factor=thresh_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "\n",
    "hole_width = 5  \n",
    "# # wrapper to remoce_small_objects\n",
    "NU_object = remove_small_holes(NU_object, hole_width ** 2 )\n",
    "\n",
    "small_object_width = 20\n",
    "NU_object = size_filter_2D(NU_object, \n",
    "                                                            min_size= small_object_width**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "NU_label = label(NU_object)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# 2D \n",
    "hole_width = 40\n",
    "#removed_holes = remove_small_holes(bw, hole_width ** 2 )\n",
    "removed_holes = hole_filling(bw, hole_min =0 , hole_max=hole_width**2, fill_2d = True) \n",
    "\n",
    "\n",
    "small_object_width = 45\n",
    "cleaned_img = size_filter_2D(removed_holes, \n",
    "                                                            min_size= small_object_width**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "# limit the labeling to where we have soma or NUclear signal\n",
    "# watershed_mask = np.logical_or(cleaned_img, NU_labels > 0)\n",
    "watershed_mask = cleaned_img \n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "labels_out = watershed(\n",
    "            inverted_img,\n",
    "            markers=NU_label,\n",
    "            connectivity=np.ones((1, 3,3), bool),\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _masked_inverted_watershed(img_in,markers, mask):\n",
    "    \"\"\"wrapper for watershed on inverted image and masked\n",
    "\n",
    "    \"\"\"\n",
    "    labels_out = watershed(\n",
    "                1. - img_in,\n",
    "                markers=markers,\n",
    "                connectivity=np.ones((1, 3,3), bool),\n",
    "                mask=mask,\n",
    "                )\n",
    "    return labels_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 768, 768), (1, 768, 768))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels_out = _masked_inverted_watershed(composite_soma,NU_label, cleaned_img)\n",
    "\n",
    "labels_out.shape, NU_label.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST- POST_PROCESSING\n",
    "###################\n",
    "# keep the \"SOMA\" label which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ raw_soma_linear[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "keep_label\n",
    "\n",
    "soma_out = np.zeros_like(labels_out)\n",
    "soma_out[labels_out==keep_label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_max_label(raw_signal: np.ndarray, labels_in: np.ndarray):\n",
    "    \"\"\" keep only the label with the maximum raw signal\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    all_labels = np.unique(labels_in)[1:]\n",
    "\n",
    "    total_signal = [ raw_signal[labels_in == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    labels_max = np.zeros_like(labels_in)\n",
    "    labels_max[labels_in==keep_label] = 1\n",
    "    return labels_max\n",
    "\n",
    "_soma_out = _choose_max_label(raw_soma_linear,labels_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with `napari` 1\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'soma_out' at 0x17fdefdc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    soma_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '_soma_out' at 0x1587b6820>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    NU_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_labels(\n",
    "    _soma_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '_labels_out' at 0x18011a490>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(\n",
    "    _labels_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE parameterized  `_infer_soma` function\n",
    "\n",
    "A function to infer_soma from our (Channel, 1 Z slice, X, Y) image accourding the the following parameters: \n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 1. infer_soma\n",
    "##########################\n",
    "\n",
    "def _infer_soma(in_img: np.ndarray,\n",
    "    median_sz_soma: int,\n",
    "    gauss_sig_soma: float,\n",
    "    median_sz_nuc: int,\n",
    "    gauss_sig_nuc: float,\n",
    "    mo_method: str,\n",
    "    mo_adjust: float,\n",
    "    mo_cutoff_size: int,\n",
    "    thresh_factor: float,\n",
    "    thresh_min: float,\n",
    "    thresh_max: float,\n",
    "    max_hole_w_nuc: int,\n",
    "    small_obj_w_nuc: int,\n",
    "    max_hole_w_soma: int,\n",
    "    small_obj_w_soma: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer soma from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "    median_sz_soma: \n",
    "        width of median filter for _soma_ signal\n",
    "    gauss_sig_soma: \n",
    "        sigma for gaussian smoothing of _soma_ signal\n",
    "    median_sz_nuc: \n",
    "        width of median filter for _soma_ signal\n",
    "    gauss_sig_nuc: \n",
    "        sigma for gaussian smoothing of _soma_ signal\n",
    "    mo_method: \n",
    "         which method to use for calculating global threshold. Options include:\n",
    "         \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").\n",
    "         \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n",
    "    mo_adjust: \n",
    "        Masked Object threshold `local_adjust`\n",
    "    mo_cutoff_size: \n",
    "        Masked Object threshold `size_min`\n",
    "    thresh_factor: \n",
    "        adjustment factor for log Li threholding\n",
    "    thresh_min: \n",
    "        abs min threhold for log Li threholding\n",
    "    thresh_max: \n",
    "        abs max threhold for log Li threholding\n",
    "    max_hole_w_nuc: \n",
    "        hole filling cutoff for nuclei post-processing\n",
    "    small_obj_w_nuc: \n",
    "        minimu object size cutoff for nuclei post-processing\n",
    "    max_hole_w_soma: \n",
    "        hole filling cutoff for soma signal post-processing\n",
    "    small_obj_w_soma: \n",
    "        minimu object size cutoff for soma signal post-processing\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    soma_mask:\n",
    "        a logical/labels object defining boundaries of soma\n",
    "\n",
    "    \"\"\"\n",
    "    nuc_ch = NUC_CH\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################\n",
    "    struct_img = _raw_soma_MCZ(in_img)\n",
    "\n",
    "    nuclei = select_channel_from_raw(in_img, nuc_ch)\n",
    "    nuclei = min_max_intensity_normalization(nuclei)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    ################# part 1- soma\n",
    "\n",
    "    struct_img = min_max_intensity_normalization(struct_img)\n",
    "    \n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    # Linear-ish processing\n",
    "    struct_img = median_filter_slice_by_slice(struct_img, size=median_sz_soma)\n",
    "\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice( struct_img,\n",
    "                                                                                sigma=gauss_sig_soma)\n",
    "\n",
    "    struct_img_non_lin = _non_linear_soma_transform_MCZ(struct_img)\n",
    "\n",
    "    ################# part 2 - nuclei\n",
    "\n",
    "    nuclei = median_filter_slice_by_slice( nuclei,\n",
    "                                                                    size=median_sz_nuc  )\n",
    "\n",
    "    nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "                                                                                                sigma=gauss_sig_nuc )\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    struct_obj = _masked_object_thresh(struct_img_non_lin, \n",
    "                                                th_method=mo_method, \n",
    "                                                cutoff_size=mo_cutoff_size, \n",
    "                                                th_adjust=mo_adjust)               \n",
    "    # # \"Masked Object Thresholding\" - 3D capable\n",
    "    # struct_obj = MO(\n",
    "    #     struct_img_non_lin, \n",
    "    #     object_minArea=mo_cutoff_size, \n",
    "    #     global_thresh_method=mo_method, \n",
    "    #     local_adjust=mo_adjust, \n",
    "    #     return_object=False\n",
    "    # )\n",
    "    ################# part 2 : nuclei thresholding\n",
    "    nuclei_object = apply_log_li_threshold(nuclei, thresh_factor=thresh_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "\n",
    "    # # wrapper to remoce_small_objects\n",
    "    nuclei_object = hole_filling(nuclei_object, hole_min=0, hole_max=max_hole_w_nuc**2, fill_2d=True)\n",
    "\n",
    "    nuclei_object = size_filter_2D(nuclei_object, \n",
    "                                                                min_size= small_obj_w_nuc**2, \n",
    "                                                                connectivity=1)\n",
    "\n",
    "\n",
    "    nuclei_labels = label(nuclei_object)\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    struct_obj = hole_filling(struct_obj, \n",
    "                                                hole_min =0 , \n",
    "                                                hole_max=max_hole_w_soma**2, \n",
    "                                                fill_2d = True) \n",
    " \n",
    "    struct_obj = size_filter_2D(struct_obj, \n",
    "                                                    min_size= small_obj_w_soma**2, \n",
    "                                                    connectivity=1)\n",
    "\n",
    "    labels_out = _masked_inverted_watershed(struct_img, nuclei_labels, struct_obj) # np.logical_or(struct_obj, NU_labels > 0)\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    soma_out = _choose_max_label(struct_img,labels_out)\n",
    "\n",
    "    return soma_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_fixed_infer_soma` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer soma. with a *fixed* set of parameters for each step in the procedure.  That is they are all \"hard coded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 1. fixed_infer_soma\n",
    "##########################\n",
    "\n",
    "\n",
    "def _fixed_infer_soma(in_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer soma from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    soma_mask:\n",
    "        a logical/labels object defining boundaries of soma\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    ###################\n",
    "    # PARAMETERS\n",
    "    ###################   \n",
    "    median_sz_soma = 15\n",
    "    gauss_sig_soma = 1.34\n",
    "    median_sz_nuc = 4\n",
    "    gauss_sig_nuc = 1.34\n",
    "    mo_method = \"ave\"\n",
    "    mo_adjust = 0.5\n",
    "    mo_cutoff_size = 100\n",
    "    thresh_factor = 0.9\n",
    "    thresh_min = 0.1\n",
    "    thresh_max = 1.\n",
    "    max_hole_w_nuc = 5\n",
    "    small_obj_w_nuc = 15\n",
    "    max_hole_w_soma = 40\n",
    "    small_obj_w_soma = 15\n",
    "\n",
    "    soma_out = _infer_soma(in_img,\n",
    "                                                median_sz_soma,\n",
    "                                                gauss_sig_soma,\n",
    "                                                median_sz_nuc,\n",
    "                                                gauss_sig_nuc,\n",
    "                                                mo_method,\n",
    "                                                mo_adjust,\n",
    "                                                mo_cutoff_size,\n",
    "                                                thresh_factor,\n",
    "                                                thresh_min,\n",
    "                                                thresh_max,\n",
    "                                                max_hole_w_nuc,\n",
    "                                                small_obj_w_nuc,\n",
    "                                                max_hole_w_soma,\n",
    "                                                small_obj_w_soma) \n",
    "\n",
    "    return soma_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# TEST `_infer_soma`  function defined above\n",
    "\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SO_label =  _fixed_infer_soma(img_2D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles import fixed_infer_soma, infer_soma\n",
    "\n",
    "soma_ =  fixed_infer_soma(img_2D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'soma_' at 0x18070c940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    SO_label,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    soma_,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the `infer_soma` spec to the widget json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function fixed_infer_soma is already in all_functions.json\n",
      "overwriting  fixed_infer_soma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_subc_2d.organelles_config.helper import add_function_spec_to_widget_json\n",
    "\n",
    "_fixed_infer_soma =  {\n",
    "        \"name\": \" infer soma mask (fixed parameters)\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"fixed_infer_soma\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"fixed_infer_soma\", _fixed_infer_soma, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function infer_soma is already in all_functions.json\n",
      "overwriting  infer_soma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_infer_soma =  {\n",
    "        \"name\": \" infer soma mask\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"infer_soma\",\n",
    "        \"parameters\": {\n",
    "                \"median_sz_soma\": {\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"min\": 3,\n",
    "                        \"max\": 15,\n",
    "                        \"increment\": 1\n",
    "                },\n",
    "                \"gauss_sig_soma\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.25,\n",
    "                        \"max\": 15.0,\n",
    "                        \"min\": 1.25,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"median_sz_nuc\": {\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"min\": 3,\n",
    "                        \"max\": 15,\n",
    "                        \"increment\": 1\n",
    "                },\n",
    "                \"gauss_sig_nuc\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.25,\n",
    "                        \"max\": 15.0,\n",
    "                        \"min\": 1.25,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"mo_method\": {\n",
    "                        \"data_type\": \"str\",\n",
    "                        \"widget_type\": \"drop-down\",\n",
    "                        \"options\": [\n",
    "                                \"triangle\",\n",
    "                                \"median\",\n",
    "                                \"ave_tri_med\"\n",
    "                                ]\n",
    "                },\n",
    "                \"mo_adjust\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 1.0,\n",
    "                        \"min\": 0.0,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"mo_cutoff_size\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 10,\n",
    "                        \"max\": 250,\n",
    "                        \"min\": 10,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_factor\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 1.2,\n",
    "                        \"min\": 0.6,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_min\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": .9,\n",
    "                        \"min\": 0.0,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_max\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 1.0,\n",
    "                        \"min\": 0.1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"max_hole_w_nuc\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 40,\n",
    "                        \"min\": 4,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },           \n",
    "                \"small_obj_w_nuc\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 50,\n",
    "                        \"min\": 1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },                           \n",
    "                \"max_hole_w_soma\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 2,\n",
    "                        \"max\": 100,\n",
    "                        \"min\": 20,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },           \n",
    "                \"small_obj_w_soma\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 50,\n",
    "                        \"min\": 1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },        \n",
    "        }\n",
    "}\n",
    "\n",
    "add_function_spec_to_widget_json(\"infer_soma\", _infer_soma, overwrite=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function raw_soma_MCZ is already in all_functions.json\n",
      "overwriting  raw_soma_MCZ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_raw_soma_MCZ =  {\n",
    "        \"name\": \"define weighted aggregate soma signal (MCZ-cellprofiler)\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"raw_soma_MCZ\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"raw_soma_MCZ\", _raw_soma_MCZ, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function non_linear_soma_transform_MCZ is already in all_functions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_non_linear_soma_transform_MCZ =  {\n",
    "        \"name\": \"non-linear filter of soma signal (MCZ-cellprofiler)\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"non_linear_soma_transform_MCZ\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"non_linear_soma_transform_MCZ\", _non_linear_soma_transform_MCZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function masked_inverted_watershed is already in all_functions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_masked_inverted_watershed =  {\n",
    "        \"name\": \"watershed on inverted image and masked\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"masked_inverted_watershed\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"masked_inverted_watershed\", _masked_inverted_watershed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function choose_max_label is already in all_functions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_choose_max_label =  {\n",
    "        \"name\": \"keep only the label with the maximum raw signa\",\n",
    "        \"python::module\": \"infer_subc_2d.utils.img\",\n",
    "        \"python::function\": \"choose_max_label\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"choose_max_label\", _choose_max_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function min_max_intensity_normalization is already in all_functions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_min_max_intensity_normalization =  {\n",
    "        \"name\": \"Min Max Intesity Normalization\",\n",
    "        \"python::module\": \"infer_subc_2d.utils.img\",\n",
    "        \"python::function\": \"min_max_intensity_normalization\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"min_max_intensity_normalization\", _min_max_intensity_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function masked_object_thresh is already in all_functions.json\n",
      "overwriting  masked_object_thresh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_subc_2d.organelles_config.helper import add_function_spec_to_widget_json\n",
    "\n",
    "_masked_object_thresh =  {\n",
    "        \"name\": \"Masked Object Threshold wrapper for widgets\",\n",
    "        \"python::module\": \"infer_subc_2d.utils.img\",\n",
    "        \"python::function\": \"masked_object_thresh\",\n",
    "        \"parameters\": {\n",
    "                \"th_method\": {\n",
    "                        \"data_type\": \"str\",\n",
    "                        \"widget_type\": \"drop-down\",\n",
    "                        \"options\": [\n",
    "                        \"triangle\",\n",
    "                        \"median\",\n",
    "                        \"ave_tri_med\"\n",
    "                        ]\n",
    "                },\n",
    "                \"cutoff_size\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"min\": 0,\n",
    "                        \"max\": 2000,\n",
    "                        \"increment\": 50\n",
    "                },\n",
    "                \"th_adjust\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"min\": 0,\n",
    "                        \"max\": 2,\n",
    "                        \"increment\": 0.02\n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "add_function_spec_to_widget_json(\"masked_object_thresh\", _masked_object_thresh, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# TEST `infer_soma` exported functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles import fixed_infer_soma\n",
    "\n",
    "soma_mask =  fixed_infer_soma(img_2D) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize  2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'soma_mask' at 0x1819c34f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    soma_mask,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "# viewer.dims.ndisplay = 3\n",
    "# viewer.camera.angles = (-30, 25, 120)\n",
    "nbscreenshot(viewer, canvas_only=True)\n",
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## Write workflow .json\n",
    "Now that we've added our function specs we can compose workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_soma_step_by_step_dict():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_soma\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    # struct_img = _raw_soma_MCZ(in_img)\n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"raw_soma_MCZ\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(0)\n",
    "\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(0)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################\n",
    "    #SOMA\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(1)\n",
    "\n",
    "\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 15 ))\n",
    "    parent.append(3)\n",
    "\n",
    "\n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.4 ))\n",
    "    parent.append(4)\n",
    "\n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"non_linear_soma_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(5)\n",
    "\n",
    "    #NUC\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(2)\n",
    "\n",
    "    step_name.append(\"8\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 4 ))\n",
    "    parent.append(7)\n",
    "\n",
    "    step_name.append(\"9\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.4 ))\n",
    "    parent.append(8)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # SOMA\n",
    "    step_name.append(\"10\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(6)\n",
    "\n",
    "\n",
    "    # NUCLEI\n",
    "    step_name.append(\"11\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(9)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # NUCLEI\n",
    "    step_name.append(\"12\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=5**2, fill_2d=True))\n",
    "    parent.append(11)\n",
    "\n",
    "    step_name.append(\"13\")\n",
    "    function_name.append(\"size_filter_2D\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(12)\n",
    "\n",
    "    step_name.append(\"14\")\n",
    "    function_name.append(\"label\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(13)\n",
    "\n",
    "    # SOMA\n",
    "    step_name.append(\"15\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=25**2, fill_2d=True))\n",
    "    parent.append(10)\n",
    "\n",
    "    step_name.append(\"16\")\n",
    "    function_name.append(\"size_filter_2D\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(15)\n",
    "\n",
    "    step_name.append(\"17\")\n",
    "    function_name.append(\"masked_inverted_watershed\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([ 5 , 14, 16])\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    step_name.append(\"18\")\n",
    "    function_name.append(\"choose_max_label\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([5, 17])\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_2.1.soma_stepbystep.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n",
    "\n",
    "infer_soma_stepbystep_dict = make_infer_soma_step_by_step_dict()\n",
    "\n",
    "write_workflow_json(\"conf_2.1.soma_stepbystep\", infer_soma_stepbystep_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_soma_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer nuclei from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    nuclei_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"fixed_get_optimal_Z_img\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(0)\n",
    "\n",
    "    # SOMA\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"raw_soma_MCZ\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(1)\n",
    "\n",
    "    # NUC\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(1)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################\n",
    "    # SOMA\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(2)\n",
    "\n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 15 ))\n",
    "    parent.append(4)\n",
    "\n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.4 ))\n",
    "    parent.append(5)\n",
    "\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"non_linear_soma_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(6)\n",
    "\n",
    "    #NUC\n",
    "    step_name.append(\"8\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(3)\n",
    "\n",
    "    step_name.append(\"9\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 4 ))\n",
    "    parent.append(8)\n",
    "\n",
    "    step_name.append(\"10\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.4 ))\n",
    "    parent.append(9)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # SOMA\n",
    "    step_name.append(\"11\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(7)\n",
    "\n",
    "    # NUC\n",
    "    step_name.append(\"12\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(10)\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # nUC\n",
    "    step_name.append(\"13\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=5**2, fill_2d=True))\n",
    "    parent.append(12)\n",
    "\n",
    "    step_name.append(\"14\")\n",
    "    function_name.append(\"size_filter_2D\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(13)\n",
    "\n",
    "    step_name.append(\"15\")\n",
    "    function_name.append(\"label\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(14)\n",
    "\n",
    "\n",
    "    # SOMA\n",
    "    step_name.append(\"16\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=25**2, fill_2d=True))\n",
    "    parent.append(11)\n",
    "\n",
    "    step_name.append(\"17\")\n",
    "    function_name.append(\"size_filter_2D\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(16)\n",
    "\n",
    "    step_name.append(\"18\")\n",
    "    function_name.append(\"masked_inverted_watershed\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([  7 , 15,17 ])\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    step_name.append(\"19\")\n",
    "    function_name.append(\"choose_max_label\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([6,18])\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_1.1.soma_stepbystep_from_raw.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_soma_stepbystep_from_raw_dict = make_infer_soma_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.1.soma_stepbystep_from_raw\", infer_soma_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## SUMMARY\n",
    "\n",
    "The above explains the overall framework.  \n",
    "\n",
    "### NEXT: INFER NUCLEI\n",
    "\n",
    "proceed to [02_infer_nuclei.ipynb](./02_infer_nuclei.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
