{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCohenLab Volumetric Image Processing notebook (Simplified MCZ)\n",
    "\n",
    "--------------\n",
    "# PIPELINE OVERVIEW\n",
    "## 1. GOAL SETTING\n",
    "\n",
    "### GOAL:  Infer sub-cellular components in order to understand interactome \n",
    "\n",
    "To measure shape, position, size, and interaction of eight organelles/cellular components (Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and SOMA) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.\n",
    "\n",
    "### summary of _OBJECTIVES_\n",
    "- Infer subcellular objects:\n",
    "  -  #### #1. [infer NUCLEI ](#image-processing-objective-1-infer-nucleii) - NU, ch 0\n",
    "  -  #### #2. [Infer SOMA](#image-processing-objective-2-infer-soma) (extent of single brightest cell)- SO, composite icluding ch 1, ch 4,ch 5, and ch 7 \"residuals\"\n",
    "  -  #### #3. [Infer CYTOSOL](#image-processing-objective-3-infer-cytosol)- CY \n",
    "  -  #### #4. [Infer LYSOSOMES](#image-processing-objective-4-infer-lysosomes)  - LS, ch 1\n",
    "  -  #### #5. [Infer MITOCHONDRIA](#image-processing-objective-5-infer-mitochondria) - MT, ch 2\n",
    "  -  #### #6. [Infer GOLGI complex](#image-processing-objective-6-infer-golgi-complex) - GL, ch 3\n",
    "  -  #### #7. [Infer PEROXISOMES](#image-processing-objective-7-infer-peroxisomes) - PO, ch  4\n",
    "  -  #### #8. [Infer ENDOPLASMIC RETICULUM ](#image-processing-objective-8-infer-endoplasmic-reticulum)- ER, ch 5\n",
    "  -  #### #9. [Infer LB](#image-processing-objective-9-infer-lipid-bodies-droplet), LD, ch 6 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. DATA CREATION\n",
    "> METHODS\n",
    "> iPSC lines prepared and visualized on Zeiss Microscopes. 32 channel multispectral images collected.  Linear Unmixing in  ZEN Blue software with target emission spectra yields 8 channel image outputs.  Channels correspond to: Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and a “residual” signal.\n",
    "\n",
    "> Meta-DATA\n",
    ">   - Microcope settings\n",
    ">  - OME scheme\n",
    "> - Experimenter observations\n",
    "> - Sample, bio-replicate, image numbers, condition values, etc\n",
    ">  - Dates\n",
    ">  - File structure, naming conventions\n",
    ">  - etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. IMAGE PROCESSING\n",
    "### INFERENCE OF SUB-CELLULAR OBJECTS\n",
    "The imported images have already been pre-processed to transform the 32 channel spectral measuremnts into \"linearly unmixed\" images which estimate independently labeled sub-cellular components.  Thes 7 channels (plus a residual \"non-linear\" signal) will be used to infer the shapes and extents of these sub-cellular components.   \n",
    "We will perform computational image analysis on the pictures (in 2D an 3D) to _segment_ the components of interest for measurement.  In other prcoedures we can used these labels as \"ground truth\" labels to train machine learning models to automatically perform the inference of these objects.\n",
    "Pseudo-independent processing of the imported multi-channel image to acheive each of the 9 objecives stated above.  i.e. infering: NUCLEI, SOMA, CYTOSOL, LYSOSOME, MITOCHONDRIA, GOLGI COMPLEX, PEROZISOMES, ENDOPLASMIC RETICULUM, and LIPID BODIES\n",
    "\n",
    "### General flow for infering objects via segmentation\n",
    "- Pre-processing\n",
    "- Core-processing (thresholding)\n",
    "- Post-processing \n",
    "\n",
    "### QC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. QUANTIFICATION\n",
    "\n",
    "SUBCELLULAR COMPONENT METRICS\n",
    "-  extent \n",
    "-  size\n",
    "-  shape\n",
    "-  position\n",
    "\n",
    "\n",
    "\n",
    "### NOTE: PIPELINE TOOL AND DESIGN CHOICES?\n",
    "We want to leverage the Allen Cell & Structure Setmenter.  It has been wrapped as a [napari-plugin](https://www.napari-hub.org/plugins/napari-allencell-segmenter) but fore the workflow we are proving out here we will want to call the `aicssegmentation` [package](https://github.com/AllenCell/aics-segmentation) directly.\n",
    "\n",
    "#### ​The Allen Cell & Structure Segmenter \n",
    "​The Allen Cell & Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.\n",
    "\n",
    "More details about Segmenter can be found at https://allencell.org/segmenter\n",
    "In order to leverage the A\n",
    "# IMPORTS\n",
    "\n",
    "import  all nescessary packages\n",
    "\n",
    "we are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.utils.file_io import read_input_image, list_image_files\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "viewer = None\n",
    "# # from infer_subc.bioim.object import BioImObject\n",
    "# # from infer_subc.transforms.transform import BioImTransform\n",
    "# # from infer_subc.transforms.pipeline import BioImPipeline\n",
    "# from infer_subc.utils.file_io import read_input_image, get_raw_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of infer_subc.utils.file_io failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/utils/file_io.py\", line 15, in <module>\n",
      "    class AICSImageReaderWrap:\n",
      "  File \"/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/utils/file_io.py\", line 23, in AICSImageReaderWrap\n",
      "    meta: Dict[str, Any]\n",
      "NameError: name 'Dict' is not defined\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from aicssegmentation.workflow import WorkflowEngine, WorkflowStep, WorkflowDefinition\n",
    "\n",
    "\n",
    "# from dataclasses import dataclass\n",
    "# from typing import List\n",
    "# from aicssegmentation.workflow import Workflow\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class Channel:\n",
    "#     index: int\n",
    "#     name: str = None\n",
    "\n",
    "#     @property\n",
    "#     def display_name(self):\n",
    "#         if self.name is None or self.name.strip().isspace():\n",
    "#             return f\"Channel {self.index}\"\n",
    "\n",
    "#         return f\"Ch{self.index}.  {self.name}\"\n",
    "\n",
    "# @dataclass\n",
    "# class SegmenterModel:\n",
    "#     \"\"\"\n",
    "#     Main Segmenter plugin model\n",
    "#     \"\"\"\n",
    "\n",
    "#     layers: List[str] = None\n",
    "#     selected_layer: Layer = None\n",
    "#     channels: List[str] = None\n",
    "#     selected_channel: Channel = None\n",
    "#     workflows: List[str] = None\n",
    "#     active_workflow: Workflow = None\n",
    "\n",
    "#     def reset(self):\n",
    "#         \"\"\"\n",
    "#         Reset model state\n",
    "#         \"\"\"\n",
    "#         self.layers = None\n",
    "#         self.selected_layer = None\n",
    "#         self.channels = None\n",
    "#         self.selected_channel = None\n",
    "#         self.workflows = None\n",
    "#         self.active_workflow = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "# viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get and load Image for processing\n",
    "For testing purposes... TODO: build a nice wrapper for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read the data into memeory from the `.czi` files.  (Note: there is also the 2D slice .tif file read for later comparision).  WE will also collect metatdata.\n",
    "\n",
    "> the `data_path` variable should have the full path to the set of images wrapped in a `Path()`.   Below the path is built in 3 stages\n",
    "> 1. my user directory \"~\" plus\n",
    "> 2. general imaging data directory \"Projects/Imaging/data\" plus\n",
    "> 3. \"raw\" where the linearly unmixed zstacks are\n",
    "\n",
    "The image \"type\" is also set by `im_type = \".czi\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# depricate this\n",
    "# list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "\n",
    "test_img_name = img_file_list[5]\n",
    "test_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioim_image = read_input_image(test_img_name)\n",
    "\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "Please proceed to 01_infer_nuclei.ipynb\n",
    "\n",
    "\n",
    "everything below is just testing some speed of different libraries..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_img = img_data.max(axis=1)\n",
    "max_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "for i,ch in enumerate(channel_names):\n",
    "    viewer.add_image(max_img[i,:,:],\n",
    "                                name = ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '0 :: None :: Nuclei_Jan22')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 ms ± 16.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from os import truncate\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "\n",
    "sigma = 1.34\n",
    "truncate_range = 3.0\n",
    "f = lambda x: gaussian_filter(x,sigma=sigma, mode=\"nearest\", truncate=truncate_range)\n",
    "\n",
    "size = 3\n",
    "f2 = lambda x: median_filter(x,size=size)\n",
    "\n",
    "\n",
    "# %timeit np.vectorize(f, signature='(n,m)->(n,m)' )(dd)\n",
    "# 143 ms ± 1.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "# %timeit np.vectorize(f2, signature='(n,m)->(n,m)' )(dd)\n",
    "# 378 ms ± 16.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 ms ± 7.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def _slice_by_slice(struct_img, sigma=1.34, truncate_range=3.0):\n",
    "    \"\"\"\n",
    "    wrapper for applying 2D Guassian smoothing slice by slice on a 3D image\n",
    "    \"\"\"\n",
    "    structure_img_smooth = np.zeros_like(struct_img)\n",
    "\n",
    "    for zz in range(struct_img.shape[0]):\n",
    "        structure_img_smooth[zz, :, :] = gaussian_filter(\n",
    "            struct_img[zz, :, :], sigma=sigma, mode=\"nearest\", truncate=truncate_range\n",
    "        )\n",
    "\n",
    "    return structure_img_smooth    \n",
    "\n",
    "def _med_slice_by_slice(struct_img, size=3):\n",
    "    \"\"\"\n",
    "    wrapper for applying 2D Guassian smoothing slice by slice on a 3D image\n",
    "    \"\"\"\n",
    "    structure_img_smooth = np.zeros_like(struct_img)\n",
    "\n",
    "    for zz in range(struct_img.shape[0]):\n",
    "        structure_img_smooth[zz, :, :] = median_filter(\n",
    "            struct_img[zz, :, :], size=size\n",
    "        )\n",
    "    return structure_img_smooth     \n",
    "    # this might be faster:  scipy.signal.medfilt2d()\n",
    "\n",
    "# %timeit _slice_by_slice(dd, sigma=1.34, truncate_range=3.0)\n",
    "# 145 ms ± 4.93 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "#median\n",
    "# %timeit _med_slice_by_slice(dd, size=3)\n",
    "# 354 ms ± 7.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v1 = np.vectorize(f2, signature='(n,m)->(n,m)' )(dd)\n",
    "v2 = _med_slice_by_slice(dd, size=3)\n",
    "\n",
    "(v1!=v2).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 270.00 MiB </td>\n",
       "                        <td> 67.50 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (8, 15, 768, 768) </td>\n",
       "                        <td> (8, 15, 384, 384) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1 Graph Layer </td>\n",
       "                        <td> 4 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"376\" height=\"186\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.60913412115106,0.0 25.60913412115106,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.804567\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >8</text>\n",
       "  <text x=\"45.609134\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.609134,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"111\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"60\" x2=\"111\" y2=\"76\" />\n",
       "  <line x1=\"95\" y1=\"120\" x2=\"111\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"111\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 111.99850848103011,16.998508481030107 111.99850848103011,136.99850848103011 95.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"231\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"111\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"155\" y1=\"0\" x2=\"171\" y2=\"16\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"231\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 215.0,0.0 231.99850848103011,16.998508481030107 111.99850848103011,16.998508481030107\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"231\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"111\" y1=\"76\" x2=\"231\" y2=\"76\" />\n",
       "  <line x1=\"111\" y1=\"136\" x2=\"231\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"111\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"171\" y1=\"16\" x2=\"171\" y2=\"136\" />\n",
       "  <line x1=\"231\" y1=\"16\" x2=\"231\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"111.99850848103011,16.998508481030107 231.99850848103011,16.998508481030107 231.99850848103011,136.99850848103011 111.99850848103011,136.99850848103011\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"171.998508\" y=\"156.998508\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >768</text>\n",
       "  <text x=\"251.998508\" y=\"76.998508\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,251.998508,76.998508)\">768</text>\n",
       "  <text x=\"93.499254\" y=\"148.499254\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,93.499254,148.499254)\">15</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(8, 15, 768, 768), dtype=float32, chunksize=(8, 15, 384, 384), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape[-3:]\n",
    "dd = im.get_image_dask_data()\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the raw data file with [napari](https://napari.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "    img_data,\n",
    "    channel_axis=0,\n",
    "    name=channel_names,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.scale_bar.visible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.dims.ndisplay = 3\n",
    "viewer.camera.angles = (-30, 25, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  need to save: \n",
    "\n",
    "# output_path, list_of_files\n",
    "viewer.dims.ndisplay = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1045,    0,  239, ...,  222,    0,  157],\n",
       "        [1279,    0,    0, ...,    0,  188,    0],\n",
       "        [  52,    0,    0, ...,  289,  444,  113],\n",
       "        ...,\n",
       "        [   0,   57,  366, ...,   72,   85,  340],\n",
       "        [ 218,   45,  415, ...,    0,    0,    0],\n",
       "        [   0,  382,    0, ...,  212,  283,   17]],\n",
       "\n",
       "       [[ 593,    0,    0, ...,  443,    0,   36],\n",
       "        [ 417, 2778,  452, ...,  243,    0,  199],\n",
       "        [1170,    0,    0, ...,  420,   60,    0],\n",
       "        ...,\n",
       "        [   0,  123,  279, ...,  439,    6,   74],\n",
       "        [  90,  166,  139, ...,  372,    0,   57],\n",
       "        [ 330,    0,  117, ...,  306,    0,    0]],\n",
       "\n",
       "       [[1092,    0,    0, ...,  107,    0,  126],\n",
       "        [1765, 1469,  603, ...,  244,    0,  499],\n",
       "        [   0,    0,    0, ...,   55,  295,    0],\n",
       "        ...,\n",
       "        [  65,  178,    0, ...,   96,  308,    0],\n",
       "        [ 177,    0,    0, ...,    0,   71,  148],\n",
       "        [ 141,    0,  108, ...,   11,    0,  109]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1079,  432,  274, ...,  141,  129,   78],\n",
       "        [   0,    0,  771, ...,    0,   70,  221],\n",
       "        [ 523,    0, 1247, ...,  313,    0,  106],\n",
       "        ...,\n",
       "        [ 102,    0,   64, ...,    0,  135,  178],\n",
       "        [ 114,  194,    0, ...,    0,   97,    0],\n",
       "        [   8,   81,    0, ...,    0,  304,  121]],\n",
       "\n",
       "       [[   0,  230,    0, ...,    0,    0,    0],\n",
       "        [  68,  854,  148, ...,    0,    0,    0],\n",
       "        [   0,    0,  981, ...,    0,    0,  189],\n",
       "        ...,\n",
       "        [   0,    0,  117, ...,   23,    0,    0],\n",
       "        [   0,    0,   36, ...,   96,   32,  268],\n",
       "        [ 100,   94,    0, ...,  107,    0,  184]],\n",
       "\n",
       "       [[   0,    0,  530, ...,    0,   51,    0],\n",
       "        [   0,  116,   86, ...,  223,    0,  147],\n",
       "        [   0,  111,    0, ...,    0,  128,    0],\n",
       "        ...,\n",
       "        [ 145,   45,    0, ...,   98,    0,    0],\n",
       "        [  58,    0,  141, ...,    0,    0,   21],\n",
       "        [  37,   84,   43, ...,    1,    6,    0]]], dtype=uint16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = img_data[2,:,:,:]\n",
    "\n",
    "\n",
    "img_ = np.asanyarray(image)\n",
    "img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_interpolated = HistogramEqualization().F(im_cls.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'im_interpolated' at 0x17686b640>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    im_interpolated,\n",
    "    scale = scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:285: error: (-215:Assertion failed) (ksize % 2 == 1) && (_src0.dims() <= 2 ) in function 'medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/00_pipeline_setup.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/00_pipeline_setup.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m MedianBlur()\u001b[39m.\u001b[39;49mapply(im_cls)\n",
      "File \u001b[0;32m~/Projects/Imaging/infer-subc/notebooks/infer_subc/core/_transform.py:37\u001b[0m, in \u001b[0;36mTransform.apply\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\"\"modify Image object in-place\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m#     raise NotImplementedError\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# def apply(self, img):\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39m# assert isinstance(\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m#     img, BioImImage\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# ), f\"img is type {type(img)} but must be Image\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     img\u001b[39m.\u001b[39mset_image(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF(img\u001b[39m.\u001b[39;49mget_image()))\n",
      "File \u001b[0;32m~/Projects/Imaging/infer-subc/notebooks/infer_subc/core/_transform.py:58\u001b[0m, in \u001b[0;36mMedianBlur.F\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mF\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[1;32m     57\u001b[0m     \u001b[39m#assert image.dtype == np.uint8, f\"image dtype {image.dtype} must be np.uint8\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m cv2\u001b[39m.\u001b[39;49mmedianBlur(image, ksize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:285: error: (-215:Assertion failed) (ksize % 2 == 1) && (_src0.dims() <= 2 ) in function 'medianBlur'\n"
     ]
    }
   ],
   "source": [
    "MedianBlur().apply(im_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
