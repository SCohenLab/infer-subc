{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer NUCLEI - 1️⃣\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: ✅ Infer sub-cellular component #1: NUCLEI  in order to understand interactome \n",
    "\n",
    "To measure shape, position, size, and interaction of eight organelles/cellular components Nuclei (NU).  \n",
    "\n",
    "Dependencies:\n",
    "SOMA and CYTOSOL inference rely on the Nuclei inference.  Therefore all of the sub-cellular objects rely on the NU segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import read_input_image, list_image_files, export_ome_tiff, etree_to_dict\n",
    "from infer_subc_2d.utils.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from infer_subc_2d.organelles.nuclei import infer_NUCLEI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING  OBJECTIVE :  infer NUCLEI\n",
    " \n",
    "\n",
    "NOTE:  using Allen Cell Segmenter  [Nucleophosmin](https://www.allencell.org/cell-observations/category/nucleophosmin) might be a good generic mechanism.  e.g.\n",
    "-  [playground_npm1.ipynb](https://github.com/AllenInstitute/aics-segmentation/blob/master/lookup_table_demo/playground_npm1.ipynb) and [npm1.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/structure_wrapper/seg_npm1.py) and [npm1_SR.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/structure_wrapper/seg_npm1_SR.py)\n",
    "\n",
    "\n",
    "> #### Note:  this initial inferred object -- the Nuclei of the brightest cell -- will be used in inferring the Soma and Cytosol objects.   This is a straightforward procedure, but also note that any inconsistencies will flow into the Soma and Cytosol objects which in turn affect ALL inferred objects.\n",
    "\n",
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "# CUSTOMIZE HERE --->\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(os.path.expanduser(\"~\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'/Users/ahenrie/Projects/Imaging/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi' does not have a recognized TIFF header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:169\u001b[0m, in \u001b[0;36m_tiff2xml\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     offsetsize, offsetformat, tagnosize, tagnoformat, tagsize, codeformat \u001b[39m=\u001b[39m {\n\u001b[1;32m    170\u001b[0m         \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mII*\u001b[39;49m\u001b[39m\\0\u001b[39;49;00m\u001b[39m\"\u001b[39;49m: (\u001b[39m4\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<I\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<H\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m12\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<H\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    171\u001b[0m         \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMM\u001b[39;49m\u001b[39m\\0\u001b[39;49;00m\u001b[39m*\u001b[39;49m\u001b[39m\"\u001b[39;49m: (\u001b[39m4\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>I\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>H\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m12\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>H\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    172\u001b[0m         \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mII+\u001b[39;49m\u001b[39m\\0\u001b[39;49;00m\u001b[39m\"\u001b[39;49m: (\u001b[39m8\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<Q\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<Q\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m<H\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    173\u001b[0m         \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMM\u001b[39;49m\u001b[39m\\0\u001b[39;49;00m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m: (\u001b[39m8\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>Q\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>Q\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m>H\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    174\u001b[0m     }[fh\u001b[39m.\u001b[39;49mread(\u001b[39m4\u001b[39;49m)]\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: b'ZISR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc-2D/notebooks/01_infer_nuclei.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc-2D/notebooks/01_infer_nuclei.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mome_types\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tiff\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc-2D/notebooks/01_infer_nuclei.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ome2 \u001b[39m=\u001b[39m from_tiff(test_img_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:142\u001b[0m, in \u001b[0;36mfrom_tiff\u001b[0;34m(path, parser, validate)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tiff\u001b[39m(\n\u001b[1;32m    110\u001b[0m     path: Union[Path, \u001b[39mstr\u001b[39m],\n\u001b[1;32m    111\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m    112\u001b[0m     parser: Union[Parser, \u001b[39mstr\u001b[39m, \u001b[39mNone\u001b[39;00m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    113\u001b[0m     validate: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    114\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OME:\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\"\"Generate OME metadata object from OME-TIFF path.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[39m    This will use the first ImageDescription tag found in the TIFF header.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m        If the TIFF file has no OME metadata.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m from_xml(_tiff2xml(path), parser\u001b[39m=\u001b[39mparser, validate\u001b[39m=\u001b[39mvalidate)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:176\u001b[0m, in \u001b[0;36m_tiff2xml\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    169\u001b[0m     offsetsize, offsetformat, tagnosize, tagnoformat, tagsize, codeformat \u001b[39m=\u001b[39m {\n\u001b[1;32m    170\u001b[0m         \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mII*\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m\"\u001b[39m: (\u001b[39m4\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<I\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<H\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<H\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    171\u001b[0m         \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMM\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m4\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>I\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>H\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>H\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    172\u001b[0m         \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mII+\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m\"\u001b[39m: (\u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<Q\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<Q\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<H\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    173\u001b[0m         \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMM\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>Q\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>Q\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m>H\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    174\u001b[0m     }[fh\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m)]\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m!r}\u001b[39;00m\u001b[39m does not have a recognized TIFF header\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    178\u001b[0m fh\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m \u001b[39mif\u001b[39;00m offsetsize \u001b[39m==\u001b[39m \u001b[39m8\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m    179\u001b[0m fh\u001b[39m.\u001b[39mseek(unpack(offsetformat, fh\u001b[39m.\u001b[39mread(offsetsize))[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: '/Users/ahenrie/Projects/Imaging/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi' does not have a recognized TIFF header"
     ]
    }
   ],
   "source": [
    "\n",
    "from ome_types import from_tiff\n",
    "\n",
    "ome2 = from_tiff(test_img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHOOZE Z-SLICE\n",
    "\n",
    "Lets find the slice with the most overall intensity...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_to_agg = (1,2,3,4,5,6)\n",
    "nuc_ch = 0\n",
    "\n",
    "optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "optimal_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Z-slice that is \"optimal\", and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1, 768, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_2D = img_data[:,[optimal_Z],:,:]\n",
    "img_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "    img_2D,\n",
    "    channel_axis=0,\n",
    "    name=channel_names,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.scale_bar.visible = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# IMAGE PROCESSING Objective 1:  infer NUCLEI\n",
    " \n",
    "## details\n",
    "\n",
    "➡️ INPUT\n",
    "\n",
    "- channel 0\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  scale to min 0, max 1.0\n",
    "- median Filter window 4\n",
    "-  gaussian 1.34\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - threshold method minimum cross-entropy.  \n",
    "    - objects 50-400 pixels, \n",
    "    - threshold smoothing scale: 1.34 (later 1 pixel\n",
    "    - threshold correction factor: 0.9 (later 1.2 )\n",
    "    - lower / upper bounds  (.1,1) ?\n",
    "    - log transformed thresholding\n",
    "    - fill holes\n",
    "\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "\n",
    "OUTPUT ➡️ \n",
    "- labels of NUCLEI\n",
    "\n",
    "\n",
    "> #### Note:  in later steps we will limit each analysis to a single object, but at this stage we have multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median filtering scale is ~ : [0.5804527163320905, 0.3194866073934927, 0.3194866073934927]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "from collections import defaultdict\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 4\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale[1:]\n",
    "\n",
    "\n",
    "gaussian_smoothing_sigma = 1.34\n",
    "gaussian_smoothing_truncate_range = 3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA IMPORT\n",
    "\n",
    "Get the \"raw\" signals we need to analyze as well as any other dependencies in \"inferred\" objects.  \n",
    "\n",
    "> NOTE: we are operating on a single \"test\" image in this notebook.  The batch-processing of all the images will be happen at the end of the notebook after we have developed/confirmed the setmentation procedures and parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE- PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_nuclei = im_dat[0].copy()\n",
    "# raw_lyso    = img_data[1,:,:,:].copy()\n",
    "# raw_mito    = img_data[2,:,:,:].copy()\n",
    "# raw_golgi   = img_data[3,:,:,:].copy()\n",
    "# raw_peroxi = img_data[4,:,:,:].copy()\n",
    "# raw_ER      = img_data[5,:,:,:].copy()\n",
    "# raw_lipid   = img_data[6,:,:,:].copy()\n",
    "# raw_residual = img_data[7,:,:,:].copy()\n",
    "# total_flourescence = intensity_normalization(img_data.copy(), scaling_param=[0]).sum(axis=0)\n",
    "# total_flourescence_scaled = intensity_normalization(total_flourescence, scaling_param=[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################                         )\n",
    "struct_img = simple_intensity_normalization(raw_nuclei.copy())\n",
    "\n",
    "structure_img_median = ndi.median_filter(struct_img, size = med_filter_size)\n",
    "\n",
    "structure_img_smooth = ndi.gaussian_filter( struct_img, sigma=gaussian_smoothing_sigma, mode=\"nearest\", truncate=gaussian_smoothing_truncate_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> #### NOTE: Thresholding\n",
    "> [Thresholding](https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29) is used to create binary images. A threshold value determines the intensity value separating foreground pixels from background pixels. Foregound pixels are pixels brighter than the threshold value, background pixels are darker. In many cases, images can be adequately segmented by thresholding followed by labelling of *connected components*, which is a fancy way of saying \"groups of pixels that touch each other\".\n",
    "> \n",
    "> Different thresholding algorithms produce different results. [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) and [Li's minimum cross entropy threshold](https://scikit-image.org/docs/dev/auto_examples/developers/plot_threshold_li.html) are two common algorithms. Below, we use Li. You can use `skimage.filters.threshold_<TAB>` to find different thresholding methods.\n",
    "\n",
    "_Li_ procedure  better matches the CellProfiler pipeline which simply calls it \"Minimum Cross Entropy\" .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "#tol = max(numpy.min(numpy.diff(numpy.unique(structure_img_median))) / 2, 0.5 / 65536) #assumes 16bit?\n",
    "#threshold_value = filters.threshold_li(structure_img_smooth)\n",
    "\n",
    "threshold_value_log = threshold_li_log(structure_img_smooth)\n",
    "\n",
    "threshold_factor = 0.9 #from cellProfiler\n",
    "thresh_min = 0.1\n",
    "thresh_max = 1.0\n",
    "threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "li_thresholded = structure_img_smooth > threshold\n",
    "li_thresholded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "hole_width = 5  \n",
    "# # wrapper to remoce_small_objects\n",
    "removed_holes = morphology.remove_small_holes(li_thresholded, hole_width ** 2 )\n",
    "\n",
    "small_object_max = 5\n",
    "\n",
    "cleaned_img = size_filter_2D(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2, \n",
    "                                                         connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT + Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NU_object = cleaned_img\n",
    "NU_labels = label(cleaned_img   )\n",
    "NU_signal = struct_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'NU_labels' at 0x186866910>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    NU_object,\n",
    "    scale=scale[1:],\n",
    "    opacity=0.3,\n",
    ")    \n",
    "\n",
    "\n",
    "viewer.add_labels(\n",
    "    NU_labels,\n",
    "    scale=scale[1:],\n",
    "    opacity=0.3,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_NUCLEI` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "\n",
    "def _infer_NUCLEI(struct_img, in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer NUCLEI from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the NUCLEI signal\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of NU\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        signal\n",
    "            scaled/filtered (pre-processed) flourescence image\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "\n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    med_filter_size = 4   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = ndi.median_filter( struct_img,\n",
    "                                                         size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.34\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = ndi.gaussian_filter( struct_img,\n",
    "                                                            sigma=gaussian_smoothing_sigma, \n",
    "                                                            mode=\"nearest\", \n",
    "                                                            truncate=gaussian_smoothing_truncate_range)\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    struct_obj = struct_img > filters.threshold_li(struct_img)\n",
    "    threshold_value_log = threshold_li_log(struct_img)\n",
    "\n",
    "    threshold_factor = 0.9 #from cellProfiler\n",
    "    thresh_min = .1\n",
    "    thresh_max = 1.\n",
    "    threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "    out_p['threshold_factor'] = threshold_factor\n",
    "    out_p['thresh_min'] = thresh_min\n",
    "    out_p['thresh_max'] = thresh_max\n",
    "\n",
    "    struct_obj = struct_img > threshold\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    hole_width = 5  \n",
    "    # # wrapper to remoce_small_objects\n",
    "    struct_obj = morphology.remove_small_holes(struct_obj, hole_width ** 2 )\n",
    "    out_p['hole_width'] = hole_width\n",
    "\n",
    "\n",
    "    small_object_max = 5\n",
    "    struct_obj = size_filter_2D(struct_obj, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    retval = (struct_obj,  label(struct_obj), out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "Use the `infer_NUCLEI` function to infer the Nucleus and export it as an _ome.tif_ for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "# test - 9.7 secods to run...\n",
    "\n",
    "\n",
    "NU_object, NU_label, out_p =  _infer_NUCLEI(raw_nuclei.copy(), default_params) \n",
    "# NU_object, NU_label, out_p =  _infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NU_object']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NU_object_filen\n",
    "NU_object_filen = export_ndarray(NU_object,  object_name, str(out_path)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_ndarray(data_in, img_name, out_path) -> str:\n",
    "    \"\"\"\n",
    "    #  data_in: types.ArrayLike,\n",
    "    #  meta_in: dict,\n",
    "    # img_name: types.PathLike,\n",
    "    # out_path: types.PathLike,\n",
    "    # curr_chan: int\n",
    "    # assumes a single image\n",
    "    \"\"\"\n",
    "\n",
    "    out_name = out_path + img_name + \".npy\"\n",
    "    data_in.tofile(out_name)\n",
    "    return out_name\n",
    "\n",
    "NU_object_filen = export_ndarray(NU_object,  object_name, str(out_path)+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/data/inferred_objects/NU_object.npy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NU_object_filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'intensity_norm_param': [0],\n",
       "             'gaussian_smoothing_sigma': 1.34,\n",
       "             'gaussian_smoothing_truncate_range': 3.0,\n",
       "             'dot_2d_sigma': 2,\n",
       "             'dot_2d_sigma_extra': 1,\n",
       "             'dot_2d_cutoff': 0.025,\n",
       "             'min_area': 10,\n",
       "             'low_level_min_size': 100,\n",
       "             'median_filter_size': 4,\n",
       "             'z_factor': 7.0,\n",
       "             'scale': (0.5804527163320905,\n",
       "              0.07987165184837318,\n",
       "              0.07987165184837318),\n",
       "             'threshold_factor': 0.9,\n",
       "             'thresh_min': 0.1,\n",
       "             'thresh_max': 1.0,\n",
       "             'hole_width': 5,\n",
       "             'small_object_max': 5})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
