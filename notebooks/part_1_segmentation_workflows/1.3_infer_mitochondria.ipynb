{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer **`Mitochondria`**\n",
    "\n",
    "***Prior to this notebook, you should have already run through [1.0_image_setup](1.0_image_setup.ipynb).***\n",
    "\n",
    "In notebooks 1.2 through 1.7, we will go over the implementation of `infer-subc` in the a Napari plugin called  `organelle-segmenter-plugin`. The steps outlined in each notebook correlate to the workflow steps from the plugin. Here, you will gain knowledge of what `infer-subc` functions are involved in each of those steps. \n",
    "\n",
    "The segmentation workflows are completely independent of each other and can be run in any order. The current notebook segments the `Mitochondria`. Notebooks for the segmentation of other organelles can be found here:\n",
    "- Infer [`lysosomes`](1.2_infer_lysosome.ipynb)\n",
    "- Infer [`golgi`](1.4_infer_golgi.ipynb)\n",
    "- Infer [`peroxisomes`](1.5_infer_peroxisome.ipynb)\n",
    "- Infer [`endoplasmic reticulum (ER)`](1.6_infer_ER.ipynb)\n",
    "- Infer [`lipid droplets`](1.7_infer_lipid_droplet.ipynb)\n",
    "\n",
    "***Note:** These notebooks do not include a batch processing option. They are simply explanations of the steps included in the Napari plugin. If you would like to batch process your images in a Jupyter notebook instead of the plugin, you can use the [batch process segmentation](batch_process_segmentations.ipynb) notebook.*\n",
    "\n",
    "### **Single cell analysis**\n",
    "Each workflow segments organelles from the entire image, irrespective of the cell mask identified in notebook 1.1. To attain a single-cell analysis, the mask will be applied to the organelle segmentation outputs before quantification in the `part_2_quantification` notebooks. \n",
    "\n",
    "### **Mitochondria**üîã\n",
    "Mitochondria are membrane enclosed structures comprised of an outter member that surrounds the inner member or cristea. This double-membrane structure is critical for mitochondria to produce ATP. Mitochondria are also important in intracellular calcium regulation, programmed cell death (e.g., apoptosis), and more. The sturucture of mitochondria are highly regulated through fission and fusion. They are also involved in organelle contacts with most other membrane-bound organelles to coordinate and regulate organellar functions. \n",
    "\n",
    "### **Fluorescence labeling strategies** üîÜ \n",
    "Mitochondria can be fluorescently labeled in live and fixed cells by staining for endogenous proteins, targeting fluorescent proteins to the outter membrane, inner membrane, intermembrane space (between the inner and outter membranes), or matrix (inside the inner membrane) using genetically encoded markers, or with dye-based approaches. The labeling approach used and resolution of your images can result in different staining outcomes that can impact the segmentation steps below.\n",
    "\n",
    "For example, a genetically encoded fluorescent protein targeted to the outer mitochondria membrane using the TOMM20 protein (e.g., Tomm20-GFP) may result in a hollow tube shaped organelle while a dye-based marker that fills the intermembrane space and matrix would produce a filled-in structure. The workflow below was optimized for images that contain filled-in mitochondria.\n",
    "\n",
    "The size and shape of a mitochondrion can range from a long filament to a small sphere depending on the cell state and stress levels. Therefore, we are utilizing two segmentation methods to idenfity all mitochondria. Read through the steps below for more details.\n",
    "\n",
    "***We advise that you test the segmentation process on a small, pilot dataset before committing to a particular labeling strategy and segmentation approach.***\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë£ **Summary of steps**  \n",
    "\n",
    "‚û°Ô∏è **EXTRACTION**\n",
    "- **`STEP 1`** - Select a channel for segmentation\n",
    "\n",
    "    - select single channel containing the mitochondria marker (channel number = user input)\n",
    "\n",
    "**PRE-PROCESSING**\n",
    "- **`STEP 2`** - Rescale and smooth image\n",
    "\n",
    "  - rescale intensity of composite image (min=0, max=1)\n",
    "  - median filter (median size = user input)\n",
    "  - gaussian filter (sigma = user input)\n",
    "\n",
    "**CORE PROCESSING**\n",
    "- **`STEP 3`** - ‚ÄòDot‚Äô thresholding method (AICSSeg)\n",
    "\n",
    "  - apply \"dot\" thresholding method (for small round objects) from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (size scale, threshold cutoff and method = user input)\n",
    "\n",
    "- **`STEP 4`** - ‚ÄòFilament‚Äô threshold method (AICSSeg)\n",
    "\n",
    "  - apply \"filament\"/\"vessel\" thresholding method (for tubular objects) from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (size scale and threshold cutoff = user input)\n",
    "\n",
    "- **`STEP 5`** - Combine Segmentations (logical or)\n",
    "\n",
    "  - combine the two segmentations with logical *OR*\n",
    "\n",
    "**POST-PROCESSING**\n",
    "- **`STEP 6`** - Remove small holes and objects\n",
    "\n",
    "  - fill holes (hole size = user input)\n",
    "  - remove small objects (object size = user input)\n",
    "  - filter method (method = user input)\n",
    "\n",
    "**POST-POST-PROCESSING**\n",
    "- **`STEP 7`** - Label objects\n",
    "\n",
    "    - label unique mitochondria objects based on connectivity\n",
    "\n",
    "\n",
    "**EXPORT**  ‚û°Ô∏è\n",
    "- save labeled ***mitochondria*** (mito, MT) as unsigned integer 16-bit tif files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## **IMPORTS AND LOAD IMAGE**\n",
    "Details about the functions included in this subsection are outlined in the [`1.0_image_setup`](1.0_image_setup.ipynb) notebook. Please visit that notebook first if you are confused about any of the code included here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image, \n",
    "                                     list_image_files, \n",
    "                                     export_inferred_organelle,\n",
    "                                     sample_input)\n",
    "\n",
    "from infer_subc.core.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following information about your data: `im_type`, `data_root_path`, `in_data_path`, and `out_data_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "# If using the sample data, select which cell type you would like analyze (\"neuron\" or \"astrocyte\"):\n",
    "# If not using the sample data, set cell_type to None\n",
    "sample_data_type = \"neuron\"\n",
    "\n",
    "# If you are not using the sample data, please edit \"USER SPECIFIED\" as necessary.\n",
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(\"USER SPECIFIED\")\n",
    "\n",
    "# Specify the file type of your raw data that will be analyzed. Ex) \".czi\" or \".tiff\"\n",
    "im_type = \"USER SPECIFIED\"\n",
    "\n",
    "## Specify which subfolder that contains the input data and the input data file extension\n",
    "in_data_path = data_root_path / \"USER SPECIFIED\"\n",
    "\n",
    "## Specify the output folder to save the segmentation outputs if.\n",
    "## If its not already created, the code below will creat it for you\n",
    "out_data_path = data_root_path / \"USER SPECIFIED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron\\raw\\20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                        Image Name\n",
       "0  c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron\\raw\\20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome.tiff"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If sample_data_type is set to \"neuron\" or \"astrocyte\", then the sample data is used and the directories are set\n",
    "if sample_data_type != None:\n",
    "    data_root_path, im_type, in_data_path, out_data_path = sample_input(sample_data_type)\n",
    "\n",
    "# list files in the input folder\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Use the list above to specify which image you wish to analyze based on its index: `test_img_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "test_img_n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata information\n",
      "File path: c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron\\raw\\20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome.tiff\n",
      "Channel 0 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:0\n",
      "Channel 1 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:1\n",
      "Channel 2 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:2\n",
      "Channel 3 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:3\n",
      "Channel 4 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:4\n",
      "Channel 5 name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:5\n",
      "Scale (ZYX): (0.410594, 0.079947, 0.079947)\n",
      "Channel axis: 0\n",
      "\n",
      "Proceed to Napari window to view your selected image.\n"
     ]
    }
   ],
   "source": [
    "# load image and metadata\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# metadata\n",
    "channel_names = meta_dict['name']\n",
    "meta = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "file_path = meta_dict['file_name']\n",
    "print(\"Metadata information\")\n",
    "print(f\"File path: {file_path}\")\n",
    "for i in list(range(len(channel_names))):\n",
    "    print(f\"Channel {i} name: {channel_names[i]}\")\n",
    "print(f\"Scale (ZYX): {scale}\")\n",
    "print(f\"Channel axis: {channel_axis}\")\n",
    "\n",
    "# open viewer and add images\n",
    "viewer = napari.Viewer()\n",
    "for i in list(range(len(channel_names))):\n",
    "    viewer.add_image(img_data[i],\n",
    "                     scale=scale,\n",
    "                     name=f\"Channel {i}\")\n",
    "viewer.grid.enabled = True\n",
    "viewer.reset_view()\n",
    "print(\"\\nProceed to Napari window to view your selected image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## **EXTRACTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 1` - Select a channel for segmentation**\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify which channel includes your mitochondria label:\n",
    "- `MITO_CH`: the index of the channel containing your mitochondria label. Image indexing begins with 0, not 1. Reference the channel numbers indicated in the Napari window for easy reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SAMPLE DATA SETTINGS**\n",
    "\n",
    "If using the sample data, here are the recommended parameters for each cell type\n",
    "\n",
    "|**Cell type**|MITO_CH| \n",
    "| :------------------------------------- |  :------:  |\n",
    "|Neuron|`4`|\n",
    "|Astrocyte|`4`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "MITO_CH = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block extracts the mitochondria channel from your multi- (or single) channel image. It will be the only part of the image used in the rest of this workflow. The single mitochondria channel is added to the Napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '1 - Extract Mito' at 0x2b419c1b580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select channel\n",
    "raw_mito = select_channel_from_raw(img_data, MITO_CH)\n",
    "\n",
    "# clear napari and add single channel as a new layer\n",
    "viewer.layers.clear()\n",
    "viewer.grid.enabled = False\n",
    "viewer.add_image(raw_mito, scale=scale, name=\"1 - Extract Mito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## **PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 2` - Rescale and smooth image**\n",
    "\n",
    "&#x1F453; **FYI:** This code block rescales the image so that the pixel/voxel with the highest intensity is set to 1 and the one with the lowest intensity is set to 0. The image is then *optionally* smoothed using a Gaussian and/or median filter. \n",
    "\n",
    "<mark> Include more information on the Gaussian and median filtering methods here </mark>\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the amount of filter to use for each method. Higher values indicate more smoothing:\n",
    "- `med_filter_size`: the size of the median filter to apply; if 0 is used, no filter will be applied\n",
    "- `gaussian_smoothing_sigma`: the sigma to apply in the Gaussian filtering step; if 0 is used, no filter will be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SAMPLE DATA SETTINGS**\n",
    "\n",
    "If using the sample data, here are the recommended parameters for each cell type\n",
    "\n",
    "|**Cell type**|med_filter_size|gaussian_smoothing_sigma| \n",
    "| :------------------------------------- |  :------:  |  :------:  |\n",
    "|Neuron|`0`|`0`|\n",
    "|Astrocyte|`0`|`0`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "med_filter_size = 0  \n",
    "gaussian_smoothing_sigma = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block rescales the image and applies the specified median and Gaussian filters. The image is then added to Napari as a new layer for visual comparison to the input image. \n",
    "\n",
    "Use the Napari viewer to iteratively adjust the smoothing settings selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '2 - Rescale and Smooth' at 0x2b4223b3340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescaling and smoothing input image\n",
    "struct_img =  scale_and_smooth(raw_mito,\n",
    "                               median_size = med_filter_size, \n",
    "                               gauss_sigma = gaussian_smoothing_sigma)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(struct_img, scale=scale, name=\"2 - Rescale and Smooth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## **CORE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 3` -  ‚ÄòDot‚Äô thresholding method (AICSSeg)**\n",
    "\n",
    "&#x1F453; **FYI:** This code block is the first of two semantic segmentation steps that are combined together in a later step. `Semantic segmentation` is the process of deciding whether a pixel/voxel should be included in an object (labeled with a value of 1) or should be considered as part of the background (labeled with a value of 0). A semantic segmentation does not discern individual objects from one another.\n",
    "\n",
    "The 'dot' filter is derived from the [`aics-segmentation`](https://github.com/AllenCell/aics-segmentation) package. It utilizes up to three scale (object size) and cutoff (threshold) pairs for objects of different size and intensity. This function is specifically designed to segment small round objects.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the scale and cutoff values for each pair:\n",
    "- `dot_scale_1`: the size scale for the first scale/cutoff pair; larger values correlate to selection of larger objects\n",
    "- `dot_cut_1`: the threshold cutoff value for the first scale/cutoff pair; small cutoffs tend to yield more dots that are larger in volume; larger cutoffs tend to yield less dots that are slimmer.\n",
    "- `dot_scale_2`: the size scale for the second scale/cutoff pair; this can be set to 0 if a second scale/cutoff pair isn't needed\n",
    "- `dot_cut_2`: the threshold cutoff value for the second scale/cutoff pair; this can be set to 0 if a second scale/cutoff pair isn't needed\n",
    "- `dot_scale_3`: the size scale for the third scale/cutoff pair; this can be set to 0 if a third scale/cutoff pair isn't needed\n",
    "- `dot_cut_3`: the threshold cutoff value for the third scale/cutoff pair; this can be set to 0 if a third scale/cutoff pair isn't needed\n",
    "- `dot_method`: \"3D\" processes the image taking into account intensities in three dimensions (XYZ); \"slice-by-slice\" processes each Z-slice in the image separately, not considering any intensity in higher or lower Z planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SAMPLE DATA SETTINGS**\n",
    "\n",
    "If using the sample data, here are the recommended parameters for each cell type\n",
    "\n",
    "|**Cell type**|dot_scale_1|dot_cut_1|dot_scale_2|dot_cut_2|dot_scale_3|dot_cut_3|dot_method|\n",
    "| :------------------------------------- |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |\n",
    "|Neuron|`1.5`|`0.08`|`0`|`0`|`0`|`0`|`\"3D\"`|\n",
    "|Astrocyte|`1.5`|`0.08`|`0`|`0`|`0`|`0`|`\"3D\"`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "dot_scale_1 = 1.5\n",
    "dot_cut_1 = 0.08\n",
    "\n",
    "dot_scale_2 = 0\n",
    "dot_cut_2 = 0\n",
    "\n",
    "dot_scale_3 = 0\n",
    "dot_cut_3 = 0\n",
    "\n",
    "dot_method = \"3D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block executes the dot filter using the settings above.\n",
    "\n",
    "Use the Napari viewer to iteratively adjust the filter settings as needed. \n",
    "\n",
    "*Hint: it is helpful to adjust the scale/cutoff filters one at a time and then combine them once each pair's settings are confirmed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '3 - Dot filter' at 0x2b422abeda0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the 2D or 3D versions of the AICSsegmentation dot filter with multiple scales\n",
    "bw_dot_test = dot_filter_3(struct_img,\n",
    "                           dot_scale_1,\n",
    "                           dot_cut_1,\n",
    "                           dot_scale_2,\n",
    "                           dot_cut_2,\n",
    "                           dot_scale_3,\n",
    "                           dot_cut_3,\n",
    "                           dot_method)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(bw_dot_test, scale=scale, name=\"3 - Dot filter\", opacity=0.3, colormap=\"cyan\", blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 4` - ‚ÄòFilament‚Äô threshold method (AICSSeg)**\n",
    "\n",
    "&#x1F453; **FYI:** This code block is the second semantic segmentation step that will be combined with the dot filter results.\n",
    "\n",
    "The 'filament' filter is derived from the [`aics-segmentation`](https://github.com/AllenCell/aics-segmentation) package. It utilizes up to three scale (object size) and cutoff (threshold) pairs for objects of different size and intensity. This function is specifically designed to segment filamentous or tubular objects.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the scale and cutoff values for each pair:\n",
    "- `fil_scale_1`: the size scale for the first scale/cutoff pair; larger values correlate to selection of larger objects\n",
    "- `fil_cut_1`: the threshold cutoff value for the first scale/cutoff pair; small cutoffs tend to yield more dots that are larger in volume; larger cutoffs tend to yield less dots that are slimmer.\n",
    "- `fil_scale_2`: the size scale for the second scale/cutoff pair; this can be set to 0 if a second scale/cutoff pair isn't needed\n",
    "- `fil_cut_2`: the threshold cutoff value for the second scale/cutoff pair; this can be set to 0 if a second scale/cutoff pair isn't needed\n",
    "- `fil_scale_3`: the size scale for the third scale/cutoff pair; this can be set to 0 if a third scale/cutoff pair isn't needed\n",
    "- `fil_cut_3`: the threshold cutoff value for the third scale/cutoff pair; this can be set to 0 if a third scale/cutoff pair isn't needed\n",
    "- `fil_method`: \"3D\" processes the image taking into account intensities in three dimensions (XYZ); \"slice-by-slice\" processes each Z-slice in the image separately, not considering any intensity in higher or lower Z planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SAMPLE DATA SETTINGS**\n",
    "\n",
    "If using the sample data, here are the recommended parameters for each cell type\n",
    "\n",
    "|**Cell type**|fil_scale_1|fil_cut_1|fil_scale_2|fil_cut_2|fil_scale_3|fil_cut_3|fil_method|\n",
    "| :------------------------------------- |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |  :------:  |\n",
    "|Neuron|`1`|`0.01`|`0.05`|`0.01`|`0`|`0`|`\"3D\"`|\n",
    "|Astrocyte|`1`|`0.01`|`0.05`|`0.01`|`0`|`0`|`\"3D\"`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "fil_scale_1 = 1\n",
    "fil_cut_1 = 0.01\n",
    "\n",
    "fil_scale_2 = 0.05\n",
    "fil_cut_2 = 0.01\n",
    "\n",
    "fil_scale_3 = 0\n",
    "fil_cut_3 = 0\n",
    "\n",
    "fil_method = \"3D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block executes the filament filter using the settings above.\n",
    "\n",
    "Use the Napari viewer to iteratively adjust the filter settings as needed. \n",
    "\n",
    "*Hint: it is helpful to adjust sellect the scale/cutoff filters one at a time and then combine them once each pair's settings are confirmed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '4 - Filament filter' at 0x2b425be4b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the 2D or 3D versions of the AICSsegmentation filament filter with multiple scales\n",
    "bw_filament_test = filament_filter_3(struct_img,\n",
    "                                    fil_scale_1,\n",
    "                                    fil_cut_1,\n",
    "                                    fil_scale_2,\n",
    "                                    fil_cut_2,\n",
    "                                    fil_scale_3,\n",
    "                                    fil_cut_3,\n",
    "                                    fil_method)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(bw_filament_test, scale=scale, name=\"4 - Filament filter\", opacity=0.3, colormap=\"magenta\", blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 5` - Combine Segmentations**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block combines the dot and filament filter outputs together using the \"logical or\" operation. The resulting semantic segmentation can be viewed in Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '5 - Combined Semantic Segmentation' at 0x2b41c6a67a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two segmentations together\n",
    "bw_test = np.logical_or(bw_dot_test, bw_filament_test)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(bw_test, scale=scale, name=\"5 - Combined Semantic Segmentation\", colormap=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## **POST-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`STEP 6` - Remove small holes and objects**\n",
    "\n",
    "&#x1F453; **FYI:** This code block cleans up the semantic segmentation by filling small holes and/or removing small objects that can be considered errors in the initial segmentation. \n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `hole_min_width`: the width of the smallest hole to be filled\n",
    "- `hole_max_width`: the width of the largest hole to be filled\n",
    "- `small_object_width`: the width of the largest object to be removed; any object smaller than this size will be removed\n",
    "- `fill_filter_method`: \"3D\" processes the image taking into account segmentation values in three dimensions (XYZ); \"slice-by-slice\" processes each Z-slice in the image separately, not considering the segmentation results in higher or lower Z planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SAMPLE DATA SETTINGS**\n",
    "\n",
    "If using the sample data, here are the recommended parameters for each cell type\n",
    "\n",
    "|**Cell type**|hole_min_width|hole_max_width|small_object_width|fill_filter_method|\n",
    "| :------------------------------------- |  :------:  |  :------:  |  :------:  |  :------:  |\n",
    "|Neuron|`0`|`0`|`2`|`\"3D\"`|\n",
    "|Astrocyte|`0`|`0`|`2`|`\"3D\"`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "hole_min_width = 0\n",
    "hole_max_width = 0\n",
    "\n",
    "small_object_width = 2\n",
    "\n",
    "fill_filter_method = \"3D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block fills small holes and removes small objects using the settings above.\n",
    "\n",
    "Use the Napari viewer to iteratively adjust the filter settings as needed. \n",
    "\n",
    "*Hint: white pixels/voxels are the ones remaining after this step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '6 - Fill holes and remove small objects' at 0x2b41b0e3eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill holes and removed small objects\n",
    "cleaned_img2 = fill_and_filter_linear_size(bw_test, \n",
    "                                           hole_min=hole_min_width, \n",
    "                                           hole_max=hole_max_width, \n",
    "                                           min_size=small_object_width,\n",
    "                                           method=fill_filter_method)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(cleaned_img2, scale=scale, name=\"6 - Fill holes and remove small objects\", colormap=\"magenta\", blending=\"additive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## **POST-POST-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 7` - Label objects**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block takes the semantic segmentation and creates an `instance segmentation`. In this output, each individual object in the image is given a unique ID number. The background pixels/voxels are still labeled as 0, but now each pixel/voxel within an object is labeled as a positive integer. Each object is identified by its unique integer.\n",
    "\n",
    "In this workflow objects are separated based on connectivity: if a pixel/voxel is touching another pixel/voxel in any direction, they are considered the same object and each pixel/voxel within that object is labeled as the same unique ID number. \n",
    "\n",
    "*In the Napari viewer, the image is added as a \"labels\" layer where each object appears as a different color.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '7 - Instance segmentation' at 0x2b425194370>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance segmentation based on connectivity\n",
    "mitochondria_labels = label_uint16(cleaned_img2)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_labels(mitochondria_labels, scale=scale, name=\"7 - Instance segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## **SAVING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Saving` - Save the segmentation output**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block saves the instance segmentation output to the `out_data_path` specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome-mito\n",
      "saved to: c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron\\seg\n"
     ]
    }
   ],
   "source": [
    "# Saving file\n",
    "out_file_n = export_inferred_organelle(mitochondria_labels, \"mito\", meta_dict, out_data_path)\n",
    "print(f\"saved to: {out_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## **Define `infer_mito()` function**\n",
    "The following code includes an example of how the workflow steps above are combined into one function. This function can be run below to process a single image. It is included in the [batch process notebook](batch_process_segmentations.ipynb) to run the above analysis on multiple cells. \n",
    "\n",
    "This function can utilized from infer-subc using: \n",
    "```python\n",
    "infer_subc.organelles.mitochondria.infer_mito()\n",
    "```\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block defines the `infer_mito()` function. It is applied below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_mito\n",
    "##########################\n",
    "def _infer_mito(\n",
    "                in_img: np.ndarray,\n",
    "                mito_ch: int,\n",
    "                median_sz: int,\n",
    "                gauss_sig: float,\n",
    "                dot_scale_1: float,\n",
    "                dot_cut_1: float,\n",
    "                dot_scale_2: float,\n",
    "                dot_cut_2: float,\n",
    "                dot_scale_3: float,\n",
    "                dot_cut_3: float,\n",
    "                dot_method: str,\n",
    "                fil_scale_1: float,\n",
    "                fil_cut_1: float,\n",
    "                fil_scale_2: float, \n",
    "                fil_cut_2: float, \n",
    "                fil_scale_3: float, \n",
    "                fil_cut_3: float,\n",
    "                fil_method: str,\n",
    "                min_hole_w: int,\n",
    "                max_hole_w: int,\n",
    "                small_obj_w: int,\n",
    "                fill_filter_method: str\n",
    "                ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img:\n",
    "        a 3d image containing all the channels\n",
    "    median_sz: \n",
    "        width of median filter for signal\n",
    "    gauss_sig: \n",
    "        sigma for gaussian smoothing of  signal\n",
    "    vesselness_scale: \n",
    "        scale (log_sigma) for vesselness filter\n",
    "    vesselness_cut: \n",
    "        threshold for vesselness fitered threshold\n",
    "    small_obj_w: \n",
    "        minimu object size cutoff for nuclei post-processing\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    mito_object\n",
    "        mask defined extent of mitochondria object\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################    \n",
    "    mito = select_channel_from_raw(in_img, mito_ch)\n",
    "    \n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    mito =  scale_and_smooth(mito,\n",
    "                             median_size = median_sz, \n",
    "                             gauss_sigma = gauss_sig)\n",
    "    ###################   \n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    bw_dot = dot_filter_3(mito, dot_scale_1, dot_cut_1, dot_scale_2, dot_cut_2, dot_scale_3, dot_cut_3, dot_method)\n",
    "\n",
    "    bw_filament = filament_filter_3(mito, fil_scale_1, fil_cut_1, fil_scale_2, fil_cut_2, fil_scale_3, fil_cut_3, fil_method)\n",
    "\n",
    "    bw = np.logical_or(bw_dot, bw_filament)\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    struct_obj = fill_and_filter_linear_size(bw, \n",
    "                                             hole_min=min_hole_w, \n",
    "                                             hole_max=max_hole_w, \n",
    "                                             min_size=small_obj_w,\n",
    "                                             method=fill_filter_method)\n",
    "\n",
    "    ###################\n",
    "    # LABELING\n",
    "    ###################\n",
    "    struct_obj1 = label_uint16(struct_obj)\n",
    "\n",
    "    return struct_obj1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block applies the function above to your test image. The settings specified above are applied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _mito_object \u001b[38;5;241m=\u001b[39m  \u001b[43m_infer_mito\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMITO_CH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmed_filter_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgaussian_smoothing_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_scale_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_cut_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_scale_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_cut_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_scale_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_cut_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdot_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_scale_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_cut_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_scale_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_cut_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_scale_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_cut_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfil_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhole_min_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhole_max_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmall_object_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_filter_method\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#confirm this output matches the output saved above\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe segmentation output here matches the output created above: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mall(mitochondria_labels\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m_mito_object)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 69\u001b[0m, in \u001b[0;36m_infer_mito\u001b[1;34m(in_img, mito_ch, median_sz, gauss_sig, dot_scale_1, dot_cut_1, dot_scale_2, dot_cut_2, dot_scale_3, dot_cut_3, dot_method, fil_scale_1, fil_cut_1, fil_scale_2, fil_cut_2, fil_scale_3, fil_cut_3, fil_method, min_hole_w, max_hole_w, small_obj_w, fill_filter_method)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m###################   \u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# CORE_PROCESSING\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[0;32m     67\u001b[0m bw_dot \u001b[38;5;241m=\u001b[39m dot_filter_3(mito, dot_scale_1, dot_cut_1, dot_scale_2, dot_cut_2, dot_scale_3, dot_cut_3, dot_method)\n\u001b[1;32m---> 69\u001b[0m bw_filament \u001b[38;5;241m=\u001b[39m \u001b[43mfilament_filter_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmito\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_scale_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_cut_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_scale_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_cut_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_scale_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_cut_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m bw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_or(bw_dot, bw_filament)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# POST_PROCESSING\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\infer_subc\\core\\img.py:1001\u001b[0m, in \u001b[0;36mfilament_filter_3\u001b[1;34m(in_img, filament_scale_1, filament_cutoff_1, filament_scale_2, filament_cutoff_2, filament_scale_3, filament_cutoff_3, method)\u001b[0m\n\u001b[0;32m    998\u001b[0m f_param \u001b[38;5;241m=\u001b[39m [[sc, ct] \u001b[38;5;28;01mfor\u001b[39;00m sc, ct \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(scales, cuts) \u001b[38;5;28;01mif\u001b[39;00m sc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3D\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1001\u001b[0m     seg \u001b[38;5;241m=\u001b[39m \u001b[43mfilament_3d_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_by_slice\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1003\u001b[0m     seg \u001b[38;5;241m=\u001b[39m filament_2d_wrapper(in_img, f_param)\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-sc\\lib\\site-packages\\aicssegmentation\\core\\vessel.py:36\u001b[0m, in \u001b[0;36mfilament_3d_wrapper\u001b[1;34m(struct_img, f3_param)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(f3_param)):\n\u001b[0;32m     35\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m f3_param[fid][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 36\u001b[0m     eigenvalues \u001b[38;5;241m=\u001b[39m \u001b[43mabsolute_3d_hessian_eigenvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstruct_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhiteonblack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     responce \u001b[38;5;241m=\u001b[39m compute_vesselness3D(eigenvalues[\u001b[38;5;241m1\u001b[39m], eigenvalues[\u001b[38;5;241m2\u001b[39m], tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m     bw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_or(bw, responce \u001b[38;5;241m>\u001b[39m f3_param[fid][\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-sc\\lib\\site-packages\\aicssegmentation\\core\\hessian.py:100\u001b[0m, in \u001b[0;36mabsolute_3d_hessian_eigenvalues\u001b[1;34m(nd_array, sigma, scale, whiteonblack)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabsolute_3d_hessian_eigenvalues\u001b[39m(\n\u001b[0;32m     75\u001b[0m     nd_array: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     76\u001b[0m     sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     77\u001b[0m     scale: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     78\u001b[0m     whiteonblack: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     79\u001b[0m ):\n\u001b[0;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    Eigenvalues of the hessian matrix calculated from the input array sorted by\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    absolute value.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    list of eigenvalues [eigenvalue1, eigenvalue2, ...]\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m absolute_eigenvaluesh(\n\u001b[1;32m--> 100\u001b[0m         \u001b[43mcompute_3d_hessian_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnd_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhiteonblack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhiteonblack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-sc\\lib\\site-packages\\aicssegmentation\\core\\hessian.py:70\u001b[0m, in \u001b[0;36mcompute_3d_hessian_matrix\u001b[1;34m(nd_array, sigma, scale, whiteonblack)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m hessian_full:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# print(row.shape)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     hessian_rows\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mstack(row, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 70\u001b[0m hessian \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhessian_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hessian\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-sc\\lib\\site-packages\\numpy\\core\\shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[0;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_mito_object =  _infer_mito(  \n",
    "        img_data,\n",
    "        MITO_CH,\n",
    "        med_filter_size,\n",
    "        gaussian_smoothing_sigma,\n",
    "        dot_scale_1,\n",
    "        dot_cut_1,\n",
    "        dot_scale_2,\n",
    "        dot_cut_2,\n",
    "        dot_scale_3,\n",
    "        dot_cut_3,\n",
    "        dot_method,\n",
    "        fil_scale_1,\n",
    "        fil_cut_1,\n",
    "        fil_scale_2,\n",
    "        fil_cut_2,\n",
    "        fil_scale_3,\n",
    "        fil_cut_3,\n",
    "        fil_method,\n",
    "        hole_min_width,\n",
    "        hole_max_width,\n",
    "        small_object_width,\n",
    "        fill_filter_method) \n",
    "\n",
    "#confirm this output matches the output saved above\n",
    "print(f\"The segmentation output here matches the output created above: {np.all(mitochondria_labels == _mito_object)}\")\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_labels(_mito_object, scale=scale, name=\"infer_mito() output\")\n",
    "viewer.grid.enabled = True\n",
    "viewer.reset_view()\n",
    "\n",
    "# screenshot viewer\n",
    "nbscreenshot(viewer, canvas_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### ‚úÖ **INFER MITOCHONDRIA COMPLETE!**\n",
    "\n",
    "Continue on to other notebooks as needed:\n",
    "- Infer [`lysosome`](1.2_infer_lysosome.ipynb)\n",
    "- Infer [`golgi`](1.4_infer_golgi.ipynb)\n",
    "- Infer [`peroxisomes`](1.5_infer_peroxisome.ipynb)\n",
    "- Infer [`endoplasmic reticulum (ER)`](1.6_infer_ER.ipynb)\n",
    "- Infer [`lipid droplets`](1.7_infer_lipid_droplet.ipynb)\n",
    "\n",
    "Or proceed to batch processing here: [batch process notebook](batch_process_segmentations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
