{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e04594",
   "metadata": {},
   "source": [
    "# **Infer `Cellmask` and `Nucleus`**\n",
    "\n",
    "***Prior to this notebook, you should have already run through [1.0_image_setup](1.0_image_setup.ipynb).***\n",
    "\n",
    "### ‚û°Ô∏è **Input:**\n",
    "In this workflow, a single or multi-channel confocal microscopy image of fluorescently tagged organelles will be used to \"infer\" (or segment) the cell and nucleus masks. The following setup is recommended for this pipeline:\n",
    "\n",
    "| **Imaging Requirements**|[**Masks Workflow (C)**](./1.1c_infer_masks_from-composite_neuron_with_pm.ipynb)|\n",
    "| :------------------------------------- |  :------:  |\n",
    "| Nuclei Marker                          |     ‚úî     |\n",
    "| Cell Membrane Marker                   |     ‚úî     |\n",
    "| Cytoplasmic Organelles                 |      ‚úî     |\n",
    "| Number of cells per image              |  Single or Multiple |\n",
    "| Applicable with sample data         | Neuron_2|\n",
    "\n",
    "*If your images are not compatible with this setup, consider the other 1.1_Masks Workflows available:*\n",
    "\n",
    "| **Imaging Requirements**|[**Masks Workflow**](./1.1_infer_masks_from-composite_with_nuc.ipynb)|[**Masks Workflow (A)**](./1.1a_infer_masks_from-composite_single_cell.ipynb)|[**Masks Workflow (B)**](./1.1b_infer_masks_from-composite_multiple-cells.ipynb)|\n",
    "| :------------------------------------- |  :------:  |  :------:  |  :------:  |\n",
    "| Nuclei Marker                          |     ‚úî     |      ‚úò     |     ‚úò     |\n",
    "| Cell Membrane Marker                   |     ‚úò     |      ‚úò     |     ‚úò     |\n",
    "| Cytoplasmic Organelles                 |     ‚úî     |      ‚úî     |     ‚úî     |\n",
    "| Number of cells per image              |  Single or Multiple  |   Single   |  Multiple |\n",
    "| Applicable with sample data         |  ‚úò  |   Neuron_1   |  Astrocyte |\n",
    "\n",
    "### **Included in this Notebook:**\n",
    "1. **Infer *nucleus*** - Segment the ***nucleus*** from a single channel (nuclei) and sum of intensities of the search image. This will be necessary to determine the other subcellular compartments - like the ***cytoplasm***. Nuclei will also be used to seed the instance segmentation of the ***cell*** area (***cellmask***).\n",
    "\n",
    "2. **Infer *cellmask*** - Segment the cell area (the ***cellmask***) from a composite image of multiple organelle markers and the ***nucleus***. The **cellmask** will be necessary for determining which organelles are in which cell\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6344f",
   "metadata": {},
   "source": [
    "### üë£ **Summary of steps**  \n",
    "\n",
    "‚û°Ô∏è **EXTRACTION**\n",
    "- **`STEP 1`** - Create composite image - I\n",
    "\n",
    "    - determine weight to apply to each channel of the intensity image (w# = user input)\n",
    "    - choose whether to invert plasma membrane or not (invert_PM = user input)\n",
    "    - select plasma membrane channel (pm_channel = user input)\n",
    "\n",
    "- **`STEP 2`** - Create composite image - II\n",
    "\n",
    "    - determine weight to apply to each channel of the intensity image (w# = user input)\n",
    "    - choose whether to invert plasma membrane or not (invert_PM = user input)\n",
    "    - select plasma membrane channel (pm_Channel = user input)\n",
    "\n",
    "**PRE-PROCESSING**\n",
    "- **`STEP 3`** - Close gaps and apply filters ‚Äì I\n",
    "\n",
    "    - apply closing algorithm or scharr edge detection (method = user input)\n",
    "    - set the footprint size for the closing algorithm (size = user input)\n",
    "    \n",
    "- **`STEP 4`** - Close gaps and apply filters ‚Äì II\n",
    "\n",
    "    - apply closing algorithm or scharr edge detection (method = user input)\n",
    "    - set the footprint size for the closing algorithm (size = user input)\n",
    " \n",
    "**CORE PROCESSING**\n",
    "- **`STEP 5`** - Threshold object and restrict to PM - I\n",
    "\n",
    "    - apply MO thresholding method from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (threshold options = user input)\n",
    "    - bind resulting segmentation (I) to inverted plasma membrane\n",
    "\n",
    "- **`STEP 6`** - Threshold object and restrict to PM - II\n",
    "\n",
    "    - apply MO thresholding method from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (threshold options = user input)\n",
    "    - bind resulting segmentation (II) to inverted plasma membrane\n",
    "\n",
    "**POST-PROCESSING**\n",
    "- **`STEP 7`** - Find the nucleus corresponding to the cell\n",
    "\n",
    "    - (A) select single channel containing the nuclei marker (channel number = user input)\n",
    "    - (B) rescale intensity of composite image (min=0, max=1); apply median (median size = user input) and gaussian filter (sigma = user input)\n",
    "    - (C) log transform image and calculate Li's minimum cross entropy threshold value; apply threshold to image (thresholding options = user input)\n",
    "    - (D) fill holes (hole size = user input) and remove small objects (object size = user input)\n",
    "    - (E) label nuclei objects\n",
    "    - (F) use search image to select single nucleus\n",
    "\n",
    "- **`STEP 8`** - Combine nucleus and thresh and fill holes - I\n",
    "\n",
    "    - select the type of footprint to be used in nucleus dilation (method = user input)\n",
    "    - set the footprint size for nucleus dilation (size = user input)\n",
    "    - fill holes (hole size = user input)\n",
    "    - remove small objects (object size = user input)\n",
    "    - combine nucleus and mask_I\n",
    "\n",
    "- **`STEP 9`** - Combine nucleus and thresh and fill holes - II\n",
    "\n",
    "    - select the type of footprint to be used in nucleus dilation (method = user input)\n",
    "    - set the footprint size for nucleus dilation (size = user input)\n",
    "    - fill holes (hole size = user input)\n",
    "    - remove small objects (object size = user input)\n",
    "    - combine nucleus and mask_II\n",
    "\n",
    "**POST-POST-PROCESSING**\n",
    "- **`STEP 10`** - Watershed for cellmask\n",
    "\n",
    "    - perform water-shedding algorithm on mask_I and mask_II using the nucleus as the seed (watershed_method = user input)\n",
    "    - combine resulting segmentations for rough cellmask\n",
    "    - apply binary closing to rough cellmask, dilation -> erosion (method = user input)\n",
    "    - set the footprint size for nucleus dilation (size = user input)\n",
    "    - fill holes (hole size = user input)\n",
    "\n",
    "**OUTPUT** ‚û°Ô∏è \n",
    "- **`STEP 11`** - Stack masks\n",
    "\n",
    "    - Stack masks in order of nucleus, then cellmask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f8a19",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## **IMPORTS AND LOAD IMAGE**\n",
    "Details about the functions included in this subsection are outlined in the [`1.0_image_setup`](1.0_image_setup.ipynb) notebook. Please visit that notebook first if you are confused about any of the code included here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed978c0",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36252474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image, \n",
    "                                     export_inferred_organelle,\n",
    "                                     list_image_files,\n",
    "                                     sample_input)\n",
    "from infer_subc.core.img import *\n",
    "from infer_subc.organelles.membrane import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ec976",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following information about your data: `im_type`, `data_root_path`, `in_data_path`, and `out_data_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dec6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "# If using the sample data, set cell_type to \"neuron_2\":\n",
    "# If not using the sample data, set cell_type to None\n",
    "sample_data_type = \"neuron_2\"\n",
    "\n",
    "# If you are not using the sample data, please edit \"USER SPECIFIED\" as necessary.\n",
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(\"USER SPECIFIED\")\n",
    "\n",
    "# Specify the file type of your raw data that will be analyzed. Ex) \".czi\" or \".tiff\"\n",
    "im_type = \"USER SPECIFIED\"\n",
    "\n",
    "## Specify which subfolder that contains the input data and the input data file extension\n",
    "in_data_path = data_root_path / \"USER SPECIFIED\"\n",
    "\n",
    "## Specify the output folder to save the segmentation outputs if.\n",
    "## If its not already created, the code below will creat it for you\n",
    "out_data_path = data_root_path / \"USER SPECIFIED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bcf9f",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb5edf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron_2\\raw\\20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   Image Name\n",
       "0  c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron_2\\raw\\20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome.tiff"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If sample_data_type is set \"neuron\", then the sample data is used and the directories are set\n",
    "if sample_data_type != None:\n",
    "    data_root_path, im_type, in_data_path, out_data_path = sample_input(sample_data_type)\n",
    "\n",
    "# list files in the input folder\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dba4a7",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Use the list above to specify which image you wish to analyze based on its index: `test_img_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a99eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "test_img_n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e73bed",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b060790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata information\n",
      "File path: c:\\Users\\redre\\Documents\\CohenLab\\scohen_lab_repo\\infer-subc\\sample_data\\example_neuron_2\\raw\\20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome.tiff\n",
      "Channel 0 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:0\n",
      "Channel 1 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:1\n",
      "Channel 2 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:2\n",
      "Channel 3 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:3\n",
      "Channel 4 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:4\n",
      "Channel 5 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:5\n",
      "Channel 6 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:6\n",
      "Channel 7 name: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome :: Channel:7\n",
      "Scale (ZYX): (0.389118, 0.07064, 0.07064)\n",
      "Channel axis: 0\n",
      "\n",
      "Proceed to Napari window to view your selected image.\n"
     ]
    }
   ],
   "source": [
    "# load image and metadata\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# metadata\n",
    "channel_names = meta_dict['name']\n",
    "meta = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "file_path = meta_dict['file_name']\n",
    "print(\"Metadata information\")\n",
    "print(f\"File path: {file_path}\")\n",
    "for i in list(range(len(channel_names))):\n",
    "    print(f\"Channel {i} name: {channel_names[i]}\")\n",
    "print(f\"Scale (ZYX): {scale}\")\n",
    "print(f\"Channel axis: {channel_axis}\")\n",
    "\n",
    "# open viewer and add images\n",
    "viewer = napari.Viewer()\n",
    "for i in list(range(len(channel_names))):\n",
    "    viewer.add_image(img_data[i],\n",
    "                     scale=scale,\n",
    "                     name=f\"Channel {i}\")\n",
    "viewer.grid.enabled = True\n",
    "viewer.reset_view()\n",
    "print(\"\\nProceed to Napari window to view your selected image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94a719",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## **masks_C**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d94c6e5",
   "metadata": {},
   "source": [
    "The **masks_C** workflow operates by running two parallel linear sequences and combines their outputs to produce a **cellmask** and **nucleus** segmentation. The aspects of the cell that each linear sequence captures are at the discretion of the user. **`Steps 7`** and **`10`** produce the **nucleus** and **cellmask** segmentation respectfully, using output from both sequences. However, **`step 7`** (nucleus) uses output from either **`step 5`** or **`step 6`**, this will be explained in detail later in the notebook. To end the workflow, **`step 11`** exports the **nucleus** and **cellmask**. Below is a basic diagram which visualizes the structure of the masks_C workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa2ca3",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "\n",
    "masks_C workflow\n",
    "\n",
    "         Sequence I                   Export\n",
    "         \n",
    "         1 --‚Üí 3 --‚Üí 5 --‚Üí 8            7\n",
    "       ‚Üó             ‚áò  ‚Üó   ‚Üò           ‚Üò\n",
    "    0 <                7      10           > 11\n",
    "       ‚Üò             ‚áó  ‚Üò   ‚Üó           ‚Üó\n",
    "         2 --‚Üí 4 --‚Üí 6 --‚Üí 9           10\n",
    "         \n",
    "         Sequence II\n",
    "\n",
    "\n",
    "0 - raw image\n",
    "1 - composite image I\n",
    "2 - composite image II\n",
    "3 - composite mask_I\n",
    "4 - composite mask_II\n",
    "5 - mask_I segmentation\n",
    "6 - mask_II segmentation\n",
    "7 - nucleus segmentation\n",
    "8 - cellmask_I segmentation\n",
    "9 - cellmask_II segmentation\n",
    "10 - cellmask segmentation\n",
    "11 - mask_C Segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f5a19",
   "metadata": {},
   "source": [
    ">\n",
    ">**If using the Sample Data üìÇ**:\n",
    ">\n",
    ">The steps ending in **I** refer to the sequence of steps that focus on capturing the cell's outer edges. By contrast, the steps ending in **II** refer to the sequence of steps that focus on capturing the interior of the cell. By detecting different regions of the cell, the quality of the comprehensive cellmask segmentation is improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef7b8f",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## **EXTRACTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97820e",
   "metadata": {},
   "source": [
    "### **`STEP 1` - Create composite image - I**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates the **first** composite image of the organelle channels. The intensity of each channel is combined with specified weights.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `Invert_PM`: \"True\" inverts the intensities of the plasma membrane channel when added to the composite image; \"False\" leaves the intensity values as is when added to the composite image\n",
    "- `PM_channel`: the index of the channel containing your plasma membrane label. Image indexing begins with 0, not 1. Reference the channel numbers indicated in the Napari window for easy reference.\n",
    "- `weight_ch0`: the weight of channel 0 (the first channel); a value of 0 will exclude this channel from the compostite; large values will cause this channel to be more prominent in the final composite image\n",
    "- `weight_ch1`: the weight of channel 1\n",
    "- `weight_ch2`: the weight of channel 2\n",
    "- `weight_ch3`: the weight of channel 3\n",
    "- `weight_ch4`: the weight of channel 4\n",
    "- `weight_ch5`: the weight of channel 5\n",
    "- `weight_ch6`: the weight of channel 6\n",
    "- `weight_ch7`: the weight of channel 7\n",
    "- `weight_ch8`: the weight of channel 8\n",
    "- `weight_ch9`: the weight of channel 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae8b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "invert_pm_I = True\n",
    "pm_chan = 5\n",
    "w0_I = 20\n",
    "w1_I = 10\n",
    "w2_I = 5\n",
    "w3_I = 15\n",
    "w4_I = 12\n",
    "w5_I = 15\n",
    "w6_I = 0\n",
    "w7_I = 0\n",
    "w8_I= 0\n",
    "w9_I = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2bb9f",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates the composite and optionally rescales the image based on the settings above. The image is then added to Napari as a new layer for visual comparison to the input image. \n",
    "\n",
    "Use the Napari viewer to iteratively adjust the weights selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a566bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '1-Cell: Create composite I' at 0x273ff752a10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make aggregate and optionally rescale\n",
    "struct_img_raw_I = membrane_composite(img_data,\n",
    "                                weight_ch0= w0_I,\n",
    "                                weight_ch1= w1_I,\n",
    "                                weight_ch2= w2_I,\n",
    "                                weight_ch3= w3_I,\n",
    "                                weight_ch4= w4_I,\n",
    "                                weight_ch5= w5_I,\n",
    "                                weight_ch6= w6_I,\n",
    "                                weight_ch7= w7_I,\n",
    "                                weight_ch8= w8_I,\n",
    "                                weight_ch9= w9_I,\n",
    "                                Invert_PM = invert_pm_I,\n",
    "                                PM_Channel = pm_chan)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.layers.clear()\n",
    "viewer.grid.enabled = False\n",
    "viewer.reset_view()\n",
    "viewer.add_image(img_data, scale=scale)\n",
    "viewer.add_image(struct_img_raw_I, scale=scale, name=\"1-Cell: Create composite I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab7640",
   "metadata": {},
   "source": [
    "### **`STEP 2` - Create composite image - II**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates the **second** composite image of the organelle channels. The intensity of each channel is combined with specified weights.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `Invert_PM`: \"True\" inverts the intensities of the plasma membrane channel when added to the composite image; \"False\" leaves the intensity values as is when added to the composite image\n",
    "- `PM_channel`: the index of the channel containing your plasma membrane label. Image indexing begins with 0, not 1. Reference the channel numbers indicated in the Napari window for easy reference.\n",
    "- `weight_ch0`: the weight of channel 0 (the first channel); a value of 0 will exclude this channel from the compostite; large values will cause this channel to be more prominent in the final composite image\n",
    "- `weight_ch1`: the weight of channel 1\n",
    "- `weight_ch2`: the weight of channel 2\n",
    "- `weight_ch3`: the weight of channel 3\n",
    "- `weight_ch4`: the weight of channel 4\n",
    "- `weight_ch5`: the weight of channel 5\n",
    "- `weight_ch6`: the weight of channel 6\n",
    "- `weight_ch7`: the weight of channel 7\n",
    "- `weight_ch8`: the weight of channel 8\n",
    "- `weight_ch9`: the weight of channel 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d93d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "# Variables are named differently to avoid overwriting Step 1 variables\n",
    "invert_pm_II = False\n",
    "pm_chan = 5\n",
    "w0_II = 20\n",
    "w1_II = 10\n",
    "w2_II = 5\n",
    "w3_II = 15\n",
    "w4_II = 12\n",
    "w5_II = 0\n",
    "w6_II = 0\n",
    "w7_II = 0\n",
    "w8_II = 0\n",
    "w9_II = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aafb6c",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates the composite and optionally rescales the image based on the settings above. The image is then added to Napari as a new layer for visual comparison to the input image. \n",
    "\n",
    "Use the Napari viewer to iteratively adjust the weights selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b192604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '2-Cell: Create composite II' at 0x27386913a00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make aggregate and optionally rescale\n",
    "struct_img_raw_II = membrane_composite(img_data,\n",
    "                                weight_ch0= w0_II,\n",
    "                                weight_ch1= w1_II,\n",
    "                                weight_ch2= w2_II,\n",
    "                                weight_ch3= w3_II,\n",
    "                                weight_ch4= w4_II,\n",
    "                                weight_ch5= w5_II,\n",
    "                                weight_ch6= w6_II,\n",
    "                                weight_ch7= w7_II,\n",
    "                                weight_ch8= w8_II,\n",
    "                                weight_ch9= w9_II,\n",
    "                                Invert_PM = invert_pm_II,\n",
    "                                PM_Channel = pm_chan)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(struct_img_raw_II, scale=scale, name=\"2-Cell: Create composite II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d831052",
   "metadata": {},
   "source": [
    "-----\n",
    "## **PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e9267",
   "metadata": {},
   "source": [
    "### **`STEP 3` - Close gaps and apply filters ‚Äì I**\n",
    "\n",
    "&#x1F453; **FYI:** Based on the selected method, this step can either apply a closing algorithm (dilate -> erode) to remove small holes and cracks, or apply a log transform and [Scharr](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.scharr) edge dectection . If Method = `\"Ball\"` or `\"Disk\"`, then a closing algorithm will be performed on the composite I image using the footprint specified by the method. If Method = `\"Scharr\"`, then the log-transformation and [Scharr](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.scharr) edge detection is applied to the composite I image. This also means that the `size` parameter is disregarded.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the amount of filter to use for each method. Higher values indicate more smoothing:\n",
    "- `Method`: \"Ball\" or \"Disk\" applies the closing algorithm, \"Scharr\" applies Scharr edge detection\n",
    "- `Size`: size of the footprint used in the closing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d3a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "method_I = \"Disk\"\n",
    "size_I = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c2ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '3-Cell: Closing/Scharr I' at 0x27380594580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply closing or the scharr edge detection filter\n",
    "composite_mask_I = close_and_filter(struct_img_raw_I,\n",
    "                                    Method = method_I,\n",
    "                                    Size = size_I)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(composite_mask_I, scale=scale, name=\"3-Cell: Closing/Scharr I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6c0e2",
   "metadata": {},
   "source": [
    "### **`STEP 4` - Close gaps and apply filters ‚Äì II**\n",
    "\n",
    "&#x1F453; **FYI:** Based on the selected method, this step can either apply a closing algorithm (dilate -> erode) to remove small holes and cracks, or apply a log transform and [Scharr](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.scharr) edge dectection . If Method = `\"Ball\"` or `\"Disk\"`, then a closing algorithm will be performed on the composite II image using the footprint specified by the method. If Method = `\"Scharr\"`, then the log-transformation and [Scharr](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.scharr) edge detection is applied to the composite II image. This also means that the `size` parameter is disregarded.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the amount of filter to use for each method. Higher values indicate more smoothing:\n",
    "- `Method`: \"Ball\" or \"Disk\" applies the closing algorithm, \"Scharr\" applies Scharr edge detection\n",
    "- `Size`: size of the footprint used in the closing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ebbd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "method_II = \"Scharr\"\n",
    "size_II = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f46c395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '4-Cell: Closing/Scharr II' at 0x273feedbee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply closing or the scharr edge detection filter\n",
    "composite_mask_II = close_and_filter(struct_img_raw_II,\n",
    "                                    Method = method_II,\n",
    "                                    Size = size_II)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(composite_mask_I, scale=scale, name=\"4-Cell: Closing/Scharr II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf9b74",
   "metadata": {},
   "source": [
    "-----\n",
    "## **CORE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb06ea",
   "metadata": {},
   "source": [
    "### **`STEP 5` - Threshold object and restrict to PM - I**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates a semantic segmentation of the cell area. `Semantic segmentation` is the process of deciding whether a pixel/voxel should be included in an object (labeled with a value of 1) or should be considered as part of the background (labeled with a value of 0). When performed on the output of Step 3, this results in the mask_I segmentation. A semantic segmentation does not discern individual objects from one another.\n",
    "\n",
    "The masked_object_filter utilizes the 'MO' filter from the [`aics-segmentation`](https://github.com/AllenCell/aics-segmentation) package. AICS documentation states: \"The algorithm is a hybrid thresholding method combining two levels of thresholds. The steps are: [1] a global threshold is calculated, [2] extract each individual connected componet after applying the global threshold, [3] remove small objects, [4] within each remaining object, a local Otsu threshold is calculated and applied with an optional local threshold adjustment ratio (to make the segmentation more and less conservative). An extra check can be used in step [4], which requires the local Otsu threshold larger than 1/3 of global Otsu threhsold and otherwise this connected component is discarded.\"\n",
    "\n",
    "If Bind_To_PM = `\"True\"`, the plasma membrane channel can be log-transformed and have an Otsu threshold can be applied to it to produce a plasma membrane segmentation. This can then be inverted and combined with the intial mask_I segmentation to create a mask_I segmentation that is restrict to the plasma membrane boundary. If Bind_To_PM = `\"False\"`, this additional step is skipped.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "- `global_method`: the type of thresholding method to be performed globally (MO)\n",
    "- `cutoff_size`: the minimum object size to advance to the local thresholding step (MO)\n",
    "- `local_adjust`: the ratio applied to the local Otsu threshold (MO)\n",
    "- `Bind_To_PM`: Whether to restrict the mask_I segmentation to the inverted plasma membrane segmentation\n",
    "- `PM_Channel`: the index of the plasma membrane channel (Please note that the first channel is indexed as 0)\n",
    "- `Thresh_Adj`: The ratio applied to the Otsu threshold of the plasma membrane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2e0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "global_method_I = \"triangle\"\n",
    "cutoff_size_I = 413\n",
    "local_adj_I = 0.533\n",
    "bind_to_pm_I = False\n",
    "pm_chan = 5\n",
    "thresh_adj_I = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff0da2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '5-Cell: MO Thresholding I' at 0x273fca66590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mask I segmentation (optional to bind to plasma membrane)\n",
    "mask_I_segmentation = masked_object_thresh_bind_pm(\n",
    "    img_data,\n",
    "    composite_mask_I,\n",
    "    Global_Method = global_method_I,\n",
    "    Cutoff_Size = cutoff_size_I,\n",
    "    Local_Adjust = local_adj_I,\n",
    "    Bind_to_PM = bind_to_pm_I,\n",
    "    PM_Channel = pm_chan,\n",
    "    Thresh_Adj = thresh_adj_I)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(mask_I_segmentation, scale=scale, name=\"5-Cell: MO Thresholding I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ed332",
   "metadata": {},
   "source": [
    "### **`STEP 6` - Threshold object and restrict to PM - II**\n",
    "\n",
    "&#x1F453; **FYI:** This code block creates a semantic segmentation of the cell area. `Semantic segmentation` is the process of deciding whether a pixel/voxel should be included in an object (labeled with a value of 1) or should be considered as part of the background (labeled with a value of 0). When performed on the output of Step 4, this results in the mask_II segmentation. A semantic segmentation does not discern individual objects from one another.\n",
    "\n",
    "The masked_object_filter utilizes the 'MO' filter from the [`aics-segmentation`](https://github.com/AllenCell/aics-segmentation) package. AICS documentation states: \"The algorithm is a hybrid thresholding method combining two levels of thresholds. The steps are: [1] a global threshold is calculated, [2] extract each individual connected componet after applying the global threshold, [3] remove small objects, [4] within each remaining object, a local Otsu threshold is calculated and applied with an optional local threshold adjustment ratio (to make the segmentation more and less conservative). An extra check can be used in step [4], which requires the local Otsu threshold larger than 1/3 of global Otsu threhsold and otherwise this connected component is discarded.\"\n",
    "\n",
    "If Bind_To_PM = `\"True\"`, the plasma membrane channel can be log-transformed and have an Otsu threshold can be applied to it to produce a plasma membrane segmentation. This can then be inverted and combined with the intial mask_II segmentation to create a mask_II segmentation that is restrict to the plasma membrane boundary. If Bind_To_PM = `\"False\"`, this additional step is skipped.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "- `global_method`: the type of thresholding method to be performed globally (MO)\n",
    "- `cutoff_size`: the minimum object size to advance to the local thresholding step (MO)\n",
    "- `local_adjust`: the ratio applied to the local Otsu threshold (MO)\n",
    "- `Bind_To_PM`: Whether to restrict the mask_II segmentation to the inverted plasma membrane segmentation\n",
    "- `PM_Channel`: the index of the plasma membrane channel (Please note that the first channel is indexed as 0)\n",
    "- `Thresh_Adj`: The ratio applied to the Otsu threshold of the plasma membrane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75578f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "global_method_II = \"ave_tri_med\"\n",
    "cutoff_size_II = 787\n",
    "local_adj_II = 1.0\n",
    "bind_to_pm_II = True\n",
    "pm_chan = 5\n",
    "thresh_adj_II = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3da5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '6-Cell: MO Thresholding II' at 0x27388edace0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mask I segmentation (optional to bind to plasma membrane)\n",
    "mask_II_segmentation = masked_object_thresh_bind_pm(\n",
    "    img_data,\n",
    "    composite_mask_II,\n",
    "    Global_Method = global_method_II,\n",
    "    Cutoff_Size = cutoff_size_II,\n",
    "    Local_Adjust = local_adj_II,\n",
    "    Bind_to_PM = bind_to_pm_II,\n",
    "    PM_Channel = pm_chan,\n",
    "    Thresh_Adj = thresh_adj_II)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(mask_II_segmentation, scale=scale, name=\"6-Cell: MO Thresholding II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b62ab8",
   "metadata": {},
   "source": [
    "-----\n",
    "## **POST-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc5227",
   "metadata": {},
   "source": [
    "### **`STEP 7` - Find the nucleus corresponding to the cell**\n",
    "\n",
    "&#x1F453; **FYI:** This step creates a semantic segmentation of the nucleus using the nuclei channel. First the nuclei intensities are blurred and then log transformed, leading to a nuclei segmentation using [Li's Minimum Cross Entropy](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_li) method. If there are multiple nuclei objects, then a search image is used to determine which nucleus is the target. The Search_Img can be set to `\"Img 5\"` (mask_I segmentation) or `\"Img 6\"` (mask_II segmentation). The nucleus label with the most overlap with the search image is selected as the nucleus object.\n",
    "\n",
    "#### **`A. Select channel`**\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify which channel includes your nuclei label:\n",
    "- `NUC_CH`: the index of the channel containing your nuclei label. Image indexing begins with 0, not 1. Reference the channel numbers indicated in the Napari window for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770f12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "NUC_CH = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08017508",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block extracts the nuclei channel from your multi-channel image. It will be the only part of the image used in the rest of this workflow. The single nuclei channel is added to the Napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b31081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '7-Nuc: Extract Channel' at 0x273fd140dc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select channel\n",
    "raw_nuclei = select_channel_from_raw(img_data, NUC_CH)\n",
    "\n",
    "# add single channel as a new layer\n",
    "viewer.add_image(raw_nuclei, scale=scale, name=\"7-Nuc: Extract Channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd47ae",
   "metadata": {},
   "source": [
    "#### **`B. Rescale and smooth image`**\n",
    "\n",
    "&#x1F453; **FYI:** This code block rescales the image so that the pixel/voxel with the highest intensity is set to 1 and the one with the lowest intensity is set to 0. The image is then *optionally* smoothed using a Gaussian and/or median filter. \n",
    "\n",
    "<mark> Include more information on the Gaussian and median filtering methods here </mark>\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the amount of filter to use for each method. Higher values indicate more smoothing:\n",
    "- `med_filter_size`: the size of the median filter to apply; if 0 is used, no filter will be applied\n",
    "- `gaussian_smoothing_sigma`: the sigma to apply in the Gaussian filtering step; if 0 is used, no filter will be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf8a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "nuc_med_filter_size = 10\n",
    "nuc_gaussian_smoothing_sigma = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34829215",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block rescales the image and applies the specified median and Gaussian filters. The image is then added to Napari as a new layer for visual comparison to the input image. \n",
    "\n",
    "Use the Napari viewer to iteratively adjust the smoothing settings selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96c0b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '7-Nuc: Rescale and Smooth' at 0x273866571c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescaling and smoothing input image\n",
    "nuclei =  scale_and_smooth(raw_nuclei,\n",
    "                           median_size = nuc_med_filter_size, \n",
    "                           gauss_sigma = nuc_gaussian_smoothing_sigma)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(nuclei, scale=scale, name=\"7-Nuc: Rescale and Smooth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c6535",
   "metadata": {},
   "source": [
    "#### **`C. Apply log transform and threshold`**\n",
    "\n",
    "&#x1F453; **FYI:** This code block applies a log transform and creates semantic segmentation using [Li's Minimum Cross Entropy](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_li) method. `Semantic segmentation` is the process of deciding whether a pixel/voxel should be included in an object (labeled with a value of 1) or should be considered as part of the background (labeled with a value of 0). A semantic segmentation does not discern individual objects from one another.\n",
    "\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following information:\n",
    "- `threshold_factor`: adjustment to make to the local threshold; larger values make the segmentation more stringent (less area included)\n",
    "- `thresh_min`: minimum bound of the threshold\n",
    "- `thresh_max`: maximum bound of the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2678181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "nuc_threshold_factor = 0.9\n",
    "nuc_thresh_min = .12\n",
    "nuc_thresh_max = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb18b9c",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block executes the log transform and threshold using the settings above.\n",
    "\n",
    "Use the Napari viewer to iteratively adjust the filter settings as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9f87252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '7-Nuc: Threshold' at 0x273fe270520>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log transform the image, calculate the threshold value using Li minimum cross entropy method, inverse log transform the value\n",
    "li_thresholded = apply_log_li_threshold(nuclei, \n",
    "                                        thresh_factor=nuc_threshold_factor, \n",
    "                                        thresh_min=nuc_thresh_min, \n",
    "                                        thresh_max=nuc_thresh_max)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(li_thresholded, scale=scale, name=\"7-Nuc: Threshold\", opacity=0.3, colormap=\"cyan\", blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5a30b",
   "metadata": {},
   "source": [
    "#### **`D. Remove small holes and objects`**\n",
    "\n",
    "&#x1F453; **FYI:** This code block cleans up the semantic segmentation by filling small holes and/or removing small objects that can be considered errors in the initial segmentation. \n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `hole_min_width`: the width of the smallest hole to be filled\n",
    "- `hole_max_width`: the width of the largest hole to be filled\n",
    "- `small_object_width`: the width of the largest object to be removed; any object smaller than this size will be removed\n",
    "- `fill_filter_method`: \"3D\" processes the image taking into account segmentation values in three dimensions (XYZ); \"slice-by-slice\" processes each Z-slice in the image separately, not considering the segmentation results in higher or lower Z planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8210cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "nuc_hole_min_width = 0\n",
    "nuc_hole_max_width = 25  \n",
    "\n",
    "nuc_small_object_width = 15\n",
    "\n",
    "nuc_fill_filter_method = \"3D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08199d",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block executes the dot filter using the settings above.\n",
    "\n",
    "Use the Napari viewer to iteratively adjust the filter settings as needed. \n",
    "\n",
    "*Hint: white pixels/voxels are the ones remaining after this step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83c18271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '7-Nuc: Fill holes and remove small objects' at 0x274046a7160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the above functions into one for downstream use in plugin\n",
    "cleaned_img = fill_and_filter_linear_size(li_thresholded, \n",
    "                                           hole_min=nuc_hole_min_width, \n",
    "                                           hole_max=nuc_hole_max_width, \n",
    "                                           min_size=nuc_small_object_width,\n",
    "                                           method=nuc_fill_filter_method)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(cleaned_img, scale=scale, name=\"7-Nuc: Fill holes and remove small objects\", colormap=\"magenta\", blending=\"additive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fca1e",
   "metadata": {},
   "source": [
    "#### **`E. - Label objects`**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block takes the semantic segmentation and creates an `instance segmentation`. In this output, each individual object in the image is given a unique ID number. The background pixels/voxels are still labeled as 0, but now each pixle/voxel within an object is labeled as a positive integer. \n",
    "\n",
    "In this workflow objects are separated based on connectivity: if a pixel/voxel is touching another pixel/voxel in any direction, they are considered the same object and each pixel/voxel within that object is labeled as the same unique ID number. \n",
    "\n",
    "*In the Napari viewer, the image is added as a \"labels\" layer where each object appears as a different color.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd973e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '7-Nuc: Instance segmentation' at 0x2740d1d2860>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance segmentation based on connectivity\n",
    "nuclei_labels = label_uint16(cleaned_img)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_labels(nuclei_labels, scale=scale, name=\"7-Nuc: Instance segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c63576",
   "metadata": {},
   "source": [
    "#### **`F. - Use search image to select single nucleus`**\n",
    "\n",
    "&#x1F453; **FYI:** This code selects a single nucleus label based on which label has the most overlap with the search image.\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "- `Search_Img`: the image/segmentation used to select the nucleus based on its intensities (‚ÄúImg 5‚Äù refers to the mask_I segmentation image and ‚ÄúImg 6‚Äù refers to the mask_II segmentation image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ddd43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "Search_Img = \"Img 6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb0f133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer '7-Nuc: Select single nucleus' at 0x2740d56ead0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect search image\n",
    "if Search_Img == \"Img 5\":\n",
    "    in_img = mask_I_segmentation\n",
    "elif Search_Img == \"Img 6\":\n",
    "    in_img = mask_II_segmentation\n",
    "\n",
    "# select single label\n",
    "keep_nuc = get_max_label((in_img), dilation(nuclei_labels))\n",
    "\n",
    "# create blank image\n",
    "nuc_obj = np.zeros_like(nuclei_labels)\n",
    "\n",
    "# finalize output\n",
    "nuc_obj[nuclei_labels == keep_nuc] = 1\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_labels(nuc_obj, scale=scale, name=\"7-Nuc: Select single nucleus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d537c",
   "metadata": {},
   "source": [
    "### **`STEP 8` - Combine nucleus and thresh and fill holes - I**\n",
    "\n",
    "&#x1F453; **FYI:** This performs a logical **OR** of the nucleus object (can be dilated) and the mask_I_segmentation. After the two segmentations are combined, small objects and holes can be removed. The result of this step is the cellmask_I segmentation.\n",
    "\n",
    "- To dilate the nucleus in 3D, set Method = `'Ball'`\n",
    "- To dilate the nucleus in 2D, set Method = `'Disk'`\n",
    "- To skip dilation, set Method = `'None'`\n",
    "###### (the string `\"None\"` is **not** to be confused with the `None` object)\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `Method`: the footprint of the nucleus dilation, \"Ball\" or \"Disk\" applies dilation, \"None\" skips dilation\n",
    "- `Size`: size of the footprint in the nucleus dilation\n",
    "- `Min_Hole_Width`: the minimum hole width to be filled in the combined segmentation\n",
    "- `Max_Hole_Width`: the maximum hole width to be filled in the combined segmentation\n",
    "- `Small_Obj_Width`: the minimum width of the objects to remain in the combined segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f27e77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm stands for cellmask, helps distinguish variables\n",
    "cm_method_I = \"Disk\"\n",
    "cm_size_I = 0\n",
    "cm_min_hole_width_I = 0\n",
    "cm_max_hole_width_I = 25\n",
    "cm_small_obj_width_I = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bf3eba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '8-Cell: Combine nuc and thresh I' at 0x2741cd78430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create cellmask_I segmentation\n",
    "cellmask_I_seg = mix_nuc_and_fill(nuc_obj,\n",
    "                 mask_I_segmentation,\n",
    "                 Method = cm_method_I,\n",
    "                 Size = cm_size_I,\n",
    "                 Min_Hole_Width = cm_min_hole_width_I,\n",
    "                 Max_Hole_Width = cm_max_hole_width_I,\n",
    "                 Small_Obj_Width = cm_small_obj_width_I)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(cellmask_I_seg, scale=scale, name=\"8-Cell: Combine nuc and thresh I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca648f",
   "metadata": {},
   "source": [
    "### **`STEP 9` - Combine nucleus and thresh and fill holes - II**\n",
    "\n",
    "&#x1F453; **FYI:** This performs a logical **OR** of the nucleus object (can be dilated) and the mask_II_segmentation. After the two segmentations are combined, small objects and holes can be removed. The result of this step is the cellmask_II segmentation.\n",
    "\n",
    "- To dilate the nucleus in 3D, set Method = `'Ball'`\n",
    "- To dilate the nucleus in 2D, set Method = `'Disk'`\n",
    "- To skip dilation, set Method = `'None'`, (the string `\"None\"` **not** the `None` object)\n",
    "\n",
    "###### (the string `\"None\"` is **not** to be confused with the `None` object)\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `Method`: the footprint of the nucleus dilation, \"Ball\" or \"Disk\" applies dilation, \"None\" skips dilation\n",
    "- `Size`: size of the footprint in the nucleus dilation\n",
    "- `Min_Hole_Width`: the minimum hole width to be filled in the combined segmentation\n",
    "- `Max_Hole_Width`: the maximum hole width to be filled in the combined segmentation\n",
    "- `Small_Obj_Width`: the minimum width of the objects to remain in the combined segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a20e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm stands for cellmask, helps distinguish variables\n",
    "cm_method_II = \"Disk\"\n",
    "cm_size_II = 0\n",
    "cm_min_hole_width_II = 0\n",
    "cm_max_hole_width_II = 25\n",
    "cm_small_obj_width_II = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d431b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '9-Cell: Combine nuc and thresh II' at 0x2741ee0e7d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create cellmask_II segmentation\n",
    "cellmask_II_seg = mix_nuc_and_fill(nuc_obj,\n",
    "                 mask_II_segmentation,\n",
    "                 Method = cm_method_II,\n",
    "                 Size = cm_size_II,\n",
    "                 Max_Hole_Width = cm_min_hole_width_II,\n",
    "                 Min_Hole_Width = cm_max_hole_width_II,\n",
    "                 Small_Obj_Width = cm_small_obj_width_II)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(cellmask_II_seg, scale=scale, name=\"9-Cell: Combine nuc and thresh II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0b611",
   "metadata": {},
   "source": [
    "-----\n",
    "## **POST-POST-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b3e3a",
   "metadata": {},
   "source": [
    "### **`STEP 10` - Watershed for cellmask**\n",
    "\n",
    "&#x1F453; **FYI:** This step peforms two [watershed](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.watershed) algorithms and then combines the results of both using a logical **OR**. \n",
    "\n",
    "For each iteration, the watershed is performed on the mask segmentation (I or II) which is bounded by its respective cellmask segmentation (I or II). To perform the watershed in 3D, set Watershed_Method = `\"3D\"`, or set Watershed_Method = `\"slice_by_slice\"` to run it in 2D. Also note that in both iterations, the seed is nucleus segmentation from step 7.\n",
    "\n",
    "Next, a logical **OR** is used to combine both segmentations to produce an unfinished cellmask. For final touches, the cellmask undergoes a closing (dilation -> erosion) algorithm. Closing can be performed in 3D if Method = `'Ball'`, or 2D if Method = `'Disk'`. Alternatively, the closing algorithm can be skipped altogether if Method = `'None'`. Small objects will be removed after the dilation, but before the erosion.\n",
    "\n",
    "###### (the string `\"None\"` is **not** to be confused with the `None` object)\n",
    "\n",
    "#### &#x1F6D1; &#x270D; **User Input Required:**\n",
    "\n",
    "Please specify the following values:\n",
    "- `Watershed_Method`: whether to perform the watershed on a ‚Äú3D‚Äù level or on a 2D level (‚Äúslice_by_slice‚Äù)\n",
    "- `Method`: the footprint of the cellmask closing, \"Ball\" or \"Disk\" applies dilation, \"None\" skips closing\n",
    "- `Size`: size of the footprint in the cellmask closing\n",
    "- `Min_Hole_Width`: the minimum hole width to be filled in the cellmask\n",
    "- `Max_Hole_Width`: the maximum hole width to be filled in the cellmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f26f0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for final cellmask\n",
    "cm_watershed_method = \"3D\"\n",
    "cm_method = \"Disk\"\n",
    "cm_size = 15\n",
    "cm_min_hole_width = 0\n",
    "cm_max_hole_width = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ea49bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '10-Cell: Watershed for Cellmask' at 0x27426408580>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellmask_obj = double_watershed(nuc_obj,\n",
    "                                mask_I_segmentation,\n",
    "                                mask_II_segmentation,\n",
    "                                cellmask_I_seg,\n",
    "                                cellmask_II_seg,\n",
    "                                Watershed_Method = cm_watershed_method,\n",
    "                                Min_Hole_Width = cm_min_hole_width,\n",
    "                                Max_Hole_Width = cm_max_hole_width,\n",
    "                                Method = cm_method,\n",
    "                                Size = cm_size)\n",
    "\n",
    "# adding image to Napari as a new layer\n",
    "viewer.add_image(cellmask_obj, scale=scale, name=\"10-Cell: Watershed for Cellmask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f4386",
   "metadata": {},
   "source": [
    "-----\n",
    "## **EXPORT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828631e2",
   "metadata": {},
   "source": [
    "### **`STEP 11` - Stack masks**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block stacks the single nucleus and cell into one multichannel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "438885f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack mask file structure: (2, 28, 796, 796)\n",
      "The dimension of '2' represents the 'nucleus' and 'cell' in that order.\n"
     ]
    }
   ],
   "source": [
    "stack = stack_masks(nuc_mask = nuc_obj, cellmask = cellmask_obj)\n",
    "print(f\"Stack mask file structure: {np.shape(stack)}\")\n",
    "print(f\"The dimension of '2' represents the 'nucleus' and 'cell' in that order.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85615604",
   "metadata": {},
   "source": [
    "-----\n",
    "## **SAVING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab13def",
   "metadata": {},
   "source": [
    "### **`Saving` - Save the segmentation output**\n",
    "\n",
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "&#x1F453; **FYI:** This code block saves the instance segmentation output to the `out_data_path` specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15770ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file: 20240118_iN D7 TRC1 ctrl_Z 9_Linear unmixing_0_cmle.ome-masks_C\n"
     ]
    }
   ],
   "source": [
    "out_file_n = export_inferred_organelle(stack, \"masks_C\", meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e49da",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## **Define functions**\n",
    "The following code includes an example of how the workflow steps above are combined into functions. The final combined `infer_masks_C` function can be run below to process a single image. It is included in the [batch process notebook](batch_process_segmentations.ipynb) to run the above analysis on multiple cells.\n",
    "\n",
    "This function can utilized from infer-subc using:\n",
    "```python\n",
    "infer_subc.organelles.masks.infer_masks_C()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb4f75",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
