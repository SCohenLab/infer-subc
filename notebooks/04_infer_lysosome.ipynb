{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer LYSOSOME - part 4\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component LYSOSOME  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The LYSOSOMES  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be organzied to explain the imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "# function for core algorithm\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, hole_filling\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters, img_as_float\n",
    "from skimage import morphology\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball, disk, dilation, white_tophat, black_tophat   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "# from aicsimageio import AICSImage\n",
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#import .infer_subc.base\n",
    "from infer_subc.base import *\n",
    "\n",
    "viewer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    "# IMAGE PROCESSING Objective 4:  infer LYSOSOME\n",
    "> Back to  [OUTLINE: Objective #4](#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  2\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "- enhance two classes of \"spots\"\n",
    "-  segment objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object LYSOSOME \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "##  set up files\n",
    "\n",
    "data_path = Path( f\"{os.getenv('HOME')}/Projects/Imaging/mcz_subcell/data\")\n",
    "czi_img_folder = data_path/\"raw\"\n",
    "\n",
    "list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "\n",
    "img_file_list = list_img_files(czi_img_folder,'.czi')\n",
    "print(img_file_list[5])\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "img_data, meta_dict = read_input_image(test_img_name)\n",
    "\n",
    "raw_meta_data, ome_types = get_raw_meta_data(meta_dict)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    "> Using Allen Cell Segmenter LAMP1 [workflow](https://www.allencell.org/cell-observations/category/lamp1).  Examples sourced from: [Notebook](/Users/ahenrie/Projects/Imaging/mcz_subcell/napari/aics-segmentation/lookup_table_demo/playground_lamp1.ipynb) and [script](/Users/ahenrie/Projects/Imaging/mcz_subcell/napari/aics-segmentation/aicssegmentation/structure_wrapper/seg_lamp1.py)\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel 1\n",
    "- CYTO mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- contrast scale\n",
    "- ne-noise and somoothe\n",
    "\n",
    "CORE PROCESSING\n",
    "- dot enhancement / segment\n",
    "- filiment enhancement / segment\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- mask of LYSOSOME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[1,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_lysosomes = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                raw_lysosomes,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# dot and filiment enhancement - 2D\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s2_param = [[5,0.09], [2.5,0.07], [1,0.01]]\n",
    "################################\n",
    "bw_spot = dot_2d_slice_by_slice_wrapper(struct_img, s2_param)\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "bw_filament = filament_2d_wrapper(struct_img, f2_param)\n",
    "bw = np.logical_or(bw_spot, bw_filament)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "fill_2d = True\n",
    "fill_max_size = 1600\n",
    "minArea = 15\n",
    "################################\n",
    "\n",
    "removed_holes = hole_filling(bw, 0, fill_max_size, fill_2d)\n",
    "\n",
    "# # 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "width = 45  \n",
    "cleaned_img = size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"3D\" ,\n",
    "                                                         connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'structure_img_smooth' at 0x14a738be0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_LYSOSOMES` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_LYSOSOMES\n",
    "##########################\n",
    "def infer_LYSOSOMES(struct_img,  CY_object, in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer LYSOSOME from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the LYSOSOME signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of Lysosomes\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    # log_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization( log_img ,  scaling_param=[0] )  \n",
    "    struct_img = intensity_normalization( struct_img ,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # dot and filiment enhancement - 2D\n",
    "\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    s2_param = [[5,0.09], [2.5,0.07], [1,0.01]]\n",
    "    ################################\n",
    "    bw_spot = dot_2d_slice_by_slice_wrapper(struct_img, s2_param)\n",
    "\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    f2_param = [[1, 0.15]]\n",
    "    ################################\n",
    "    bw_filament = filament_2d_wrapper(struct_img, f2_param)\n",
    "\n",
    "    bw = np.logical_or(bw_spot, bw_filament)\n",
    "\n",
    "    out_p[\"s2_param\"] = s2_param \n",
    "    out_p[\"f2_param\"] = f2_param \n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # 2D cleaning\n",
    "    hole_max = 1600  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "\n",
    "    # # 3D\n",
    "    # cleaned_img = remove_small_objects(removed_holes>0, \n",
    "    #                                                             min_size=width, \n",
    "    #                                                             connectivity=1, \n",
    "    #                                                             in_place=False)\n",
    "\n",
    "    small_object_max = 15\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "                \n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #2 - WIP\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " > Speckles: A speckle is an area of enhanced intensity relative to its immediate neighborhood. The module enhances speckles using a white tophat filter, which is the image minus the morphological grayscale opening of the image. The opening operation first suppresses the speckles by applying a grayscale erosion to reduce everything within a given radius to the lowest value within that radius, then uses a grayscale dilation to restore objects larger than the radius to an approximation of their former shape. The white tophat filter enhances speckles by subtracting the effects of opening from the original image. \n",
    "\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel 1\n",
    "- CYTO mask\n",
    "PRE-PROCESSING\n",
    "-   median filter, 2 pix window\n",
    "- gaussian  Filter window 10\n",
    "\n",
    "CORE-PROCESSING\n",
    "- \"BIG\"\n",
    "  - enhance speckles \n",
    "    - feature size: 40 pix\n",
    "    - speed/accurace: slow\n",
    "  - identify primary objects \"BIG\"\n",
    "    - adaptive Otsu\n",
    "      - diameter: (10,100)\n",
    "      - three classes\n",
    "        - middle intensity is foreground\n",
    "        - threshold smoothing scale: 1.34\n",
    "        - threshold correction factor: .7\n",
    "        - threshold bounds: (0.08197, 1)\n",
    "        - adaptive window: 20 pixels\n",
    "- \"SMALL\"\n",
    "  - enhance speckles \n",
    "    - feature size: 10 pix\n",
    "    - speed/accurace: slow\n",
    "- identify primary objects \"SMALL\"\n",
    "  - adaptive Sauvola\n",
    "    - diameter: (2,10)\n",
    "    - threshold smoothing scale: 1.34\n",
    "    - threshold correction factor: .75\n",
    "    - threshold bounds: (0.06, 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - embedded in CORE\n",
    "\n",
    "OUTPUT\n",
    "- mask of LYSOSOME\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[1,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "# Linear-ish smoothing\n",
    "raw_lysosomes = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                raw_lysosomes,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "def _enhance_speckles(image, radius, volumetric=True):\n",
    "    radius = radius / 2\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "\n",
    "    # if radius >10:\n",
    "    #         minimum = scipy.ndimage.minimum_filter(image, footprint=selem)\n",
    "    #         maximum = scipy.ndimage.maximum_filter(minimum, footprint=selem)\n",
    "    #         result = data - maximum\n",
    "    # else:\n",
    "    result =  white_tophat(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "def enhance_neurites(image, radius, volumetric = True):\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "    white = white_tophat(image,selem)\n",
    "    black = black_tophat(image, selem)\n",
    "    result = image + white - black\n",
    "    result[result > 1] = 1\n",
    "    result[result < 0] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = _enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = _enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n",
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'sm_img' at 0x16ef15fd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_LYSOSOME_CP` function ( WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "# mangle so we can call from base.py\n",
    "def infer_LYSOSOME_CP(struct_img: np.ndarray, CY_object: np.ndarray, in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer LYSOSOMES from linearly unmixed input as per CellProfiler procedure\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "        TODO:  perform the mask, flag?\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.25\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    # 3D cleaning\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=np.abs(ndi.sobel(struct_img)),\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "\n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST `infer_LYSOSOMES` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'struct_obj' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m raw_soma_linear \u001b[39m=\u001b[39m intensity_normalization(  img_data[composite_channels,:,:,:]\u001b[39m.\u001b[39mcopy(), scaling_param\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m] )\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#struct_img = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m SO_object, SO_label, out_p \u001b[39m=\u001b[39m  infer_LYSOSOMES(raw_soma_linear\u001b[39m.\u001b[39;49mcopy(), NU_labels, default_params) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#              also fix Path vs. str action for export wrapper\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m chan_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnuclei\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb Cell 40\u001b[0m in \u001b[0;36minfer_LYSOSOMES\u001b[0;34m(struct_img, CY_object, in_params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m hole_max \u001b[39m=\u001b[39m \u001b[39m1600\u001b[39m  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# discount z direction\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m struct_obj \u001b[39m=\u001b[39m aicssegmentation\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mhole_filling(struct_obj, hole_min \u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m , hole_max\u001b[39m=\u001b[39mhole_max\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, fill_2d \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m out_p[\u001b[39m'\u001b[39m\u001b[39mhole_max\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hole_max\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# # 3D\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# cleaned_img = remove_small_objects(removed_holes>0, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m#                                                             min_size=width, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m#                                                             connectivity=1, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahenrie/Projects/Imaging/infer-subc/notebooks/04_infer_lysosomes.ipynb#X54sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m#                                                             in_place=False)\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'struct_obj' referenced before assignment"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[1,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n",
    "\n",
    "\n",
    "\n",
    "LY_object, out_p =  infer_LYSOSOMES(raw_soma_linear.copy(), CY_object, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "# need to bapck all the objects into a single TIFF\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'LY_object'\n",
    "\n",
    "LY_object_filen = export_ome_tiff(LY_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_soma_linear,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    SO_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n",
    "viewer2.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
