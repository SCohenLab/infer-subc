{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer GOLGI - part 6️⃣\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  ✅ Infer sub-cellular component GOLGI COMPLEX  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The GOLGI  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_input_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles.nuclei import infer_NUCLEI\n",
    "from infer_subc_2d.organelles.soma import infer_SOMA\n",
    "from infer_subc_2d.organelles.cytosol import infer_CYTOSOL\n",
    "from infer_subc_2d.constants import TEST_IMG_N\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 6:  infer GOLGI COMPLEX\n",
    "> Back to  [OUTLINE: Objective #5](00_pipeline_setup.ipynb#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  4\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  segment objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object GOLGI \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default parameters, including  \"optimal\" Z\n",
    "\n",
    "takes ~ 4 seconds to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_Z_from_params = False\n",
    "\n",
    "\n",
    "if load_Z_from_params:\n",
    "\n",
    "    default_params = load_parameters( test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "\n",
    "    ch_to_agg = default_params[\"ch_to_agg\"]\n",
    "    nuc_ch = default_params['nuc_ch']\n",
    "    optimal_Z = default_params[\"optimal_Z\"] #find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "else:\n",
    "    ch_to_agg = (1,2,3,4,5,6)\n",
    "    nuc_ch = 0\n",
    "    optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "\n",
    "    default_params = defaultdict(str, **{\n",
    "        #\"intensity_norm_param\" : [0.5, 15]\n",
    "        \"intensity_norm_param\" : [0],\n",
    "        \"gaussian_smoothing_sigma\" : 1.34,\n",
    "        \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "        \"dot_2d_sigma\" : 2,\n",
    "        \"dot_2d_sigma_extra\" : 1,\n",
    "        \"dot_2d_cutoff\" : 0.025,\n",
    "        \"min_area\" : 10,\n",
    "        \"low_level_min_size\" :  100,\n",
    "        \"median_filter_size\" : 4,\n",
    "        \"ch_to_agg\" : (1,2,3,4,5,6), # exclude residual\n",
    "        \"nuc_ch\" : 0,\n",
    "        \"optimal_Z\": optimal_Z,\n",
    "    })\n",
    "    save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "# make sure we have removed Z\n",
    "if len(scale)>2:\n",
    "    scale = scale[1:]\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred nuclei object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "raw_nuclei = img_2D[0].copy()\n",
    "NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred soma object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "raw_soma = (4. * img_2D[1].copy() + \n",
    "                               1. * img_2D[5].copy() + \n",
    "                               1. * img_2D[7].copy() )\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA(raw_soma.copy(), NU_label, default_params) \n",
    "CY_object =  infer_CYTOSOL(SO_object, NU_object) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    "> As per the Allen Cell segmenter sialyltransferase 1 (ST6GAL1) a potential Golgi segmenter. e.g. [Allen Cell](https://www.allencell.org/cell-observations/category/golgi-apparatus).    using [seg_st6gal1.py](\"../../../../aics-segmentation/aicssegmentation/structure_wrapper/seg_st6gal1.py\") and [playground_st6gal1.ipynb](\"../../../../aics-segmentation/lookup_table_demo/playground_st6gal1.ipynb\")\n",
    "\n",
    "\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- ch 4\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-   non-local noise reduction\n",
    "  - size:4, distance:2, cut-off:0.1\n",
    "\n",
    "CORE-PROCESSING\n",
    "- adaptive Otsu\n",
    "    - diameter: (4,100)\n",
    "  - two classes\n",
    "    - threshold smoothing scale: 1.34\n",
    "    - threshold correction factor: .75\n",
    "    - threshold bounds: (0.14, 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "  - adaptive Sauvola\n",
    "    - threshold smoothing scale: 0\n",
    "    - threshold correction factor: .6\n",
    "    - threshold bounds: (0. ,1.0)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - N/A\n",
    "\n",
    "OUTPUT\n",
    "- object GOLGI \n",
    "\n",
    "\n",
    ">#### ASIDE: Perform topology-preserving thinning \n",
    ">There are two parameters:\n",
    ">* `thin_dist_preserve`: Half of the minimum width you want to keep from being thinned. For example, when the object width is smaller than 4, you don't want to make this part even thinning (may break the thin object and alter the topology), you can set `thin_dist_preserve` as `2`.\n",
    ">* `thin_dist`: the amount to thin (has to be an positive integer). The number of pixels to be removed from outter boundary towards center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_golgi   = img_2D[3].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "intensity_norm_param = [0.1, 30.]  # CHECK THIS\n",
    "# Linear-ish smoothing\n",
    "golgi = intensity_normalization( masked_golgi ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.34\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(golgi,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "struct_img = structure_img_smooth\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "cell_wise_min_area = 1200\n",
    "dot_2d_sigma = 1.6\n",
    "dot_2d_cutoff = 0.02\n",
    "minArea = 10\n",
    "thin_dist = 1\n",
    "thin_dist_preserve = 1.6\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "bw, object_for_debug = MO(structure_img_smooth, \n",
    "                                                global_thresh_method='tri', \n",
    "                                                object_minArea=cell_wise_min_area, \n",
    "                                                return_object=True)\n",
    "\n",
    "thin_dist_preserve=1.6\n",
    "thin_dist=1\n",
    "bw_thin = topology_preserving_thinning(bw>0, thin_dist_preserve, thin_dist)\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "#s3_param = [[1.6, 0.02]]\n",
    "s3_param = [(dot_2d_sigma,dot_2d_cutoff)]\n",
    "################################\n",
    "\n",
    "bw_extra = dot_3d_wrapper(structure_img_smooth, s3_param)\n",
    "\n",
    "bw_combine = np.logical_or(bw_extra>0, bw_thin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "small_object_max = 4\n",
    "\n",
    "GO_object = size_filter_2D(bw, \n",
    "                                                min_size= small_object_max**2, \n",
    "                                                connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'GO_object' at 0x149c7cf10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "    bw_combine,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'GO_object [1]' at 0x17f586e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    GO_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_GOLGI` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_GOLGI\n",
    "##########################\n",
    "def _infer_GOLGI(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer GOLGI COMPLEX  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 2d image containing the GOLGI signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 2d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of MITOCHONDRIA\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "    \n",
    "    struct_img = apply_mask(struct_img,CY_object)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    intensity_norm_param = [0.1, 30.]  # CHECK THIS\n",
    "\n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=intensity_norm_param)\n",
    "    out_p[\"intensity_norm_param\"] = intensity_norm_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    struct_img = median_filter(struct_img,    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.34\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    cell_wise_min_area = 1200\n",
    "    bw, object_for_debug = MO(struct_img, \n",
    "                                                global_thresh_method='tri', \n",
    "                                                object_minArea=cell_wise_min_area, \n",
    "                                                return_object=True)\n",
    "    out_p[\"cell_wise_min_area\"] = cell_wise_min_area \n",
    "\n",
    "    thin_dist_preserve=1.6\n",
    "    thin_dist=1\n",
    "    bw_thin = topology_preserving_thinning(bw>0, thin_dist_preserve, thin_dist)\n",
    "    out_p[\"thin_dist_preserve\"] = thin_dist_preserve \n",
    "    out_p[\"thin_dist\"] = thin_dist \n",
    "\n",
    "    dot_2d_sigma = 1.6\n",
    "    dot_2d_cutoff = 0.02\n",
    "    s3_param = [(dot_2d_sigma,dot_2d_cutoff)]\n",
    "\n",
    "    bw_extra = dot_3d_wrapper(struct_img, s3_param)\n",
    "    out_p[\"dot_2d_sigma\"] = dot_2d_sigma \n",
    "    out_p[\"dot_2d_cutoff\"] = dot_2d_cutoff \n",
    "    out_p[\"s3_param\"] = s3_param \n",
    "\n",
    "    bw = np.logical_or(bw_extra>0, bw_thin)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    small_object_max = 4\n",
    "    struct_obj = size_filter_2D(bw, \n",
    "                                                min_size= small_object_max**2, \n",
    "                                                connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `infer_GOLGI` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_golgi    = img_2D[3].copy()\n",
    "\n",
    "GL_object, out_p =  _infer_GOLGI(raw_golgi, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Labels [5]' at 0x1803eb400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    GL_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_labels(\n",
    "    label(GL_object),\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles.golgi import infer_GOLGI\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "raw_golgi    = img_2D[3].copy()\n",
    "\n",
    "GL_object, out_p =  infer_GOLGI(raw_golgi, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------\n",
    "\n",
    " 🚧 WIP 🚧 (🚨🚨🚨🚨 )\n",
    "\n",
    " \n",
    "# WORKFLOW #2 (WIP)\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " \n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- ch 4\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-   non-local noise reduction\n",
    "  - size:4, distance:2, cut-off:0.08\n",
    "\n",
    "CORE-PROCESSING\n",
    "- adaptive Otsu\n",
    "    - diameter: (4,100)\n",
    "  - two classes\n",
    "    - threshold smoothing scale: 1.34\n",
    "    - threshold correction factor: .75\n",
    "    - threshold bounds: (0.14, 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - N/A\n",
    "\n",
    "OUTPUT\n",
    "- object GOLGI \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[3,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0] # \n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "def _enhance_speckles(image, radius, volumetric=True):\n",
    "    radius = radius / 2\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "\n",
    "    # if radius >10:\n",
    "    #         minimum = scipy.ndimage.minimum_filter(image, footprint=selem)\n",
    "    #         maximum = scipy.ndimage.maximum_filter(minimum, footprint=selem)\n",
    "    #         result = data - maximum\n",
    "    # else:\n",
    "    result =  white_tophat(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "def enhance_neurites(image, radius, volumetric = True):\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "    white = white_tophat(image,selem)\n",
    "    black = black_tophat(image, selem)\n",
    "    result = image + white - black\n",
    "    result[result > 1] = 1\n",
    "    result[result < 0] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = _enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = _enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n",
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/data/intermediate/ZSTACK_PBTOhNGN2hiPSCs_BR3_N14_Unmixed.czi_params.pkl'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save updated parameters for ongoing testing\n",
    "save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
