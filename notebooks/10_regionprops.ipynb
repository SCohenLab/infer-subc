{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCohenLab 2D BATCH Image Processing notebook (Simplified MCZ)\n",
    "\n",
    "--------------\n",
    "# PIPELINE OVERVIEW\n",
    "## ‚ù∂ GOAL SETTING ‚úç\n",
    "\n",
    "### GOAL:  Infer sub-cellular components in order to understand interactome \n",
    "\n",
    "To measure shape, position, size, and interaction of eight organelles/cellular components (Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and SOMA) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.\n",
    "\n",
    "### summary of _OBJECTIVES_ ‚úÖ\n",
    "- robust inference of subcellular objects:\n",
    "  + 1Ô∏è‚É£-***nuclei***\n",
    "  + 2Ô∏è‚É£-***cellmask***\n",
    "  + 3Ô∏è‚É£-***cytoplasm*** (+ ***nucleus***)\n",
    "  + 4Ô∏è‚É£-***lysosome***\n",
    "  + 5Ô∏è‚É£-***mitochondria***\n",
    "  + 6Ô∏è‚É£-***golgi***\n",
    "  + 7Ô∏è‚É£-***peroxisome***\n",
    "  + 8Ô∏è‚É£-***ER***\n",
    "  + 9Ô∏è‚É£-***lipid droplet***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ‚ù∑ DATA CREATION\n",
    "> METHODS:üìöüìö\n",
    "> \n",
    "> iPSC lines prepared and visualized on Zeiss Microscopes. 32 channel multispectral images collected.  Linear Unmixing in  ZEN Blue software with target emission spectra yields 8 channel image outputs.  Channels correspond to: Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and a ‚Äúresidual‚Äù signal.\n",
    "\n",
    "> Meta-DATA üè∫ (artifacts)\n",
    ">   - Microcope settings\n",
    ">  - OME scheme\n",
    "> - Experimenter observations\n",
    "> - Sample, bio-replicate, image numbers, condition values, etc\n",
    ">  - Dates\n",
    ">  - File structure, naming conventions\n",
    ">  - etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ù∏. IMAGE PROCESSING ‚öôÔ∏èü©ªüî¨\n",
    "### INFERENCE OF SUB-CELLULAR OBJECTS\n",
    "The imported images have already been pre-processed to transform the 32 channel spectral measuremnts into \"linearly unmixed\" images which estimate independently labeled sub-cellular components.  Thes 7 channels (plus a residual \"non-linear\" signal) will be used to infer the shapes and extents of these sub-cellular components.   \n",
    "We will perform computational image analysis on the pictures (in 2D an 3D) to _segment_ the components of interest for measurement.  In other prcoedures we can used these labels as \"ground truth\" labels to train machine learning models to automatically perform the inference of these objects.\n",
    "Pseudo-independent processing of the imported multi-channel image to acheive each of the 9 objecives stated above.  i.e. infering: NUCLEI, SOMA, CYTOSOL, LYSOSOME, MITOCHONDRIA, GOLGI COMPLEX, PEROZISOMES, ENDOPLASMIC RETICULUM, and LIPID BODIES\n",
    "\n",
    "### General flow for infering objects via segmentation\n",
    "- Pre-processing üåí\n",
    "- Core-processing (thresholding) üåï\n",
    "- Post-processing  üåò\n",
    "\n",
    "### QC üöß WIP üöß \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ‚ùπ. QUANTIFICATION üìèüìêüßÆ\n",
    "\n",
    "SUBCELLULAR COMPONENT METRICS\n",
    "-  extent \n",
    "-  size\n",
    "-  shape\n",
    "-  position\n",
    "\n",
    "\n",
    "\n",
    "### NOTE: PIPELINE TOOL AND DESIGN CHOICES?\n",
    "We want to leverage the Allen Cell & Structure Setmenter.  It has been wrapped as a [napari-plugin](https://www.napari-hub.org/plugins/napari-allencell-segmenter) but fore the workflow we are proving out here we will want to call the `aicssegmentation` [package](https://github.com/AllenCell/aics-segmentation) directly.\n",
    "\n",
    "#### ‚ÄãThe Allen Cell & Structure Segmenter \n",
    "‚ÄãThe Allen Cell & Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.\n",
    "\n",
    "More details about Segmenter can be found at https://allencell.org/segmenter\n",
    "In order to leverage the A\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table, regionprops, label\n",
    "from skimage.morphology import binary_erosion\n",
    "\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.core.file_io import (read_czi_image,\n",
    "                                                                    export_inferred_organelle,\n",
    "                                                                    import_inferred_organelle,\n",
    "                                                                    export_tiff,\n",
    "                                                                    list_image_files)\n",
    "\n",
    "from infer_subc_2d.core.img import *\n",
    "from infer_subc_2d.utils.stats import *\n",
    "\n",
    "from infer_subc_2d.organelles import * \n",
    "\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:  these \"constants\" are only accurate for the testing MCZ dataset\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROX_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LD_CH ,\n",
    "                                                                    RESIDUAL_CH )              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example image for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "in_data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "# save output \".tiff\" files here\n",
    "out_data_path = data_root_path / \"out\"\n",
    "\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cento/lib/python3.9/site-packages/ome_types/_convenience.py:106: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "source_file = meta_dict['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.267318290023735,\n",
       " (0.5804527163320905, 0.07987165184837318, 0.07987165184837318))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale[0]/scale[1], scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the single \"optimal\" slice of all our organelle channels...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred cellmask, nuclei and cytoplasm objects\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builde the segmentations in order\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.01) sec\n",
      "loaded  inferred 3D `nuclei`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=int32in (0.02) sec\n",
      "loaded  inferred 3D `cellmask`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.01) sec\n",
      "loaded  inferred 3D `cytoplasm`  from /Users/ahenrie/Projects/Imaging/data/out \n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# SOMA, NUCLEI, CYTOSOL, NUCLEUS\n",
    "###################\n",
    "nuclei_obj =  get_nuclei(img_data,meta_dict, out_data_path)\n",
    "soma_obj = get_cellmask(img_data, nuclei_obj, meta_dict, out_data_path)\n",
    "cytoplasm_mask = get_cytoplasm(nuclei_obj , soma_obj , meta_dict, out_data_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## regionprops\n",
    "\n",
    "`skimage.measure.regionprops` provides the basic tools nescessary to quantify our segmentations.\n",
    "\n",
    "First lets see what works in 3D.  \n",
    "\n",
    "> Note: the names of the regionprops correspond to the 2D analysis even for those which are well defined in 3D.  i.e. \"area\" is actually \"volume\" in 3D, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## basic stats\n",
    "\n",
    "### per-organelle\n",
    "\n",
    "\n",
    "- regionprops \n",
    "\n",
    "\n",
    "### summary stats\n",
    "\n",
    "- group + aggregate:  surface_area, volume\n",
    "  - median\n",
    "  - mean\n",
    "  - std \n",
    "  - count\n",
    "\n",
    "- normalizers\n",
    "  - SOMA?\n",
    "  - CYTOSOL?\n",
    "\n",
    "### nuclei caveats\n",
    "The other organelles are sensibly normalized by cytoplasm.  does normalizing the nuclei by cytoplasm make sense?  or use cellmask?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which possible measures are sensible for 3D or volumetric with regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label(nuclei_obj )\n",
    "rp = regionprops(labels, intensity_image=img_data[NUC_CH])\n",
    "\n",
    "supported = [] \n",
    "unsupported = []\n",
    "\n",
    "for prop in rp[0]:\n",
    "    try:\n",
    "        rp[0][prop]\n",
    "        supported.append(prop)\n",
    "    except NotImplementedError:\n",
    "        unsupported.append(prop)\n",
    "\n",
    "print(\"Supported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(supported))\n",
    "print()\n",
    "print(\"Unsupported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(unsupported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.ndimage import find_objects\n",
    "    \n",
    "# labels = label(nuclei_obj ).astype(\"int\")\n",
    "# objects = find_objects(labels)\n",
    "\n",
    "# # objects are the slices into the original array for each organelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overall summary stats for cellmask\n",
    "florescence =  raw_soma_MCZ(img_data, scale_min_max=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dump_stats(name: str, segmentation:np.ndarray, intensity_img:np.ndarray, mask:np.ndarray, out_data_path: Path, source_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get summary stats\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table,_ = get_summary_stats_3D(segmentation, intensity_img, mask) \n",
    "    csv_path = out_data_path / f\"{name}_{source_file.split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "    stats_table.to_csv(csv_path )\n",
    "    print(f\"dumped {name} table to {csv_path}\")\n",
    "\n",
    "    return stats_table\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_table = dump_stats(\"cellmask\", soma_obj, florescence, soma_obj, out_data_path, source_file)\n",
    "nucleus_table = dump_stats(\"nucleus\", nuclei_obj, img_data[NUC_CH], soma_obj, out_data_path, source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_table.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get a list of our organelle names, segmentations, intensities (florescence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`lyso` object not found: /Users/ahenrie/Projects/Imaging/data/out/lyso_ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.tiff\n",
      "starting segmentation...\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.04) sec\n",
      "saved file: None\n",
      "inferred lyso. wrote None\n",
      "inferred (and exported) lyso in (10.87) sec\n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.01) sec\n",
      "loaded  inferred 3D `mitochondria`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.00) sec\n",
      "loaded  inferred 3D `golgi`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      "starting segmentation...\n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.01) sec\n",
      "loaded  inferred 3D `peroxisome`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      "loaded peroxisome in (0.01) sec\n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.00) sec\n",
      "loaded  inferred 3D `er`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint8in (0.01) sec\n",
      "loaded  inferred 3D `lipid`  from /Users/ahenrie/Projects/Imaging/data/out \n"
     ]
    }
   ],
   "source": [
    "# names of organelles we have\n",
    "organelle_names = [\"lyso\", \"mitochondria\",\"golgi\",\"peroxisome\",\"er\",\"lipid\"]\n",
    "\n",
    "get_methods  = [get_lyso,\n",
    "            get_mito,\n",
    "            get_golgi,\n",
    "            get_perox,\n",
    "            get_ER,\n",
    "            get_LD]\n",
    "\n",
    "# load all the organelle segmentations\n",
    "organelles = [meth(img_data,meta_dict, out_data_path) for meth in get_methods]\n",
    "\n",
    "# get the intensities\n",
    "organelle_channels = [LYSO_CH,MITO_CH,GOLGI_CH,PEROX_CH,ER_CH,LD_CH]\n",
    "\n",
    "intensities = [img_data[ch] for ch in organelle_channels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# stats_tables = []\n",
    "# props = []\n",
    "# for org, ch in zip(organelles, organelle_channels):\n",
    "#     stats_tab, prps = get_summary_stats_3D(org , img_data[ch] ,cytoplasm_mask )\n",
    "#     stats_tables.append(stats_tab)\n",
    "#     props.append(prps)\n",
    "# ch_dict = dict(zip(organelle_names, organelle_channels))\n",
    "# idx_ = dict(zip(organelle_names, range(len(organelle_names) )) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## CONTACTS (cross-stats)\n",
    "\n",
    "### organelle cross stats\n",
    "\n",
    "\n",
    "- regionprops \n",
    "\n",
    "\n",
    "\n",
    "- intersect for A vs all other organelles Bi\n",
    "  - regionprops on A ‚à© Bi\n",
    "\n",
    "   \n",
    "- contacts?\n",
    "  - dilate then intersect?\n",
    "  - loop through each sub-object for each \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def shell_cross_stats(organelle_names: List[str], organelles:List[np.ndarray], mask:np.ndarray, out_data_path: Path, source_file: str) -> int:\n",
    "    \"\"\"\n",
    "    get all cross stats between organelles A and B, and \"shell of A\" and B.   \"shell\" is the boundary of A \n",
    "    calls `get_AintB_stats_3D`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for j,target in enumerate(organelle_names):    \n",
    "        print(f\"getting stats for A = {target}\")\n",
    "        A = organelles[j ]\n",
    "        # loop over Bs\n",
    "        for i,nmi in enumerate(organelle_names):    \n",
    "            if  i  != j:\n",
    "                # get overall stats of intersection\n",
    "                print(f\"  b = {nmi}\")\n",
    "                B = organelles[i]\n",
    "                stats_tab = get_AintB_stats_3D(A,B, mask)    \n",
    "                csv_path = out_data_path / f\"{target}X{nmi}_{source_file.split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "                stats_tab.to_csv(csv_path )\n",
    "\n",
    "                e_stats_tab = get_AintB_stats_3D(A,B, cytoplasm_mask, erode_A=True)\n",
    "                csv_path = out_data_path / f\"{target}_shellX{nmi}_{source_file.split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "                e_stats_tab.to_csv(csv_path )\n",
    "\n",
    "                # add the list of touches \n",
    "                labB = label(B)\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organelle_stats(organelle_names: List[str], organelles:List[np.ndarray], intinsities:List[np.ndarray], mask:np.ndarray, out_data_path: Path, source_file: str) -> int:\n",
    "    \"\"\"\n",
    "    get summary and all cross stats between organelles A and B\n",
    "\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    org_stats_tabs = []\n",
    "    for j,target in enumerate(organelle_names):    \n",
    "        print(f\"getting stats for A = {target}\")\n",
    "        A = organelles[ j ]\n",
    "        # A_stats_tab, rp = get_simple_stats_3D(A,mask)\n",
    "        A_stats_tab, rp = get_summary_stats_3D(A , intinsities[ j ] ,mask )\n",
    "\n",
    "        # loop over Bs\n",
    "        for i,nmi in enumerate(organelle_names):    \n",
    "            if  i != j:\n",
    "                # get overall stats of intersection\n",
    "                print(f\"  b = {nmi}\")\n",
    "                B = organelles[i]\n",
    "\n",
    "                count += 1 \n",
    "                # add the list of touches \n",
    "                labB = label(B)\n",
    "\n",
    "                ov = []\n",
    "                B_labs = []\n",
    "                labs = []\n",
    "                for idx,lab in enumerate(A_stats_tab['label']): # loop over A_objects\n",
    "                    xyz = tuple(rp[idx].coords.T)\n",
    "                    cmp_org = labB[xyz]\n",
    "\n",
    "                    #total number of overlapping pixels\n",
    "                    overlap = sum(cmp_org>0)\n",
    "                    # overlap?\n",
    "                    b_labs = cmp_org[cmp_org>0]\n",
    "                    b_js = np.unique(b_labs).tolist()\n",
    "\n",
    "                    # if overlap > 0:\n",
    "                    labs.append(lab)\n",
    "                    ov.append(overlap)\n",
    "                    B_labs.append(b_js)\n",
    "\n",
    "                # add organelle B columns to A_stats_tab\n",
    "                A_stats_tab[f\"{nmi}_overlap\"] = ov\n",
    "                A_stats_tab[f\"{nmi}_labels\"] = B_labs  # might want to make this easier for parsing later\n",
    "\n",
    "        # org_stats_tabs.append(A_stats_tab)\n",
    "        csv_path = out_data_path / f\"{target}_{source_file.split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "        A_stats_tab.to_csv(csv_path)\n",
    "\n",
    "        print(f\"dumped {count} csvs\")\n",
    "    return count\n",
    "\n",
    "    \n",
    "# refactor to just to a target vs. list of probes\n",
    "# for nuclei mask == cellmask\n",
    "# for all oother mask == cytoplasm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = organelle_stats(organelle_names, organelles,intensities, cytoplasm_mask, out_data_path, source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = dump_cross_stats(organelle_names, organelles, cytoplasm_mask, out_data_path, source_file) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "##  SUMMARY STATS  \n",
    "> WARNING: (üö®üö®üö®üö® WIP)\n",
    "### normalizations.\n",
    "\n",
    "- overlaps, normalized by CYTOSOL, A, and B\n",
    "- per cell averages, medians, std, and totals\n",
    "\n",
    "These is all pandas munging and very straightforward tabular manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = organelle_names[1]\n",
    "\n",
    "csv_path = out_data_path / f\"{target}_{source_file.split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "\n",
    "mito_table = pd.read_csv(csv_path)\n",
    "mito_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_table.volume.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## DISTRIBUTION  \n",
    "> WARNING: (üö®üö®üö®üö® WIP)\n",
    "### XY- summary\n",
    "Segment image in 3D;\n",
    "sum projection of binary image; \n",
    "create 5 concentric rings going from the edge of the nuclie to the edge of the cellmask (ideally these will be morphed to cellmask/nuclei shape as done in CellProfiler); \n",
    "measure intensity per ring (include nuclei as the center area to measure from)/ring area; \n",
    "the normalized measurement will act as a frequency distribution of that organelle starting from the nuclei bin going out to the cell membrane - \n",
    "Measurements needed: mean, median, and standard deviation of the frequency will be calculated\n",
    "\n",
    "- pre-processing\n",
    "  1. Make 2D sum projection of binary segmentation\n",
    "  2. Create 5 concentric rings going out from the edge of the nuclei to the edge of the cellmask - these rings should be morphed to the shape of the nuclei and cellmask. \n",
    "  3. Use nucleus + concentric rings to mask the 2D sum project into radial distribution regions: nuclei = bin 1, ... largest/outter most ring = bin 6. See similar concept in CellProfiler: https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.5/modules/measurement.html?highlight=distribution#module-cellprofiler.modules.measureobjectintensitydistribution\"\t\n",
    "   \n",
    "- per-object measurements\n",
    "  - For each bin measure:\n",
    "    1. pixel \"\"intensity\"\"\n",
    "    2. bin area\"\n",
    "\n",
    "- per-object calculations\n",
    "  - per-object For each bin: \n",
    "  - sum of pixel intensity per bin / bin area\"\t\n",
    "\n",
    "- per cell summary\n",
    "  1. Create a frequency table with bin number of the x axis and normalized pixel intensity on the y-axis\n",
    "  2. Measure the frequency distribution's mean, median, and standard deviation for each cell\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Z- summary\n",
    "Segment image in 3D;\n",
    "measure area fraction of each organelle per Z slice;\n",
    "these measurements will act as a frequency distribution of that organelle starting from the bottom of the cellmask (not including neurites) to the top of the cellmask;\n",
    "measurements: mean, median, and standard deviation of the frequency distribution\t\n",
    "\n",
    "- pre-processing\n",
    "  1. subtract nuclei from the cellmask --> cellmask cytoplasm\n",
    "  2. mask organelle channels with cellmask cytoplasm mask\n",
    "\n",
    "- per-object measurements\n",
    "  - For each Z slice in the masked binary image measure:\n",
    "    1. organelle area\n",
    "    2. cellmask cytoplasm area\n",
    "\n",
    "- per-object calculations\n",
    "  - For each Z slice in the masked binary image: organelle area / cellmask cytoplasm area\n",
    "\n",
    "- per cell summary\n",
    "  1. create a frequency table with the z slice number on the x axis and the area fraction on the y axis\n",
    "  2. Measure the frequency distribution's mean, median, and standard deviation for each cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the flattened\n",
    "flat_soma = soma_obj.sum(axis=0) >0\n",
    "flat_nuclei = apply_mask(nuclei_obj,soma_obj).sum(axis=0)>0\n",
    "d_to_edge = distance_to_edge( label(flat_soma) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = color_labels(label(flat_soma) + label(flat_nuclei))\n",
    "d_to_edge = distance_to_edge( colors )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viewer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m viewer\u001b[39m.\u001b[39mclose()\n\u001b[1;32m      2\u001b[0m viewer \u001b[39m=\u001b[39mnapari\u001b[39m.\u001b[39mview_image(d_to_edge)\n\u001b[1;32m      3\u001b[0m viewer\u001b[39m.\u001b[39madd_image(flat_nuclei)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'viewer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "viewer =napari.view_image(d_to_edge)\n",
    "viewer.add_image(flat_nuclei)\n",
    "viewer.add_image(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zflat_soma = soma_obj.sum(axis=(1,2)) >0\n",
    "Zflat_nuclei = apply_mask(nuclei_obj,soma_obj).sum(axis=(1,2)) > 0\n",
    "\n",
    "Zflat_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_org[0]=2\n",
    "org_js = np.unique(cmp_org)\n",
    "org_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = out_data_path / f\"{o}_{meta_dict[\"file_name\"].split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "meta_dict['file_name'].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import maximum_position, center_of_mass\n",
    "from scipy.ndimage import sum as ndi_sum\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from infer_subc_2d.core.img import distance_to_edge, distance_transform_edt\n",
    "\n",
    "import centrosome\n",
    "\n",
    "C_SELF = \"These objects\"\n",
    "C_CENTERS_OF_OTHER_V2 = \"Other objects\"\n",
    "C_CENTERS_OF_OTHER = \"Centers of other objects\"\n",
    "C_EDGES_OF_OTHER = \"Edges of other objects\"\n",
    "C_ALL = [C_SELF, C_CENTERS_OF_OTHER, C_EDGES_OF_OTHER]\n",
    "Z_NONE = \"None\"\n",
    "Z_MAGNITUDES = \"Magnitudes only\"\n",
    "Z_MAGNITUDES_AND_PHASE = \"Magnitudes and phase\"\n",
    "Z_ALL = [Z_NONE, Z_MAGNITUDES, Z_MAGNITUDES_AND_PHASE]\n",
    "\n",
    "M_CATEGORY = \"RadialDistribution\"\n",
    "F_FRAC_AT_D = \"FracAtD\"\n",
    "F_MEAN_FRAC = \"MeanFrac\"\n",
    "F_RADIAL_CV = \"RadialCV\"\n",
    "F_ALL = [F_FRAC_AT_D, F_MEAN_FRAC, F_RADIAL_CV]\n",
    "\n",
    "FF_SCALE = \"%dof%d\"\n",
    "FF_OVERFLOW = \"Overflow\"\n",
    "FF_GENERIC = \"_%s_\" + FF_SCALE\n",
    "FF_FRAC_AT_D = F_FRAC_AT_D + FF_GENERIC\n",
    "FF_MEAN_FRAC = F_MEAN_FRAC + FF_GENERIC\n",
    "FF_RADIAL_CV = F_RADIAL_CV + FF_GENERIC\n",
    "\n",
    "FF_ZERNIKE_MAGNITUDE = \"ZernikeMagnitude\"\n",
    "FF_ZERNIKE_PHASE = \"ZernikePhase\"\n",
    "\n",
    "MF_FRAC_AT_D = \"_\".join((M_CATEGORY, FF_FRAC_AT_D))\n",
    "MF_MEAN_FRAC = \"_\".join((M_CATEGORY, FF_MEAN_FRAC))\n",
    "MF_RADIAL_CV = \"_\".join((M_CATEGORY, FF_RADIAL_CV))\n",
    "OF_FRAC_AT_D = \"_\".join((M_CATEGORY, F_FRAC_AT_D, \"%s\", FF_OVERFLOW))\n",
    "OF_MEAN_FRAC = \"_\".join((M_CATEGORY, F_MEAN_FRAC, \"%s\", FF_OVERFLOW))\n",
    "OF_RADIAL_CV = \"_\".join((M_CATEGORY, F_RADIAL_CV, \"%s\", FF_OVERFLOW))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def centers_of_labels(labels):\n",
    "    \"\"\"Return the i,j coordinates of the centers of a labels matrix\n",
    "    \n",
    "    The result returned is an 2 x n numpy array where n is the number\n",
    "    of the label minus one, result[0,x] is the i coordinate of the center\n",
    "    and result[x,1] is the j coordinate of the center.\n",
    "    You can unpack the result as \"i,j = centers_of_labels(labels)\"\n",
    "    \"\"\"\n",
    "    max_labels = np.max(labels)\n",
    "    if max_labels == 0:\n",
    "        return np.zeros((2, 0), int)\n",
    "\n",
    "    result = center_of_mass(\n",
    "        np.ones(labels.shape), labels, np.arange(max_labels) + 1\n",
    "    )\n",
    "    result = np.array(result)\n",
    "    if result.ndim == 1:\n",
    "        result.shape = (2, 1)\n",
    "        return result\n",
    "    return result.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def maximum_position_of_labels(image, labels, indices):\n",
    "    \"\"\"Return the i,j coordinates of the maximum value within each object\n",
    "    \n",
    "    image - measure the maximum within this image\n",
    "    labels - use the objects within this labels matrix\n",
    "    indices - label #s to measure\n",
    "    \n",
    "    The result returned is an 2 x n numpy array where n is the number\n",
    "    of the label minus one, result[0,x] is the i coordinate of the center\n",
    "    and result[x,1] is the j coordinate of the center.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(indices) == 0:\n",
    "        return np.zeros((2, 0), int)\n",
    "\n",
    "    result = maximum_position(image, labels, indices)\n",
    "    result = np.array(result, int)\n",
    "    if result.ndim == 1:\n",
    "        result.shape = (2, 1)\n",
    "        return result\n",
    "    return result.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def size_similarly(labels, secondary):\n",
    "    \"\"\"Size the secondary matrix similarly to the labels matrix\n",
    "\n",
    "    labels - labels matrix\n",
    "    secondary - a secondary image or labels matrix which might be of\n",
    "                different size.\n",
    "    Return the resized secondary matrix and a mask indicating what portion\n",
    "    of the secondary matrix is bogus (manufactured values).\n",
    "\n",
    "    Either the mask is all ones or the result is a copy, so you can\n",
    "    modify the output within the unmasked region w/o destroying the original.\n",
    "    \"\"\"\n",
    "    if labels.shape[:2] == secondary.shape[:2]:\n",
    "        return secondary, np.ones(secondary.shape, bool)\n",
    "    if labels.shape[0] <= secondary.shape[0] and labels.shape[1] <= secondary.shape[1]:\n",
    "        if secondary.ndim == 2:\n",
    "            return (\n",
    "                secondary[: labels.shape[0], : labels.shape[1]],\n",
    "                np.ones(labels.shape, bool),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                secondary[: labels.shape[0], : labels.shape[1], :],\n",
    "                np.ones(labels.shape, bool),\n",
    "            )\n",
    "\n",
    "    # Some portion of the secondary matrix does not cover the labels\n",
    "    result = np.zeros(\n",
    "        list(labels.shape) + list(secondary.shape[2:]), secondary.dtype\n",
    "    )\n",
    "    i_max = min(secondary.shape[0], labels.shape[0])\n",
    "    j_max = min(secondary.shape[1], labels.shape[1])\n",
    "    if secondary.ndim == 2:\n",
    "        result[:i_max, :j_max] = secondary[:i_max, :j_max]\n",
    "    else:\n",
    "        result[:i_max, :j_max, :] = secondary[:i_max, :j_max, :]\n",
    "    mask = np.zeros(labels.shape, bool)\n",
    "    mask[:i_max, :j_max] = 1\n",
    "    return result, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fixup_scipy_ndimage_result(whatever_it_returned):\n",
    "    \"\"\"Convert a result from scipy.ndimage to a numpy array\n",
    "    \n",
    "    scipy.ndimage has the annoying habit of returning a single, bare\n",
    "    value instead of an array if the indexes passed in are of length 1.\n",
    "    For instance:\n",
    "    scind.maximum(image, labels, [1]) returns a float\n",
    "    but\n",
    "    scind.maximum(image, labels, [1,2]) returns a list\n",
    "    \"\"\"\n",
    "    if getattr(whatever_it_returned, \"__getitem__\", False):\n",
    "        return np.array(whatever_it_returned)\n",
    "    else:\n",
    "        return np.array([whatever_it_returned])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (897300926.py, line 139)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 139\u001b[0;36m\u001b[0m\n\u001b[0;31m    number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def do_measurements(\n",
    "        self,\n",
    "        workspace,\n",
    "        image_name,\n",
    "        object_name,\n",
    "        center_object_name,\n",
    "        center_choice,\n",
    "        bin_count_settings,\n",
    "        dd,\n",
    "    ):\n",
    "    \"\"\"Perform the radial measurements on the image set\n",
    "\n",
    "    workspace - workspace that holds images / objects\n",
    "    image_name - make measurements on this image\n",
    "    object_name - make measurements on these objects\n",
    "    center_object_name - use the centers of these related objects as\n",
    "                    the centers for radial measurements. None to use the\n",
    "                    objects themselves.\n",
    "    center_choice - the user's center choice for this object:\n",
    "                    C_SELF, C_CENTERS_OF_OBJECTS or C_EDGES_OF_OBJECTS.\n",
    "    bin_count_settings - the bin count settings group\n",
    "    dd - a dictionary for saving reusable partial results\n",
    "\n",
    "    returns one statistics tuple per ring.\n",
    "    \"\"\"\n",
    "    bin_count = bin_count_settings.bin_count.value\n",
    "    wants_scaled = bin_count_settings.wants_scaled.value\n",
    "    maximum_radius = bin_count_settings.maximum_radius.value\n",
    "    image = workspace.image_set.get_image(image_name, must_be_grayscale=True)\n",
    "    objects = workspace.object_set.get_objects(object_name)\n",
    "    labels, pixel_data = crop_labels_and_image(objects.segmented, image.pixel_data)\n",
    "    nobjects = np.max(objects.segmented)\n",
    "    measurements = workspace.measurements\n",
    "\n",
    "    d_to_edge = distance_to_edge(labels) # made a local version\n",
    "    if center_object_name is not None:\n",
    "        #\n",
    "        # Use the center of the centering objects to assign a center\n",
    "        # to each labeled pixel using propagation\n",
    "        #\n",
    "        center_objects = workspace.object_set.get_objects(center_object_name)\n",
    "\n",
    "        center_labels, cmask = size_similarly(labels, center_objects.segmented)\n",
    "        pixel_counts = fixup_scipy_ndimage_result(\n",
    "            ndi_sum(\n",
    "                np.ones(center_labels.shape),\n",
    "                center_labels,\n",
    "                np.arange(\n",
    "                    1, np.max(center_labels) + 1, dtype=np.int32\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        good = pixel_counts > 0\n",
    "        i, j = ( centers_of_labels(center_labels) + 0.5).astype(int)\n",
    "        ig = i[good]\n",
    "        jg = j[good]\n",
    "        lg = np.arange(1, len(i) + 1)[good]\n",
    "        if (center_choice == C_CENTERS_OF_OTHERS):  # Reduce the propagation labels to the centers of the centering objects\n",
    "            center_labels = np.zeros(center_labels.shape, int)\n",
    "            center_labels[ig, jg] = lg\n",
    "\n",
    "        cl, d_from_center = centrosome.propagate.propagate(  np.zeros(center_labels.shape), center_labels, labels != 0, 1)\n",
    "        cl[labels == 0] = 0            # Erase the centers that fall outside of labels\n",
    "\n",
    "        # If objects are hollow or crescent-shaped, there may be objects without center labels. As a backup, find the\n",
    "        # center that is the closest to the center of mass.\n",
    "        missing_mask = (labels != 0) & (cl == 0)\n",
    "        missing_labels = np.unique(labels[missing_mask])\n",
    "\n",
    "        if len(missing_labels):\n",
    "            all_centers = centers_of_labels(labels)\n",
    "            missing_i_centers, missing_j_centers = all_centers[:, missing_labels-1]\n",
    "            di = missing_i_centers[:, np.newaxis] - ig[np.newaxis, :]\n",
    "            dj = missing_j_centers[:, np.newaxis] - jg[np.newaxis, :]\n",
    "            missing_best = lg[np.argsort(di * di + dj * dj)[:, 0]]\n",
    "            best = np.zeros(np.max(labels) + 1, int)\n",
    "            best[missing_labels] = missing_best\n",
    "            cl[missing_mask] = best[labels[missing_mask]]\n",
    "\n",
    "            # Now compute the crow-flies distance to the centers of these pixels from whatever center was assigned to the object.\n",
    "            iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "            di = iii[missing_mask] - i[cl[missing_mask] - 1]\n",
    "            dj = jjj[missing_mask] - j[cl[missing_mask] - 1]\n",
    "            d_from_center[missing_mask] = np.sqrt(di * di + dj * dj)\n",
    "    else:\n",
    "        # Find the point in each object farthest away from the edge.\n",
    "        # This does better than the centroid:\n",
    "        # * The center is within the object\n",
    "        # * The center tends to be an interesting point, like the center of the nucleus or the center of one or the other of two touching cells.\n",
    "        i, j = maximum_position_of_labels(   d_to_edge, labels, objects.indices )\n",
    "        center_labels = np.zeros(labels.shape, int)\n",
    "        center_labels[i, j] = labels[i, j]\n",
    "        # Use the coloring trick here to process touching objectsin separate operations\n",
    "        colors = color_labels(labels)\n",
    "        ncolors = np.max(colors)\n",
    "        d_from_center = np.zeros(labels.shape)\n",
    "        cl = np.zeros(labels.shape, int)\n",
    "\n",
    "        for color in range(1, ncolors + 1):\n",
    "            mask = colors == color\n",
    "            l, d = centrosome.propagate.propagate( np.zeros(center_labels.shape), center_labels, mask, 1)\n",
    "            d_from_center[mask] = d[mask]\n",
    "            cl[mask] = l[mask]\n",
    "\n",
    "        good_mask = cl > 0\n",
    "\n",
    "        if (center_choice == C_EDGES_OF_OTHER):\n",
    "            # Exclude pixels within the centering objects\n",
    "            # when performing calculations from the centers\n",
    "            good_mask = good_mask & (center_labels == 0)\n",
    "        i_center = np.zeros(cl.shape)\n",
    "        i_center[good_mask] = i[cl[good_mask] - 1]\n",
    "        j_center = np.zeros(cl.shape)\n",
    "        j_center[good_mask] = j[cl[good_mask] - 1]\n",
    "        normalized_distance = np.zeros(labels.shape)\n",
    "\n",
    "        if wants_scaled:\n",
    "            total_distance = d_from_center + d_to_edge\n",
    "            normalized_distance[good_mask] = d_from_center[good_mask] / ( total_distance[good_mask] + 0.001 )\n",
    "        else:\n",
    "            normalized_distance[good_mask] = (d_from_center[good_mask] / maximum_radius)\n",
    "        dd[name] = [normalized_distance, i_center, j_center, good_mask]\n",
    "\n",
    "\n",
    "\n",
    "    ngood_pixels = np.sum(good_mask)\n",
    "    good_labels = labels[good_mask]\n",
    "    bin_indexes = (normalized_distance * bin_count).astype(int)\n",
    "    bin_indexes[bin_indexes > bin_count] = bin_count\n",
    "    labels_and_bins = (good_labels - 1, bin_indexes[good_mask])\n",
    "\n",
    "    histogram = coo_matrix( (pixel_data[good_mask], labels_and_bins), (nobjects, bin_count + 1) ).toarray()\n",
    "\n",
    "    sum_by_object = np.sum(histogram, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_distance = histogram / sum_by_object_per_bin\n",
    "    number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\n",
    "\n",
    "    object_mask = number_at_distance > 0\n",
    "    sum_by_object = np.sum(number_at_distance, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_bin = number_at_distance / sum_by_object_per_bin\n",
    "    mean_pixel_fraction = fraction_at_distance / ( fraction_at_bin + np.finfo(float).eps    )\n",
    "    masked_fraction_at_distance = np.ma.masked_array( fraction_at_distance, ~object_mask )\n",
    "    masked_mean_pixel_fraction = np.ma.masked_array(mean_pixel_fraction, ~object_mask)\n",
    "\n",
    "    # Anisotropy calculation.  Split each cell into eight wedges, then compute coefficient of variation of the wedges' mean intensities\n",
    "    # in each ring. Compute each pixel's delta from the center object's centroid\n",
    "    i, j = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "    imask = i[good_mask] > i_center[good_mask]\n",
    "    jmask = j[good_mask] > j_center[good_mask]\n",
    "    absmask = abs(i[good_mask] - i_center[good_mask]) > abs(\n",
    "        j[good_mask] - j_center[good_mask]\n",
    "    )\n",
    "    radial_index = (\n",
    "        imask.astype(int) + jmask.astype(int) * 2 + absmask.astype(int) * 4\n",
    "    )\n",
    "    statistics = []\n",
    "\n",
    "    for bin in range(bin_count + (0 if wants_scaled else 1)):\n",
    "        bin_mask = good_mask & (bin_indexes == bin)\n",
    "        bin_pixels = np.sum(bin_mask)\n",
    "        bin_labels = labels[bin_mask]\n",
    "        bin_radial_index = radial_index[bin_indexes[good_mask] == bin]\n",
    "        labels_and_radii = (bin_labels - 1, bin_radial_index)\n",
    "        radial_values = coo_matrix( (pixel_data[bin_mask], labels_and_radii), (nobjects, 8) ).toarray()\n",
    "        pixel_count = coo_matrix( (np.ones(bin_pixels), labels_and_radii), (nobjects, 8) ).toarray()\n",
    "\n",
    "        mask = pixel_count == 0\n",
    "        radial_means = np.ma.masked_array(radial_values / pixel_count, mask)\n",
    "        radial_cv = np.std(radial_means, 1) / np.mean(radial_means, 1)\n",
    "        radial_cv[np.sum(~mask, 1) == 0] = 0\n",
    "\n",
    "        for measurement, feature, overflow_feature in (\n",
    "            (fraction_at_distance[:, bin], MF_FRAC_AT_D, OF_FRAC_AT_D),\n",
    "            (mean_pixel_fraction[:, bin], MF_MEAN_FRAC, OF_MEAN_FRAC),\n",
    "            (np.array(radial_cv), MF_RADIAL_CV, OF_RADIAL_CV),\n",
    "        ):\n",
    "            if bin == bin_count:\n",
    "                measurement_name = overflow_feature % image_name\n",
    "            else:\n",
    "                measurement_name = feature % (image_name, bin + 1, bin_count)\n",
    " \n",
    "           measurements.add_measurement(object_name, measurement_name, measurement)\n",
    "\n",
    "            # if feature in heatmaps:\n",
    "            #     heatmaps[feature][bin_mask] = measurement[bin_labels - 1]\n",
    "\n",
    "        radial_cv.mask = np.sum(~mask, 1) == 0\n",
    "        bin_name = str(bin + 1) if bin < bin_count else \"Overflow\"\n",
    "\n",
    "        statistics += [\n",
    "            (image_name,\n",
    "                object_name,\n",
    "                bin_name,\n",
    "                str(bin_count),\n",
    "                np.round(np.mean(masked_fraction_at_distance[:, bin]), 4),\n",
    "                np.round(np.mean(masked_mean_pixel_fraction[:, bin]), 4),\n",
    "                np.round(np.mean(radial_cv), 4) )\n",
    "        ]\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# MITOCONDRIA\n",
    "###################\n",
    "mito_obj  = get_mito(img_data,meta_dict, out_data_path)\n",
    "mito_table = get_summary_stats_3D( mito_obj, img_data[MITO_CH],cytoplasm_mask)\n",
    "\n",
    "###################\n",
    "#  GOLGI\n",
    "###################\n",
    "golgi_obj = get_golgi(img_data,meta_dict, out_data_path)\n",
    "golgi_obj = get_summary_stats_3D( golgi_obj, img_data[GOLGI_CH],cytoplasm_mask)\n",
    "\n",
    "###################\n",
    "#  PEROXISOME\n",
    "###################\n",
    "perox_obj  = get_perox(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  ER\n",
    "###################\n",
    "er_obj  = get_ER(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  LIPID BODIES\n",
    "###################\n",
    "LD_obj  =  get_LD(img_data,meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(lyso_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(florescence)\n",
    "viewer.add_image(cytoplasm_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi as PI\n",
    "\n",
    "table['equivalent_diameter'], table['area'], (2 * 3 *  table['area'] / PI) ** (1 /3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SOMA, NUCLEI, CYTOSOL, NUCLEUS\n",
    "###################\n",
    "nuclei_obj =  infer_and_export_nuclei(img_data,meta_dict, out_data_path)\n",
    "\n",
    "soma_obj = infer_and_export_soma(img_data, nuclei,meta_dict, out_data_path)\n",
    "cytoplasm_mask =  infer_and_export_cytoplasm(soma_obj, nuclei_obj, meta_dict, out_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(cytoplasm_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LYSOSOME\n",
    "###################\n",
    "lyso_obj  = get_lyso(img_data,meta_dict, out_data_path)\n",
    "florescence = apply_mask(img_data[LYSO_CH],cytoplasm_mask )  \n",
    "lyso_table = get_summary_stats_3D(lyso_obj, florescence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# LYSOSOME\n",
    "###################\n",
    "lyso = infer_and_export_lyso(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "# MITOCONDRIA\n",
    "###################\n",
    "mitochondria = infer_and_export_mito(img_data,meta_dict, out_data_path)\n",
    "###################\n",
    "#  GOLGI\n",
    "###################\n",
    "golgi = infer_and_export_golgi(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  PEROXISOME\n",
    "###################\n",
    "peroxisome = infer_and_export_perox(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  ER\n",
    "###################\n",
    "er = infer_and_export_ER(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  LIPID BODIES\n",
    "###################\n",
    "lipid =  infer_and_export_LD(img_data,meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops_table\n",
    "\n",
    "def collect_organelle_stats(\n",
    "                                    img_in:np.ndarray, \n",
    "                                    florescence:Union[np.ndarray,None]=None\n",
    "                                    ): \n",
    "\n",
    "    properties = ['label']\n",
    "    extra_properties = []\n",
    "    size = False \n",
    "    perimeter = False \n",
    "    shape = True \n",
    "    position = True \n",
    "    moments = True\n",
    "\n",
    "    labels = label(img_in).astype(\"int\").squeeze()\n",
    "    intensity_image = None if florescence is None else florescence.squeeze()\n",
    "    intensity = intensity_image is not None # depricate for now because the \"infered object\" doesn't have intensity\n",
    "\n",
    "\n",
    "    if size:\n",
    "        properties = properties + ['area', 'bbox_area',  'equivalent_diameter'] #'convex_area',\n",
    "\n",
    "    if intensity:\n",
    "        properties = properties + ['max_intensity', 'mean_intensity', 'min_intensity']\n",
    "        # arguments must be in the specified order, matching regionprops\n",
    "        def standard_deviation_intensity(region, intensities):\n",
    "            return np.std(intensities[region])\n",
    "        extra_properties.append(standard_deviation_intensity)\n",
    "\n",
    "    if perimeter:\n",
    "        if len(labels.shape) == 2:\n",
    "            properties = properties + ['perimeter', 'perimeter_crofton']\n",
    "        else:\n",
    "            print(\"Perimeter measurements are not supported in 3D\")\n",
    "            # warnings.warn(\"Perimeter measurements are not supported in 3D\")\n",
    "\n",
    "    if shape:\n",
    "        properties = properties + ['solidity', 'extent', 'feret_diameter_max', 'local_centroid']\n",
    "        if len(labels.shape) == 2:\n",
    "            properties = properties + ['major_axis_length', 'minor_axis_length', 'orientation', 'eccentricity']\n",
    "            # we need these two to compute some shape descriptors\n",
    "            if not size:\n",
    "                properties = properties + ['area']\n",
    "            if not perimeter:\n",
    "                properties = properties + ['perimeter']\n",
    "        else:\n",
    "            properties = properties + ['moments_central']\n",
    "        # euler_number,\n",
    "\n",
    "    if position:\n",
    "        properties = properties + ['centroid', 'bbox', 'weighted_centroid']\n",
    "\n",
    "    if moments:\n",
    "        properties = properties + ['moments', 'moments_normalized']\n",
    "        if 'moments_central' not in properties:\n",
    "            properties = properties + ['moments_central']\n",
    "        if len(labels.shape) == 2:\n",
    "            properties = properties + ['moments_hu']\n",
    "\n",
    "    # todo:\n",
    "    # weighted_local_centroid\n",
    "    # weighted_moments\n",
    "    # weighted_moments_central\n",
    "    # weighted_moments_hu\n",
    "    # weighted_moments_normalized\n",
    "\n",
    "    # quantitative analysis using scikit-image's regionprops\n",
    "    print(labels.shape)\n",
    "    print(properties)\n",
    "    table = regionprops_table(labels, intensity_image=intensity_image,\n",
    "                                properties=properties, extra_properties=extra_properties)\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "organelles = [nuclei,\n",
    "                            lyso,\n",
    "                            mitochondria,\n",
    "                            golgi,\n",
    "                            peroxisome,\n",
    "                            er,\n",
    "                            lipid]\n",
    "\n",
    "organelle_names = [\"nuclei\",\"lyso\", \"mitochondria\",\"golgi\",\"peroxisome\",\"er\",\"lipid\"]\n",
    "organelle_channel = [NUC_CH,LYSO_CH,MITO_CH,GOLGI_CH,PEROX_CH,ER_CH,LD_CH]\n",
    "\n",
    "stats_bag = []\n",
    "for i,o in enumerate(organelle_names):\n",
    "    print(f\"{o}- {organelle_channel[i]}\")\n",
    "    org = organelles[i]\n",
    "    ch = organelle_channel[i]\n",
    "    florescence = img_data[ch]\n",
    "\n",
    "    # apply mask \n",
    "    mask = cellmask if ch==NUC_CH else cytoplasm\n",
    "\n",
    "    org = apply_mask(org, mask)\n",
    "    florescence = apply_mask(org,mask)  \n",
    "    _stats = collect_organelle_stats(org, florescence)\n",
    "    stats_bag.append(_stats)\n",
    "\n",
    "    # get lablels of masked organelle\n",
    "\n",
    "    # export\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_bag = []\n",
    "for i,o in enumerate(organelle_names):\n",
    "    print(f\"{o}- {organelle_channel[i]}\")\n",
    "    org = organelles[i]\n",
    "    ch = organelle_channel[i]\n",
    "    florescence = img_data[ch]\n",
    "\n",
    "    # apply mask \n",
    "    mask = cellmask if ch==NUC_CH else cytoplasm\n",
    "\n",
    "    org = apply_mask(org, mask)\n",
    "    florescence = apply_mask(org,mask)  \n",
    "    _stats = collect_organelle_stats(org, florescence)\n",
    "    stats_bag.append(_stats)\n",
    "\n",
    "    # get lablels of masked organelle\n",
    "\n",
    "    # export\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# LYSOSOME\n",
    "###################\n",
    "lyso_object =  fixed_infer_lyso(img_data) \n",
    "\n",
    "###################\n",
    "# MITOCONDRIA\n",
    "###################\n",
    "mito_object =  fixed_infer_mito(img_data) \n",
    "###################\n",
    "#  GOLGI\n",
    "###################\n",
    "golgi_object =  fixed_infer_golgi(img_data) \n",
    "\n",
    "###################\n",
    "#  PEROXISOME\n",
    "###################\n",
    "peroxi_object =  fixed_infer_perox(img_data) \n",
    "\n",
    "###################\n",
    "#  ER\n",
    "###################\n",
    "er_object =  fixed_infer_ER(img_data) \n",
    "\n",
    "###################\n",
    "#  LIPID BODIES\n",
    "###################\n",
    "LD_object =  fixed_infer_LD(img_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layers = [soma_mask,\n",
    "                            nuclei_object,\n",
    "                            cytoplasm_mask,\n",
    "                            lyso_object,\n",
    "                            mito_object,\n",
    "                            golgi_object,\n",
    "                            peroxi_object,\n",
    "                            er_object,\n",
    "                            LD_object ]\n",
    "\n",
    "\n",
    "organelle_names = [\"cellmask\",\"nuclei\",\"cytoplasm\",\"lyso\", \"mitochondria\",\"golgi\",\"peroxisome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label(soma_mask).astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionprops_table(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # load region properties from csv file\n",
    "# reg_props = pd.read_csv(csv_filename)\n",
    "# try:\n",
    "#     edited_reg_props = reg_props.drop([\"Unnamed: 0\"], axis=1)\n",
    "# except KeyError:\n",
    "#     edited_reg_props = reg_props\n",
    "\n",
    "# if \"label\" not in edited_reg_props.keys().tolist():\n",
    "#     label_column = pd.DataFrame(\n",
    "#         {\"label\": np.array(range(1, (len(edited_reg_props) + 1)))}\n",
    "#     )\n",
    "#     edited_reg_props = pd.concat([label_column, edited_reg_props], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_organelles(\n",
    "        segmentation:Union[np.ndarray,None]=None, ,\n",
    "        florescence:Union[np.ndarray,None]=None, \n",
    "        organelle: int,\n",
    "        mask:Union[np.ndarray,None]=None, \n",
    "        # infer_params: Union[dict, None]=None,\n",
    "        # prior:Union[Any,None]=None, \n",
    "        # export_nm:Union[Path, str,None]=None, \n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to get \n",
    "    \n",
    "    Params:\n",
    "    ----------\n",
    "    segmentation:\n",
    "        np.ndarray containing inferred organelle object\n",
    "\n",
    "    florescence:\n",
    "        np.ndarray containing raw organelle image\n",
    "\n",
    "    organelle:\n",
    "        channel of organelle to process: nuclei,  NUC_CH = 0, LYSO_CH = 1, MITO_CH = 2, GOLGI_CH = 3, PEROX_CH = 4, ER_CH = 5, LD_CH = 6, RESIDUAL_CH = 7\n",
    "\n",
    "    in_image:\n",
    "        optional np.ndarray containing raw organelle image\n",
    "\n",
    "    mask:\n",
    "        optional mask (cellmask or cytoplasm)\n",
    "    \n",
    "    stats:\n",
    "        optiohal Prior class\n",
    "    \n",
    "    export:\n",
    "        boolean flag to export - default True\n",
    "    \"\"\"\n",
    "    # CHOOSE which inferred organelle to \n",
    "    if organelle == NUC_CH: #0\n",
    "        organelle_name = 'nucleus'\n",
    "    elif organelle == LYSO_CH: #1 \n",
    "        organelle_name = 'lyso'\n",
    "    elif organelle == MITO_CH: #2\n",
    "        organelle_name = 'mitochondria'\n",
    "    elif organelle == GOLGI_CH: #3\n",
    "        organelle_name = 'golgi'\n",
    "    elif organelle == PEROX_CH: #4\n",
    "        organelle_name = 'peroxisome'\n",
    "    elif organelle == ER_CH: #5\n",
    "        organelle_name = 'ER'\n",
    "    elif organelle == LD_CH: #6 \n",
    "        organelle_name = 'lipid'\n",
    "    elif organelle == RESIDUAL_CH: #7\n",
    "        organelle_name = 'residual'\n",
    "\n",
    "    print(organelle_name)\n",
    "\n",
    "    target = segmentation[organelle].squeeze()\n",
    "    target = apply_mask(target, mask.squeeze())    \n",
    "    target_intensity = florescence[organelle].squeeze()\n",
    "\n",
    "    summary_stats = collect_organelle_stats(\n",
    "                                    target, \n",
    "                                    target_intensity\n",
    "                                    )\n",
    "    # test if it worked\n",
    "    labels = label(img_in).astype(\"int\").squeeze()\n",
    "\n",
    "    # export\n",
    "\n",
    "    # return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['label']\n",
    "extra_properties = []\n",
    "size = True \n",
    "perimeter = True \n",
    "shape = True \n",
    "position = True \n",
    "moments = True\n",
    "\n",
    "labels = label(img_in).astype(\"int\").squeeze()\n",
    "intensity_image = None if florescence is None else florescence.squeeze()\n",
    "intensity = intensity_image is not None # depricate for now because the \"infered object\" doesn't have intensity\n",
    "\n",
    "\n",
    "if size:\n",
    "    properties = properties + ['area', 'bbox_area',  'equivalent_diameter'] #'convex_area',\n",
    "\n",
    "if intensity:\n",
    "    properties = properties + ['max_intensity', 'mean_intensity', 'min_intensity']\n",
    "    # arguments must be in the specified order, matching regionprops\n",
    "    def standard_deviation_intensity(region, intensities):\n",
    "        return np.std(intensities[region])\n",
    "    extra_properties.append(standard_deviation_intensity)\n",
    "\n",
    "if perimeter:\n",
    "    if len(labels.shape) == 2:\n",
    "        properties = properties + ['perimeter', 'perimeter_crofton']\n",
    "    else:\n",
    "        print(\"Perimeter measurements are not supported in 3D\")\n",
    "        # warnings.warn(\"Perimeter measurements are not supported in 3D\")\n",
    "        properties = properties + ['perimeter', 'perimeter_crofton']\n",
    "\n",
    "if shape:\n",
    "    properties = properties + ['solidity', 'extent', 'feret_diameter_max', 'local_centroid']\n",
    "    if len(labels.shape) == 2:\n",
    "        properties = properties + ['major_axis_length', 'minor_axis_length', 'orientation', 'eccentricity']\n",
    "        # we need these two to compute some shape descriptors\n",
    "        if not size:\n",
    "            properties = properties + ['area']\n",
    "        if not perimeter:\n",
    "            properties = properties + ['perimeter']\n",
    "    else:\n",
    "        properties = properties + ['moments_central']\n",
    "    # euler_number,\n",
    "\n",
    "if position:\n",
    "    properties = properties + ['centroid', 'bbox', 'weighted_centroid']\n",
    "\n",
    "if moments:\n",
    "    properties = properties + ['moments', 'moments_normalized']\n",
    "    if 'moments_central' not in properties:\n",
    "        properties = properties + ['moments_central']\n",
    "    if len(labels.shape) == 2:\n",
    "        properties = properties + ['moments_hu']\n",
    "\n",
    "# todo:\n",
    "# weighted_local_centroid\n",
    "# weighted_moments\n",
    "# weighted_moments_central\n",
    "# weighted_moments_hu\n",
    "# weighted_moments_normalized\n",
    "\n",
    "# quantitative analysis using scikit-image's regionprops\n",
    "print(labels.shape)\n",
    "print(properties)\n",
    "table = regionprops_table(labels, intensity_image=intensity_image,\n",
    "                            properties=properties, extra_properties=extra_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organelle = 1\n",
    "mask = cytoplasm_mask\n",
    "segmentation = np.stack([\n",
    "                            nuclei_object,\n",
    "                            lyso_object,\n",
    "                            mito_object,\n",
    "                            golgi_object,\n",
    "                            peroxi_object,\n",
    "                            er_object,\n",
    "                            LD_object ])\n",
    "\n",
    "florescence = img_2D[:-1] # throw out residual\n",
    "\n",
    "\n",
    "florescence.shape, segmentation.shape, mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CHOOSE which inferred organelle to \n",
    "if organelle == NUC_CH: #0\n",
    "    organelle_name = 'nucleus'\n",
    "elif organelle == LYSO_CH: #1 \n",
    "    organelle_name = 'lyso'\n",
    "elif organelle == MITO_CH: #2\n",
    "    organelle_name = 'mitochondria'\n",
    "elif organelle == GOLGI_CH: #3\n",
    "    organelle_name = 'golgi'\n",
    "elif organelle == PEROX_CH: #4\n",
    "    organelle_name = 'peroxisome'\n",
    "elif organelle == ER_CH: #5\n",
    "    organelle_name = 'ER'\n",
    "elif organelle == LD_CH: #6 \n",
    "    organelle_name = 'lipid'\n",
    "elif organelle == RESIDUAL_CH: #7\n",
    "    organelle_name = 'residual'\n",
    "\n",
    "print(organelle_name)\n",
    "\n",
    "target = segmentation[organelle].squeeze()\n",
    "target = apply_mask(target, mask.squeeze())    \n",
    "target_intensity = florescence[organelle].squeeze()\n",
    "\n",
    "labels = label(target).astype(\"int\").squeeze()\n",
    "\n",
    "\n",
    "summary_stats = collect_organelle_stats(\n",
    "                                target, \n",
    "                                target_intensity\n",
    "                                )\n",
    "# target.shape, target_intensity.shape, labels.shape\n",
    "\n",
    "labels.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop over all labeled organelles\n",
    "for org_i in range(1,labels.max()+1):\n",
    "    # extract org_i mask\n",
    "    msk_i = labels == org_i\n",
    "    intersect = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "label_image = labels\n",
    "\n",
    "input_props = regionprops(\n",
    "    label_image, intensity_image=None, cache=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_props[0].coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_centroids = [np.int_(obj[\"centroid\"]) for obj in input_props]\n",
    "input_centroids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_segmented = np.zeros_like(label_image)\n",
    "\n",
    "for ind, arr in enumerate(input_centroids):\n",
    "    output_segmented[tuple(arr)] = ind + 1\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.view_image(output_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_stats = collect_organelle_stats(\n",
    "                                target, \n",
    "                                target_intensity\n",
    "                                )\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "stats_table = pd.DataFrame(summary_stats)\n",
    "stats_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack(img_layers, axis=0).shape\n",
    "nuclei_table =  collect_organelle_stats(nuclei_object)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "nuc = pd.DataFrame(nuclei_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyso_table =  collect_organelle_stats(lyso_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.view_image(lyso_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.view_labels(label(lyso_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyso_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with `napari` 1\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    nuclei_object,\n",
    "    scale=scale,\n",
    "    colormap='blue', \n",
    "    blending='additive'\n",
    ")\n",
    "viewer.add_image(\n",
    "    lyso_object,\n",
    "    scale=scale,\n",
    "    colormap='cyan', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    mito_object,\n",
    "    scale=scale,\n",
    "    colormap='green', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    golgi_object,\n",
    "    scale=scale,\n",
    "    colormap='yellow', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    peroxi_object,\n",
    "    scale=scale,\n",
    "    colormap='bop orange', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    er_object,\n",
    "    scale=scale,\n",
    "    blending='additive')\n",
    "\n",
    "viewer.add_image(\n",
    "    LD_object,\n",
    "    scale=scale,\n",
    "    blending='additive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.scale_bar.visible = True\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "# viewer.dims.ndisplay = 3\n",
    "# viewer.camera.angles = (-30, 25, 120)\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There may be a bug where the input images to the \"infer_*\" functions are modified in place and we might need to access them.  _MASKING_ seems to be the problem.  Also need to be clear about _when_ to apply the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.core.img import select_z_from_raw\n",
    "###########\n",
    "# infer organelles\n",
    "##########\n",
    "def _fixed_infer_organelles(img_data):\n",
    "    \"\"\"\n",
    "    wrapper to infer all organelles from a single multi-channel image\n",
    "    \"\"\"\n",
    "    # ch_to_agg = (LYSO_CH, MITO_CH, GOLGI_CH, PEROX_CH, ER_CH, LD_CH)\n",
    "\n",
    "    # nuc_ch = NUC_CH\n",
    "    # optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg)\n",
    "    # # Stage 1:  nuclei, cellmask, cytoplasm\n",
    "    # img_2D = select_z_from_raw(img_data, optimal_Z)\n",
    "    img_2D = fixed_get_optimal_Z_image(img_data)\n",
    "\n",
    "    soma_mask = fixed_infer_cellmask_fromaggr(img_2D)\n",
    "\n",
    "    nuclei_object = fixed_infer_nuclei(img_2D, soma_mask)\n",
    "\n",
    "    cytoplasm_mask = infer_cytoplasm(nuclei_object, soma_mask)\n",
    "\n",
    "    # cyto masked objects.\n",
    "    lyso_object = fixed_infer_lyso(img_2D, cytoplasm_mask)\n",
    "    mito_object = fixed_infer_mito(img_2D, cytoplasm_mask)\n",
    "    golgi_object = fixed_infer_golgi(img_2D, cytoplasm_mask)\n",
    "    peroxi_object = fixed_infer_perox(img_2D, cytoplasm_mask)\n",
    "    er_object = fixed_infer_ER(img_2D, cytoplasm_mask)\n",
    "    LD_object = fixed_infer_LD(img_2D, cytoplasm_mask)\n",
    "\n",
    "    img_layers = [\n",
    "        nuclei_object,\n",
    "        lyso_object,\n",
    "        mito_object,\n",
    "        golgi_object,\n",
    "        peroxi_object,\n",
    "        er_object,\n",
    "        LD_object,\n",
    "        soma_mask,\n",
    "        cytoplasm_mask,\n",
    "    ]\n",
    "\n",
    "    layer_names = [\n",
    "        \"nuclei\",\n",
    "        \"lyso\",\n",
    "        \"mitochondria\",\n",
    "        \"golgi\",\n",
    "        \"peroxisome\",\n",
    "        \"er\",\n",
    "        \"LD_body\",\n",
    "        \"soma_mask\",\n",
    "        \"cytoplasm_mask\",\n",
    "    ]\n",
    "    # TODO: pack outputs into something napari readable\n",
    "    img_out = np.stack(img_layers, axis=0)\n",
    "    return (img_out, layer_names, optimal_Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stack_organelle_objects(soma_mask,\n",
    "                            nuclei_object,\n",
    "                            cytoplasm_mask,\n",
    "                            lyso_object,\n",
    "                            mito_object,\n",
    "                            golgi_object,\n",
    "                            peroxi_object,\n",
    "                            er_object,\n",
    "                            LD_object) -> np.ndarray:\n",
    "    \"\"\" wrapper to stack the inferred objects into a single numpy.ndimage \"\"\"\n",
    "    img_layers = [soma_mask,\n",
    "                            nuclei_object,\n",
    "                            cytoplasm_mask,\n",
    "                            lyso_object,\n",
    "                            mito_object,\n",
    "                            golgi_object,\n",
    "                            peroxi_object,\n",
    "                            er_object,\n",
    "                            LD_object]\n",
    "    return np.stack(img_layers, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_organelle_layers(*layers) -> np.ndarray:\n",
    "    \"\"\" wrapper to stack the inferred objects into a single numpy.ndimage \"\"\"\n",
    "\n",
    "    return np.stack(layers, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_organelle_objects(*img_layers).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inferred_organelles, layer_names, optimal_Z = _fixed_infer_organelles(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = ['blue','cyan','green','yellow','bop orange','magenta','gray','gray','gray']\n",
    "\n",
    "for i,organelle in enumerate(inferred_organelles):\n",
    "    viewer.add_image(\n",
    "        organelle,\n",
    "        scale=scale,\n",
    "        blending='additive',\n",
    "        name = layer_names[i],\n",
    "        colormap=cmaps[i]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.scale_bar.visible = True\n",
    "\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################\n",
    "# export\n",
    "##################\n",
    "\n",
    "def _export_infer_organelles(img_out, layer_names, meta_dict, data_root_path):\n",
    "       # get some top-level info about the RAW data\n",
    "    # channel_names = meta_dict['name']\n",
    "    # img = meta_dict['metadata']['aicsimage']\n",
    "    # scale = meta_dict['scale']\n",
    "    # channel_axis = meta_dict['channel_axis']\n",
    "    img_name = meta_dict['file_name']\n",
    "    # add params to metadata\n",
    "    meta_dict['layer_names'] = layer_names\n",
    "    out_path = data_root_path / \"inferred_objects\" \n",
    "    img_name_out = 'binarized_' + img_name.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    out_file_n = export_ome_tiff(img_out, meta_dict, img_name_out, str(out_path)+\"/\", layer_names)\n",
    "    print(f\"saved file: {out_file_n}\")\n",
    "    return out_file_n\n",
    "\n",
    "out_file_n = _export_infer_organelles(inferred_organelles, layer_names, meta_dict, data_root_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "run a batch of ALL the images\n",
    "\n",
    "First get all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now build a function to loop over them all and export\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_process_all_czi(data_root_path):\n",
    "\n",
    "    # linearly unmixed \".czi\" files are here\n",
    "    data_path = data_root_path / \"raw\"\n",
    "    im_type = \".czi\"\n",
    "    # get the list of all files\n",
    "    img_file_list = list_image_files(data_path,im_type)\n",
    "    files_generated = []\n",
    "    for czi_file in img_file_list:\n",
    "        out_fn = process_czi_image(czi_file)\n",
    "        files_generated.append(out_fn)\n",
    "\n",
    "    print(f\"generated {len(files_generated)} \")\n",
    "    return files_generated\n",
    "\n",
    "def process_czi_image(czi_file_name):\n",
    "    \"\"\"wrapper for processing\"\"\"\n",
    "\n",
    "    img_data,meta_dict = read_czi_image(czi_file_name)\n",
    "    # # get some top-level info about the RAW data\n",
    "    # channel_names = meta_dict['name']\n",
    "    # img = meta_dict['metadata']['aicsimage']\n",
    "    # scale = meta_dict['scale']\n",
    "    # channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "    inferred_organelles, layer_names,optimal_Z = _infer_organelles(img_data)\n",
    "    meta_dict['z_slice'] = optimal_Z\n",
    "    out_file_n = _export_infer_organelles(inferred_organelles, layer_names, meta_dict, data_root_path)\n",
    "\n",
    "    ## TODO:  collect stats... \n",
    "\n",
    "    return out_file_n\n",
    "\n",
    "# chan_name = 'nuclei'\n",
    "# out_path = data_root_path / \"inferred_objects\" \n",
    "# object_name = 'NU_object'\n",
    "\n",
    "# NU_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "# NU_object = NU_bioim.image\n",
    "# NU_labels = label(NU_object)\n",
    "\n",
    "# # calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "# z_factor = scale[0]//scale[1]\n",
    "# med_filter_size = 4 #2D \n",
    "# med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tiffs = batch_process_all_czi(data_root_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the `infer_cellmask_fromaggr` spec to the widget json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import add_function_spec_to_widget_json\n",
    "\n",
    "_fixed_infer_organelles =  {\n",
    "        \"name\": \"infer all organelles (fixed parameters)\",\n",
    "        \"python::module\": \"infer_subc_2d.batch.batch_process\",\n",
    "        \"python::function\": \"fixed_infer_organelles\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"fixed_infer_organelles\",_fixed_infer_organelles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_stack_organelle_objects =  {\n",
    "        \"name\": \"stack organelles, argv spelled out\",\n",
    "        \"python::module\": \"infer_subc_2d.batch\",\n",
    "        \"python::function\": \"stack_organelle_objects\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"stack_organelle_objects\",_stack_organelle_objects)\n",
    "\n",
    "\n",
    "_stack_organelle_layers =  {\n",
    "        \"name\": \"stack organelles, *argv \",\n",
    "        \"python::module\": \"infer_subc_2d.batch\",\n",
    "        \"python::function\": \"stack_organelle_layers\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"stack_organelle_layers\",_stack_organelle_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## Write workflow .json\n",
    "Now that we've added our function specs we can compose workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fixed_infer_organelles_batch_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "   \n",
    "    ###################\n",
    "    # Stage 1:  nuclei, cellmask, cytoplasm\n",
    "    ###################   \n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"fixed_get_optimal_Z_img\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(0)\n",
    "\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"fixed_infer_cellmask_fromaggr\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append(1)\n",
    "\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"fixed_infer_nuclei\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([1,2])\n",
    "\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(erode_nuclei = True ))\n",
    "    parent.append([2,3])\n",
    "\n",
    "    ###################\n",
    "    # Stage 2:  cyto masked objects\n",
    "    ###################   \n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"fixed_infer_lyso\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None )\n",
    "    parent.append([1,4])\n",
    "\n",
    "    \n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"fixed_infer_mito\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"fixed_infer_golgi\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"8\")\n",
    "    function_name.append(\"fixed_infer_perox\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"9\")\n",
    "    function_name.append(\"fixed_infer_ER\") \n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"10\")\n",
    "    function_name.append(\"fixed_infer_LD\") \n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"11\")\n",
    "    function_name.append(\"stack_organelle_objects\") \n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "\n",
    "    # TODO: add export functions\n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n",
    "\n",
    "infer_fixed_infer_organelles_batch_dict = make_fixed_infer_organelles_batch_dict()\n",
    "\n",
    "write_workflow_json(\"infer_fixed_infer_organelles_batch\", infer_fixed_infer_organelles_batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fixed_infer_organelles_batch_dict2():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "    \"\"\"\n",
    "    \n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "   \n",
    "    ###################\n",
    "    # Stage 1:  nuclei, cellmask, cytoplasm\n",
    "    ###################   \n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"fixed_get_optimal_Z_img\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(0)\n",
    "\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"fixed_infer_cellmask_fromaggr\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append(1)\n",
    "\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"fixed_infer_nuclei\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([1,2])\n",
    "\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(erode_nuclei = True ))\n",
    "    parent.append([2,3])\n",
    "\n",
    "    ###################\n",
    "    # Stage 2:  cyto masked objects\n",
    "    ###################   \n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"fixed_infer_lyso\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None )\n",
    "    parent.append([1,4])\n",
    "\n",
    "    \n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"fixed_infer_mito\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"fixed_infer_golgi\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"8\")\n",
    "    function_name.append(\"fixed_infer_perox\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"9\")\n",
    "    function_name.append(\"fixed_infer_ER\") \n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "    step_name.append(\"10\")\n",
    "    function_name.append(\"fixed_infer_LD\") \n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([1,4])\n",
    "\n",
    "\n",
    "    step_name.append(\"11\")\n",
    "    function_name.append(\"stack_organelle_objects\") \n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "    # TODO: add export functions\n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n",
    "\n",
    "infer_fixed_infer_organelles_batch_dict2 = make_fixed_infer_organelles_batch_dict2()\n",
    "\n",
    "write_workflow_json(\"infer_fixed_infer_organelles_batch2\", infer_fixed_infer_organelles_batch_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make infer_organelles function with the exhaustive list of parmaters\n",
    "_infer_organelles =  {\n",
    "        \"name\": \"Infer Endoplasmic Reticulum\",\n",
    "        \"python::module\": \"infer_subc_2d.organelles\",\n",
    "        \"python::function\": \"infer_ER\",\n",
    "        \"parameters\": {\n",
    "                \"filament_scale\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 10,\n",
    "                        \"min\": 0,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"filament_cut\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.001,\n",
    "                        \"max\": 0.5,\n",
    "                        \"min\": 0,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"small_obj_w\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 50,\n",
    "                        \"min\": 1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "add_function_spec_to_widget_json(\"eeeinfer_organelles\", _infer_organelles, overwrite=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35 files processed in 6 minutes 47 seconds!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tiff_img_data,tiff_meta_dict = read_czi_image(output_tiffs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_img_data.shape\n",
    "\n",
    "img = tiff_meta_dict['metadata']['aicsimage']\n",
    "img.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.writers import OmeTiffWriter\n",
    "data_in = img_out\n",
    "channel_names = [layer_names]\n",
    "image_names = [img_name]\n",
    "print(image_names)\n",
    "# chan_names = meta_in['metadata']['aicsimage'].channel_names\n",
    "dimension_order = [\"CZYX\"]\n",
    "\n",
    "num_images = len(  [data_in.shape])\n",
    "if data_in.dtype == \"bool\":\n",
    "    data_in = data_in.astype(np.uint8)\n",
    "    data_in[data_in > 0] = 255\n",
    "\n",
    "physical_pixel_sizes = [meta_dict[\"metadata\"][\"aicsimage\"].physical_pixel_sizes]\n",
    "out_ome = OmeTiffWriter.build_ome(\n",
    "        [data_in.shape],\n",
    "        [data_in.dtype],\n",
    "        channel_names=channel_names,  # type: ignore\n",
    "        image_name=image_names,\n",
    "        physical_pixel_sizes=physical_pixel_sizes,\n",
    "        dimension_order=dimension_order,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
