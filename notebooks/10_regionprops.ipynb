{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCohenLab 2D BATCH Image Processing notebook (Simplified MCZ)\n",
    "\n",
    "--------------\n",
    "# PIPELINE OVERVIEW\n",
    "## ‚ù∂ GOAL SETTING ‚úç\n",
    "\n",
    "### GOAL:  Infer sub-cellular components in order to understand interactome \n",
    "\n",
    "To measure shape, position, size, and interaction of eight organelles/cellular components (Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and SOMA) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.\n",
    "\n",
    "### summary of _OBJECTIVES_ ‚úÖ\n",
    "- robust inference of subcellular objects:\n",
    "  + 1Ô∏è‚É£-***nuclei***\n",
    "  + 2Ô∏è‚É£-***cellmask***\n",
    "  + 3Ô∏è‚É£-***cytoplasm*** (+ ***nucleus***)\n",
    "  + 4Ô∏è‚É£-***lysosome***\n",
    "  + 5Ô∏è‚É£-***mitochondria***\n",
    "  + 6Ô∏è‚É£-***golgi***\n",
    "  + 7Ô∏è‚É£-***peroxisome***\n",
    "  + 8Ô∏è‚É£-***ER***\n",
    "  + 9Ô∏è‚É£-***lipid droplet***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ‚ù∑ DATA CREATION\n",
    "> METHODS:üìöüìö\n",
    "> \n",
    "> iPSC lines prepared and visualized on Zeiss Microscopes. 32 channel multispectral images collected.  Linear Unmixing in  ZEN Blue software with target emission spectra yields 8 channel image outputs.  Channels correspond to: Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and a ‚Äúresidual‚Äù signal.\n",
    "\n",
    "> Meta-DATA üè∫ (artifacts)\n",
    ">   - Microcope settings\n",
    ">  - OME scheme\n",
    "> - Experimenter observations\n",
    "> - Sample, bio-replicate, image numbers, condition values, etc\n",
    ">  - Dates\n",
    ">  - File structure, naming conventions\n",
    ">  - etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ù∏. IMAGE PROCESSING ‚öôÔ∏èü©ªüî¨\n",
    "### INFERENCE OF SUB-CELLULAR OBJECTS\n",
    "The imported images have already been pre-processed to transform the 32 channel spectral measuremnts into \"linearly unmixed\" images which estimate independently labeled sub-cellular components.  Thes 7 channels (plus a residual \"non-linear\" signal) will be used to infer the shapes and extents of these sub-cellular components.   \n",
    "We will perform computational image analysis on the pictures (in 2D an 3D) to _segment_ the components of interest for measurement.  In other prcoedures we can used these labels as \"ground truth\" labels to train machine learning models to automatically perform the inference of these objects.\n",
    "Pseudo-independent processing of the imported multi-channel image to acheive each of the 9 objecives stated above.  i.e. infering: NUCLEI, SOMA, CYTOSOL, LYSOSOME, MITOCHONDRIA, GOLGI COMPLEX, PEROZISOMES, ENDOPLASMIC RETICULUM, and LIPID BODIES\n",
    "\n",
    "### General flow for infering objects via segmentation\n",
    "- Pre-processing üåí\n",
    "- Core-processing (thresholding) üåï\n",
    "- Post-processing  üåò\n",
    "\n",
    "### QC üöß WIP üöß \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ‚ùπ. QUANTIFICATION üìèüìêüßÆ\n",
    "\n",
    "SUBCELLULAR COMPONENT METRICS\n",
    "-  extent \n",
    "-  size\n",
    "-  shape\n",
    "-  position\n",
    "\n",
    "\n",
    "\n",
    "### NOTE: PIPELINE TOOL AND DESIGN CHOICES?\n",
    "We want to leverage the Allen Cell & Structure Setmenter.  It has been wrapped as a [napari-plugin](https://www.napari-hub.org/plugins/napari-allencell-segmenter) but fore the workflow we are proving out here we will want to call the `aicssegmentation` [package](https://github.com/AllenCell/aics-segmentation) directly.\n",
    "\n",
    "#### ‚ÄãThe Allen Cell & Structure Segmenter \n",
    "‚ÄãThe Allen Cell & Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.\n",
    "\n",
    "More details about Segmenter can be found at https://allencell.org/segmenter\n",
    "In order to leverage the A\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table, regionprops, label\n",
    "from skimage.morphology import binary_erosion\n",
    "\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.core.file_io import (read_czi_image,\n",
    "                                                                    export_inferred_organelle,\n",
    "                                                                    import_inferred_organelle,\n",
    "                                                                    export_tiff,\n",
    "                                                                    list_image_files)\n",
    "\n",
    "from infer_subc_2d.core.img import *\n",
    "from infer_subc_2d.utils.stats import *\n",
    "\n",
    "from infer_subc_2d.organelles import * \n",
    "\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:  these \"constants\" are only accurate for the testing MCZ dataset\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROX_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LD_CH ,\n",
    "                                                                    RESIDUAL_CH )              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example image for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "in_data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "# save output \".tiff\" files here\n",
    "out_data_path = data_root_path / \"out\"\n",
    "\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cento/lib/python3.9/site-packages/ome_types/_convenience.py:106: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "source_file = meta_dict['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.267318290023735,\n",
       " (0.5804527163320905, 0.07987165184837318, 0.07987165184837318))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale[0]/scale[1], scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the single \"optimal\" slice of all our organelle channels...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred cellmask, nuclei and cytoplasm objects\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builde the segmentations in order\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`nuclei` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-nuclei.tiff\n",
      "starting segmentation...\n",
      " in_img = (8, 15, 768, 768)\n",
      "nuclei size = (15, 768, 768)\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.01) sec\n",
      "saved file: None\n",
      "inferred nuclei. wrote None\n",
      "inferred nuclei in (7.24) sec\n",
      "`cellmask` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-cellmask.tiff\n",
      "starting segmentation...\n",
      "shape in_img (8, 15, 768, 768)\n",
      "shape nuclei_obj (15, 768, 768)\n",
      "weighted_aggregate: shape in- (8, 15, 768, 768) , shape_out- (15, 768, 768)\n",
      "shape struct_img (15, 768, 768)\n",
      "changed dtype from bool to uint8\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.02) sec\n",
      "saved file: None\n",
      "inferred (and exported) cellmask in (58.35) sec\n",
      "`cytoplasm` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-cytoplasm.tiff\n",
      "starting segmentation...\n",
      "changed dtype from bool to uint8\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.04) sec\n",
      "saved file: None\n",
      "inferred cytoplasm. wrote None\n",
      "inferred cytoplasm in (0.24) sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# SOMA, NUCLEI, CYTOSOL, NUCLEUS\n",
    "###################\n",
    "nuclei_obj =  get_nuclei(img_data,meta_dict, out_data_path)\n",
    "cellmask_obj = get_cellmask(img_data, nuclei_obj, meta_dict, out_data_path)\n",
    "cyto_mask = get_cytoplasm(nuclei_obj , cellmask_obj , meta_dict, out_data_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## regionprops\n",
    "\n",
    "`skimage.measure.regionprops` provides the basic tools nescessary to quantify our segmentations.\n",
    "\n",
    "First lets see what works in 3D.  \n",
    "\n",
    "> Note: the names of the regionprops correspond to the 2D analysis even for those which are well defined in 3D.  i.e. \"area\" is actually \"volume\" in 3D, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## basic stats\n",
    "\n",
    "### per-organelle\n",
    "\n",
    "\n",
    "- regionprops \n",
    "\n",
    "\n",
    "### summary stats\n",
    "\n",
    "- group + aggregate:  surface_area, volume\n",
    "  - median\n",
    "  - mean\n",
    "  - std \n",
    "  - count\n",
    "\n",
    "- normalizers\n",
    "  - SOMA?\n",
    "  - CYTOSOL?\n",
    "\n",
    "### nuclei caveats\n",
    "The other organelles are sensibly normalized by cytoplasm.  does normalizing the nuclei by cytoplasm make sense?  or use cellmask?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which possible measures are sensible for 3D or volumetric with regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported properties:\n",
      "  area\n",
      "  bbox\n",
      "  bbox_area\n",
      "  centroid\n",
      "  convex_area\n",
      "  convex_image\n",
      "  coords\n",
      "  equivalent_diameter\n",
      "  euler_number\n",
      "  extent\n",
      "  feret_diameter_max\n",
      "  filled_area\n",
      "  filled_image\n",
      "  image\n",
      "  inertia_tensor\n",
      "  inertia_tensor_eigvals\n",
      "  intensity_image\n",
      "  label\n",
      "  local_centroid\n",
      "  major_axis_length\n",
      "  max_intensity\n",
      "  mean_intensity\n",
      "  min_intensity\n",
      "  minor_axis_length\n",
      "  moments\n",
      "  moments_central\n",
      "  moments_normalized\n",
      "  slice\n",
      "  solidity\n",
      "  weighted_centroid\n",
      "  weighted_local_centroid\n",
      "  weighted_moments\n",
      "  weighted_moments_central\n",
      "  weighted_moments_normalized\n",
      "\n",
      "Unsupported properties:\n",
      "  eccentricity\n",
      "  moments_hu\n",
      "  orientation\n",
      "  perimeter\n",
      "  perimeter_crofton\n",
      "  weighted_moments_hu\n"
     ]
    }
   ],
   "source": [
    "labels = label(nuclei_obj )\n",
    "rp = regionprops(labels, intensity_image=img_data[NUC_CH])\n",
    "\n",
    "supported = [] \n",
    "unsupported = []\n",
    "\n",
    "for prop in rp[0]:\n",
    "    try:\n",
    "        rp[0][prop]\n",
    "        supported.append(prop)\n",
    "    except NotImplementedError:\n",
    "        unsupported.append(prop)\n",
    "\n",
    "print(\"Supported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(supported))\n",
    "print()\n",
    "print(\"Unsupported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(unsupported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.ndimage import find_objects\n",
    "    \n",
    "# labels = label(nuclei_obj ).astype(\"int\")\n",
    "# objects = find_objects(labels)\n",
    "\n",
    "# # objects are the slices into the original array for each organelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_aggregate: shape in- (8, 15, 768, 768) , shape_out- (15, 768, 768)\n"
     ]
    }
   ],
   "source": [
    "# get overall summary stats for cellmask\n",
    "cm_intensity =  raw_cellmask_fromaggr(img_data, scale_min_max=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dump_stats(name: str, segmentation:np.ndarray, intensity_img:np.ndarray, mask:np.ndarray, out_data_path: Path, source_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get summary stats\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table,_ = get_summary_stats_3D(segmentation, intensity_img, mask) \n",
    "    csv_path = out_data_path / f\"{source_file.stem}-{name}-stats.csv\"\n",
    "    stats_table.to_csv(csv_path )\n",
    "    print(f\"dumped {name} table to {csv_path}\")\n",
    "\n",
    "    return stats_table\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumped cellmask table to /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-cellmask-stats.csv\n",
      "dumped nucleus table to /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-nucleus-stats.csv\n",
      "dumped cytosol table to /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-cytosol-stats.csv\n"
     ]
    }
   ],
   "source": [
    "cellmask_table = dump_stats(\"cellmask\", cellmask_obj, cm_intensity, cellmask_obj, out_data_path, source_file)\n",
    "nucleus_table = dump_stats(\"nucleus\", nuclei_obj, img_data[NUC_CH], cellmask_obj, out_data_path, source_file)\n",
    "cyto_table = dump_stats(\"cytosol\", cyto_mask, cm_intensity+img_data[NUC_CH], cellmask_obj, out_data_path, source_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellmask_obj.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get a list of our organelle names, segmentations, intensities (florescence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint16in (0.02) sec\n",
      "loaded  inferred 3D `lyso`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      "loaded lyso in (0.02) sec\n",
      "`mitochondria` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-mitochondria.tiff\n",
      "starting segmentation...\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.02) sec\n",
      "saved file: None\n",
      "inferred mitochondria. wrote None\n",
      "inferred (and exported) mitochondria in (26.77) sec\n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint16in (0.02) sec\n",
      "loaded  inferred 3D `golgi`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      "starting segmentation...\n",
      "`peroxisome` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-peroxisome.tiff\n",
      "starting segmentation...\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.02) sec\n",
      "saved file: None\n",
      "inferred peroxisome. wrote None\n",
      "inferred (and exported) peroxisome in (2.57) sec\n",
      ">>>>>>>>>>>> tifffile.imread  (dtype=uint16in (0.02) sec\n",
      "loaded  inferred 3D `er`  from /Users/ahenrie/Projects/Imaging/data/out \n",
      "`lipid` object not found: /Users/ahenrie/Projects/Imaging/data/out/ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed-lipid.tiff\n",
      "starting segmentation...\n",
      ">>>>>>>>>>>> tifffile.imwrite in (0.02) sec\n",
      "saved file: None\n",
      "inferred lipid. wrote None\n",
      "inferred (and exported) lipid in (2.35) sec\n"
     ]
    }
   ],
   "source": [
    "# names of organelles we have\n",
    "organelle_names = [\"lyso\", \"mitochondria\",\"golgi\",\"peroxisome\",\"er\",\"lipid\"]\n",
    "\n",
    "get_methods  = [get_lyso,\n",
    "            get_mito,\n",
    "            get_golgi,\n",
    "            get_perox,\n",
    "            get_ER,\n",
    "            get_LD]\n",
    "\n",
    "# load all the organelle segmentations\n",
    "organelles = [meth(img_data,meta_dict, out_data_path) for meth in get_methods]\n",
    "\n",
    "# get the intensities\n",
    "organelle_channels = [LYSO_CH,MITO_CH,GOLGI_CH,PEROX_CH,ER_CH,LD_CH]\n",
    "\n",
    "intensities = [img_data[ch] for ch in organelle_channels]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## CONTACTS (cross-stats)\n",
    "\n",
    "### organelle cross stats\n",
    "\n",
    "\n",
    "- regionprops \n",
    "\n",
    "\n",
    "\n",
    "- intersect for A vs all other organelles Bi\n",
    "  - regionprops on A ‚à© Bi\n",
    "\n",
    "   \n",
    "- contacts?\n",
    "  - dilate then intersect?\n",
    "  - loop through each sub-object for each \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def shell_cross_stats(organelle_names: List[str], organelles:List[np.ndarray], mask:np.ndarray, out_data_path: Path, source_file: str) -> int:\n",
    "    \"\"\"\n",
    "    get all cross stats between organelles `a` and `b`, and \"shell of `a`\" and `b`.   \"shell\" is the boundary of `a` \n",
    "    calls `get_aXb_stats_3D`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for j, target in enumerate(organelle_names):    \n",
    "        print(f\"getting stats for A = {target}\")\n",
    "        a = organelles[j ]\n",
    "        # loop over Bs\n",
    "        for i,nmi in enumerate(organelle_names):    \n",
    "            if  i  !=  j:\n",
    "                # get overall stats of intersection\n",
    "                print(f\"  X {nmi}\")\n",
    "                b = organelles[i]\n",
    "                stats_tab = get_aXb_stats_3D(a,b, mask)    \n",
    "                csv_path = out_data_path / f\"{source_file.stem}-{target}X{nmi}-stats.csv\"\n",
    "                stats_tab.to_csv(csv_path )\n",
    "\n",
    "                e_stats_tab = get_aXb_stats_3D(a,b, cytoplasm_mask, use_shell_a=True)\n",
    "                csv_path = out_data_path / f\"{source_file.stem}-{target}_shellX{nmi}-stats.csv\"\n",
    "                e_stats_tab.to_csv(csv_path )\n",
    "                \n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organelle_stats(organelle_names: List[str], organelles:List[np.ndarray], intinsities:List[np.ndarray], mask:np.ndarray, out_data_path: Path, source_file: str) -> int:\n",
    "    \"\"\"\n",
    "    get summary and all cross stats between organelles A and B\n",
    "\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    org_stats_tabs = []\n",
    "    for j,target in enumerate(organelle_names):    \n",
    "        print(f\"getting stats for A = {target}\")\n",
    "        A = organelles[ j ]\n",
    "        # A_stats_tab, rp = get_simple_stats_3D(A,mask)\n",
    "        A_stats_tab, rp = get_summary_stats_3D(A , intinsities[ j ] ,mask )\n",
    "\n",
    "        # loop over Bs\n",
    "        for i,nmi in enumerate(organelle_names):    \n",
    "            if  i != j:\n",
    "                # get overall stats of intersection\n",
    "                print(f\"  b = {nmi}\")\n",
    "                B = organelles[i]\n",
    "\n",
    "                count += 1 \n",
    "                # add the list of touches \n",
    "                labB = label(B)\n",
    "\n",
    "                ov = []\n",
    "                B_labs = []\n",
    "                labs = []\n",
    "                for idx,lab in enumerate(A_stats_tab['label']): # loop over A_objects\n",
    "                    xyz = tuple(rp[idx].coords.T)\n",
    "                    cmp_org = labB[xyz]\n",
    "\n",
    "                    #total number of overlapping pixels\n",
    "                    overlap = sum(cmp_org>0)\n",
    "                    # overlap?\n",
    "                    b_labs = cmp_org[cmp_org>0]\n",
    "                    b_js = np.unique(b_labs).tolist()\n",
    "\n",
    "                    # if overlap > 0:\n",
    "                    labs.append(lab)\n",
    "                    ov.append(overlap)\n",
    "                    B_labs.append(b_js)\n",
    "\n",
    "                # add organelle B columns to A_stats_tab\n",
    "                A_stats_tab[f\"{nmi}_overlap\"] = ov\n",
    "                A_stats_tab[f\"{nmi}_labels\"] = B_labs  # might want to make this easier for parsing later\n",
    "\n",
    "        # org_stats_tabs.append(A_stats_tab)\n",
    "        csv_path = out_data_path / f\"{source_file.stem}-{target}-stats.csv\"\n",
    "\n",
    "        A_stats_tab.to_csv(csv_path)\n",
    "\n",
    "\n",
    "    print(f\"dumped {count} csvs\")\n",
    "    return count\n",
    "\n",
    "    \n",
    "# refactor to just to a target vs. list of probes\n",
    "# for nuclei mask == cellmask\n",
    "# for all oother mask == cytoplasm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organelle_stats(organelle_names: List[str], organelles:List[np.ndarray], intinsities:List[np.ndarray], mask:np.ndarray, out_data_path: Path, source_file: str) -> int:\n",
    "    \"\"\"\n",
    "    get summary and all cross stats between organelles A and B\n",
    "\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    org_stats_tabs = []\n",
    "    for j,target in enumerate(organelle_names):    \n",
    "        print(f\"getting stats for `a` = {target}\")\n",
    "        a = organelles[ j ]\n",
    "        # A_stats_tab, rp = get_simple_stats_3D(A,mask)\n",
    "        a_stats_tab, rp = get_summary_stats_3D(a , intinsities[ j ] ,mask )\n",
    "\n",
    "        # loop over Bs\n",
    "        for i,nmi in enumerate(organelle_names):    \n",
    "            if  i != j:\n",
    "                # get overall stats of intersection\n",
    "                print(f\"  `b` = {nmi}\")\n",
    "                b = organelles[i]\n",
    "\n",
    "                count += 1\n",
    "                # in case we sent a boolean mask (e.g. cyto, nucleus, cellmask)\n",
    "                if b.dtype == \"bool\" or b.dtype == np.uint8 :\n",
    "                    lab_b = label(b > 0).astype(np.uint16)\n",
    "                else:\n",
    "                    lab_b = b\n",
    "                ov = []\n",
    "\n",
    "                b_labels = []\n",
    "                for idx,lab in enumerate(a_stats_tab['label']): # loop over A_objects\n",
    "                    xyz = tuple(rp[idx].coords.T)\n",
    "                    cmp_org = lab_b[xyz]\n",
    "\n",
    "                    #total number of overlapping pixels\n",
    "                    overlap = sum(cmp_org>0)\n",
    "                    # overlap?\n",
    "                    b_ls = cmp_org[cmp_org>0]\n",
    "                    b_js = np.unique(b_ls).tolist()\n",
    "\n",
    "                    # if overlap > 0:\n",
    "                    ov.append(overlap)\n",
    "                    b_labels.append(b_js)\n",
    "\n",
    "                # add organelle B columns to A_stats_tab\n",
    "                a_stats_tab[f\"{nmi}_overlap\"] = ov\n",
    "                a_stats_tab[f\"{nmi}_labels\"] = b_labels  # might want to make this easier for parsing later\n",
    "\n",
    "        # org_stats_tabs.append(A_stats_tab)\n",
    "        csv_path = out_data_path / f\"{source_file.stem}-{target}-stats.csv\"\n",
    "\n",
    "        a_stats_tab.to_csv(csv_path)\n",
    "\n",
    "\n",
    "    print(f\"dumped {count} csvs\")\n",
    "    return count\n",
    "\n",
    "    \n",
    "# refactor to just to a target vs. list of probes\n",
    "# for nuclei mask == cellmask\n",
    "# for all oother mask == cytoplasm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting stats for `a` = lyso\n",
      "  `b` = mitochondria\n",
      "  `b` = golgi\n",
      "  `b` = peroxisome\n",
      "  `b` = er\n",
      "  `b` = lipid\n",
      "getting stats for `a` = mitochondria\n",
      "  `b` = lyso\n",
      "  `b` = golgi\n",
      "  `b` = peroxisome\n",
      "  `b` = er\n",
      "  `b` = lipid\n",
      "getting stats for `a` = golgi\n",
      "  `b` = lyso\n",
      "  `b` = mitochondria\n",
      "  `b` = peroxisome\n",
      "  `b` = er\n",
      "  `b` = lipid\n",
      "getting stats for `a` = peroxisome\n",
      "  `b` = lyso\n",
      "  `b` = mitochondria\n",
      "  `b` = golgi\n",
      "  `b` = er\n",
      "  `b` = lipid\n",
      "getting stats for `a` = er\n",
      "  `b` = lyso\n",
      "  `b` = mitochondria\n",
      "  `b` = golgi\n",
      "  `b` = peroxisome\n",
      "  `b` = lipid\n",
      "getting stats for `a` = lipid\n",
      "  `b` = lyso\n",
      "  `b` = mitochondria\n",
      "  `b` = golgi\n",
      "  `b` = peroxisome\n",
      "  `b` = er\n",
      "dumped 30 csvs\n"
     ]
    }
   ],
   "source": [
    "n_files = organelle_stats(organelle_names, organelles,intensities, cyto_mask, out_data_path, source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting stats for A = lyso\n",
      "  X mitochondria\n",
      "  X golgi\n",
      "  X peroxisome\n",
      "  X er\n",
      "  X lipid\n",
      "getting stats for A = mitochondria\n",
      "  X lyso\n",
      "  X golgi\n",
      "  X peroxisome\n",
      "  X er\n",
      "  X lipid\n",
      "getting stats for A = golgi\n",
      "  X lyso\n",
      "  X mitochondria\n",
      "  X peroxisome\n",
      "  X er\n",
      "  X lipid\n",
      "getting stats for A = peroxisome\n",
      "  X lyso\n",
      "  X mitochondria\n",
      "  X golgi\n",
      "  X er\n",
      "  X lipid\n",
      "getting stats for A = er\n",
      "  X lyso\n",
      "  X mitochondria\n",
      "  X golgi\n",
      "  X peroxisome\n",
      "  X lipid\n",
      "getting stats for A = lipid\n",
      "  X lyso\n",
      "  X mitochondria\n",
      "  X golgi\n",
      "  X peroxisome\n",
      "  X er\n"
     ]
    }
   ],
   "source": [
    "n_files =shell_cross_stats(organelle_names, organelles, cyto_mask, out_data_path, source_file) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "##  SUMMARY STATS  \n",
    "> WARNING: (üö®üö®üö®üö® WIP)\n",
    "### normalizations.\n",
    "\n",
    "- overlaps, normalized by CYTOSOL, A, and B\n",
    "- per cell averages, medians, std, and totals\n",
    "\n",
    "These is all pandas munging and very straightforward tabular manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>max_intensity</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>min_intensity</th>\n",
       "      <th>volume</th>\n",
       "      <th>equivalent_diameter</th>\n",
       "      <th>centroid-0</th>\n",
       "      <th>centroid-1</th>\n",
       "      <th>centroid-2</th>\n",
       "      <th>...</th>\n",
       "      <th>lyso_overlap</th>\n",
       "      <th>lyso_labels</th>\n",
       "      <th>golgi_overlap</th>\n",
       "      <th>golgi_labels</th>\n",
       "      <th>peroxisome_overlap</th>\n",
       "      <th>peroxisome_labels</th>\n",
       "      <th>er_overlap</th>\n",
       "      <th>er_labels</th>\n",
       "      <th>lipid_overlap</th>\n",
       "      <th>lipid_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18751</td>\n",
       "      <td>7867.069930</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>6.488024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>342.356643</td>\n",
       "      <td>523.419580</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61674</td>\n",
       "      <td>18140.592896</td>\n",
       "      <td>0</td>\n",
       "      <td>6475</td>\n",
       "      <td>23.124928</td>\n",
       "      <td>4.872587</td>\n",
       "      <td>405.907645</td>\n",
       "      <td>562.084324</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>[33, 34, 57, 174, 209]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1565</td>\n",
       "      <td>[5, 27, 78]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>26609</td>\n",
       "      <td>11076.260417</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>5.680992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.927083</td>\n",
       "      <td>481.802083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>[19]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>52794</td>\n",
       "      <td>15597.380997</td>\n",
       "      <td>0</td>\n",
       "      <td>50444</td>\n",
       "      <td>45.842712</td>\n",
       "      <td>6.627448</td>\n",
       "      <td>176.820613</td>\n",
       "      <td>482.624713</td>\n",
       "      <td>...</td>\n",
       "      <td>3906</td>\n",
       "      <td>[7, 13, 41, 44, 76, 83, 106, 108, 109, 111, 11...</td>\n",
       "      <td>1042</td>\n",
       "      <td>[1, 3, 14, 16]</td>\n",
       "      <td>120</td>\n",
       "      <td>[4, 7, 14, 15, 18, 19, 20, 21, 24, 25]</td>\n",
       "      <td>13740</td>\n",
       "      <td>[5, 115, 275, 307, 313, 344]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7772</td>\n",
       "      <td>3231.764706</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3.190192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>176.588235</td>\n",
       "      <td>523.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>8</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label  max_intensity  mean_intensity  min_intensity  volume  \\\n",
       "0           0      1          18751     7867.069930              0     143   \n",
       "1           1      3          61674    18140.592896              0    6475   \n",
       "2           2      5          26609    11076.260417              0      96   \n",
       "3           3      6          52794    15597.380997              0   50444   \n",
       "4           4      7           7772     3231.764706              0      17   \n",
       "\n",
       "   equivalent_diameter  centroid-0  centroid-1  centroid-2  ...  lyso_overlap  \\\n",
       "0             6.488024    1.000000  342.356643  523.419580  ...             0   \n",
       "1            23.124928    4.872587  405.907645  562.084324  ...           302   \n",
       "2             5.680992    1.000000  397.927083  481.802083  ...             0   \n",
       "3            45.842712    6.627448  176.820613  482.624713  ...          3906   \n",
       "4             3.190192    1.000000  176.588235  523.176471  ...             0   \n",
       "\n",
       "                                         lyso_labels  golgi_overlap  \\\n",
       "0                                                 []              0   \n",
       "1                             [33, 34, 57, 174, 209]              0   \n",
       "2                                                 []              0   \n",
       "3  [7, 13, 41, 44, 76, 83, 106, 108, 109, 111, 11...           1042   \n",
       "4                                                 []              0   \n",
       "\n",
       "     golgi_labels  peroxisome_overlap                       peroxisome_labels  \\\n",
       "0              []                   0                                      []   \n",
       "1              []                   0                                      []   \n",
       "2              []                   0                                      []   \n",
       "3  [1, 3, 14, 16]                 120  [4, 7, 14, 15, 18, 19, 20, 21, 24, 25]   \n",
       "4              []                   0                                      []   \n",
       "\n",
       "   er_overlap                     er_labels  lipid_overlap  lipid_labels  \n",
       "0           0                            []              0            []  \n",
       "1        1565                   [5, 27, 78]              0            []  \n",
       "2           5                          [19]              0            []  \n",
       "3       13740  [5, 115, 275, 307, 313, 344]              0            []  \n",
       "4           8                           [5]              0            []  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = organelle_names[1]\n",
    "\n",
    "csv_path = out_data_path / f\"{source_file.stem}-{target}-stats.csv\"\n",
    "\n",
    "mito_table = pd.read_csv(csv_path)\n",
    "mito_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883.2333333333333"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mito_table.volume.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "## DISTRIBUTION  \n",
    "> WARNING: (üö®üö®üö®üö® WIP)\n",
    "### XY- summary\n",
    "Segment image in 3D;\n",
    "sum projection of binary image; \n",
    "create 5 concentric rings going from the edge of the nuclie to the edge of the cellmask (ideally these will be morphed to cellmask/nuclei shape as done in CellProfiler); \n",
    "measure intensity per ring (include nuclei as the center area to measure from)/ring area; \n",
    "the normalized measurement will act as a frequency distribution of that organelle starting from the nuclei bin going out to the cell membrane - \n",
    "Measurements needed: mean, median, and standard deviation of the frequency will be calculated\n",
    "\n",
    "- pre-processing\n",
    "  1. Make 2D sum projection of binary segmentation\n",
    "  2. Create 5 concentric rings going out from the edge of the nuclei to the edge of the cellmask - these rings should be morphed to the shape of the nuclei and cellmask. \n",
    "  3. Use nucleus + concentric rings to mask the 2D sum project into radial distribution regions: nuclei = bin 1, ... largest/outter most ring = bin 6. See similar concept in CellProfiler: https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.5/modules/measurement.html?highlight=distribution#module-cellprofiler.modules.measureobjectintensitydistribution\"\t\n",
    "   \n",
    "- per-object measurements\n",
    "  - For each bin measure:\n",
    "    1. pixel \"\"intensity\"\"\n",
    "    2. bin area\"\n",
    "\n",
    "- per-object calculations\n",
    "  - per-object For each bin: \n",
    "  - sum of pixel intensity per bin / bin area\"\t\n",
    "\n",
    "- per cell summary\n",
    "  1. Create a frequency table with bin number of the x axis and normalized pixel intensity on the y-axis\n",
    "  2. Measure the frequency distribution's mean, median, and standard deviation for each cell\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Z- summary\n",
    "Segment image in 3D;\n",
    "measure area fraction of each organelle per Z slice;\n",
    "these measurements will act as a frequency distribution of that organelle starting from the bottom of the cellmask (not including neurites) to the top of the cellmask;\n",
    "measurements: mean, median, and standard deviation of the frequency distribution\t\n",
    "\n",
    "- pre-processing\n",
    "  1. subtract nuclei from the cellmask --> cellmask cytoplasm\n",
    "  2. mask organelle channels with cellmask cytoplasm mask\n",
    "\n",
    "- per-object measurements\n",
    "  - For each Z slice in the masked binary image measure:\n",
    "    1. organelle area\n",
    "    2. cellmask cytoplasm area\n",
    "\n",
    "- per-object calculations\n",
    "  - For each Z slice in the masked binary image: organelle area / cellmask cytoplasm area\n",
    "\n",
    "- per cell summary\n",
    "  1. create a frequency table with the z slice number on the x axis and the area fraction on the y axis\n",
    "  2. Measure the frequency distribution's mean, median, and standard deviation for each cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the flattened\n",
    "_cellmask = cellmask_obj.sum(axis=0) \n",
    "_nuclei = apply_mask(nuclei_obj,cellmask_obj).sum(axis=0)\n",
    "d_to_edge = distance_to_edge( label(_cellmask) )\n",
    "\n",
    "\n",
    "# _lyso = organelles[0].sum(axis=0) \n",
    "\n",
    "_lyso = (apply_mask( organelles[0],cellmask_obj)>0).sum(axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = color_labels(label(_cellmask) + label(_nuclei))\n",
    "# d_to_edge = distance_to_edge( colors )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '_lyso [1]' at 0x1ba376d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# viewer =napari.view_image(d_to_edge)\n",
    "# viewer.add_image(_nuclei)\n",
    "# viewer.add_image(colors)\n",
    "viewer.add_image(_cellmask>0)\n",
    "viewer.add_image(_lyso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 106014, 145230, 174336, 187272, 195216, 196374, 193998,\n",
       "       185172, 162624, 118242, 102036,  81024,  48546,   4422],\n",
       "      dtype=uint64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zflat_cellmask = cellmask_obj.sum(axis=(1,2)) \n",
    "Zflat_nuclei = apply_mask(nuclei_obj,cellmask_obj).sum(axis=(1,2)) \n",
    "\n",
    "Zflat_nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed.czi'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_path = out_data_path / f\"{o}_{meta_dict[\"file_name\"].split('/')[-1].split('.')[0]}_stats.csv\"\n",
    "Path(meta_dict['file_name']).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import maximum_position, center_of_mass\n",
    "from scipy.ndimage import sum as ndi_sum\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from infer_subc_2d.core.img import distance_to_edge, distance_transform_edt\n",
    "\n",
    "import centrosome\n",
    "\n",
    "C_SELF = \"These objects\"\n",
    "C_CENTERS_OF_OTHER_V2 = \"Other objects\"\n",
    "C_CENTERS_OF_OTHER = \"Centers of other objects\"\n",
    "C_EDGES_OF_OTHER = \"Edges of other objects\"\n",
    "C_ALL = [C_SELF, C_CENTERS_OF_OTHER, C_EDGES_OF_OTHER]\n",
    "Z_NONE = \"None\"\n",
    "Z_MAGNITUDES = \"Magnitudes only\"\n",
    "Z_MAGNITUDES_AND_PHASE = \"Magnitudes and phase\"\n",
    "Z_ALL = [Z_NONE, Z_MAGNITUDES, Z_MAGNITUDES_AND_PHASE]\n",
    "\n",
    "M_CATEGORY = \"RadialDistribution\"\n",
    "F_FRAC_AT_D = \"FracAtD\"\n",
    "F_MEAN_FRAC = \"MeanFrac\"\n",
    "F_RADIAL_CV = \"RadialCV\"\n",
    "F_ALL = [F_FRAC_AT_D, F_MEAN_FRAC, F_RADIAL_CV]\n",
    "\n",
    "FF_SCALE = \"%dof%d\"\n",
    "FF_OVERFLOW = \"Overflow\"\n",
    "FF_GENERIC = \"_%s_\" + FF_SCALE\n",
    "FF_FRAC_AT_D = F_FRAC_AT_D + FF_GENERIC\n",
    "FF_MEAN_FRAC = F_MEAN_FRAC + FF_GENERIC\n",
    "FF_RADIAL_CV = F_RADIAL_CV + FF_GENERIC\n",
    "\n",
    "FF_ZERNIKE_MAGNITUDE = \"ZernikeMagnitude\"\n",
    "FF_ZERNIKE_PHASE = \"ZernikePhase\"\n",
    "\n",
    "MF_FRAC_AT_D = \"_\".join((M_CATEGORY, FF_FRAC_AT_D))\n",
    "MF_MEAN_FRAC = \"_\".join((M_CATEGORY, FF_MEAN_FRAC))\n",
    "MF_RADIAL_CV = \"_\".join((M_CATEGORY, FF_RADIAL_CV))\n",
    "OF_FRAC_AT_D = \"_\".join((M_CATEGORY, F_FRAC_AT_D, \"%s\", FF_OVERFLOW))\n",
    "OF_MEAN_FRAC = \"_\".join((M_CATEGORY, F_MEAN_FRAC, \"%s\", FF_OVERFLOW))\n",
    "OF_RADIAL_CV = \"_\".join((M_CATEGORY, F_RADIAL_CV, \"%s\", FF_OVERFLOW))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def centers_of_labels(labels):\n",
    "    \"\"\"Return the i,j coordinates of the centers of a labels matrix\n",
    "    \n",
    "    The result returned is an 2 x n numpy array where n is the number\n",
    "    of the label minus one, result[0,x] is the i coordinate of the center\n",
    "    and result[x,1] is the j coordinate of the center.\n",
    "    You can unpack the result as \"i,j = centers_of_labels(labels)\"\n",
    "    \"\"\"\n",
    "    max_labels = np.max(labels)\n",
    "    if max_labels == 0:\n",
    "        return np.zeros((2, 0), int)\n",
    "\n",
    "    result = center_of_mass(\n",
    "        np.ones(labels.shape), labels, np.arange(max_labels) + 1\n",
    "    )\n",
    "    result = np.array(result)\n",
    "    if result.ndim == 1:\n",
    "        result.shape = (2, 1)\n",
    "        return result\n",
    "    return result.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def maximum_position_of_labels(image, labels, indices):\n",
    "    \"\"\"Return the i,j coordinates of the maximum value within each object\n",
    "    \n",
    "    image - measure the maximum within this image\n",
    "    labels - use the objects within this labels matrix\n",
    "    indices - label #s to measure\n",
    "    \n",
    "    The result returned is an 2 x n numpy array where n is the number\n",
    "    of the label minus one, result[0,x] is the i coordinate of the center\n",
    "    and result[x,1] is the j coordinate of the center.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(indices) == 0:\n",
    "        return np.zeros((2, 0), int)\n",
    "\n",
    "    result = maximum_position(image, labels, indices)\n",
    "    result = np.array(result, int)\n",
    "    if result.ndim == 1:\n",
    "        result.shape = (2, 1)\n",
    "        return result\n",
    "    return result.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def size_similarly(labels, secondary):\n",
    "    \"\"\"Size the secondary matrix similarly to the labels matrix\n",
    "\n",
    "    labels - labels matrix\n",
    "    secondary - a secondary image or labels matrix which might be of\n",
    "                different size.\n",
    "    Return the resized secondary matrix and a mask indicating what portion\n",
    "    of the secondary matrix is bogus (manufactured values).\n",
    "\n",
    "    Either the mask is all ones or the result is a copy, so you can\n",
    "    modify the output within the unmasked region w/o destroying the original.\n",
    "    \"\"\"\n",
    "    if labels.shape[:2] == secondary.shape[:2]:\n",
    "        return secondary, np.ones(secondary.shape, bool)\n",
    "    if labels.shape[0] <= secondary.shape[0] and labels.shape[1] <= secondary.shape[1]:\n",
    "        if secondary.ndim == 2:\n",
    "            return (\n",
    "                secondary[: labels.shape[0], : labels.shape[1]],\n",
    "                np.ones(labels.shape, bool),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                secondary[: labels.shape[0], : labels.shape[1], :],\n",
    "                np.ones(labels.shape, bool),\n",
    "            )\n",
    "\n",
    "    # Some portion of the secondary matrix does not cover the labels\n",
    "    result = np.zeros(\n",
    "        list(labels.shape) + list(secondary.shape[2:]), secondary.dtype\n",
    "    )\n",
    "    i_max = min(secondary.shape[0], labels.shape[0])\n",
    "    j_max = min(secondary.shape[1], labels.shape[1])\n",
    "    if secondary.ndim == 2:\n",
    "        result[:i_max, :j_max] = secondary[:i_max, :j_max]\n",
    "    else:\n",
    "        result[:i_max, :j_max, :] = secondary[:i_max, :j_max, :]\n",
    "    mask = np.zeros(labels.shape, bool)\n",
    "    mask[:i_max, :j_max] = 1\n",
    "    return result, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fixup_scipy_ndimage_result(whatever_it_returned):\n",
    "    \"\"\"Convert a result from scipy.ndimage to a numpy array\n",
    "    \n",
    "    scipy.ndimage has the annoying habit of returning a single, bare\n",
    "    value instead of an array if the indexes passed in are of length 1.\n",
    "    For instance:\n",
    "    scind.maximum(image, labels, [1]) returns a float\n",
    "    but\n",
    "    scind.maximum(image, labels, [1,2]) returns a list\n",
    "    \"\"\"\n",
    "    if getattr(whatever_it_returned, \"__getitem__\", False):\n",
    "        return np.array(whatever_it_returned)\n",
    "    else:\n",
    "        return np.array([whatever_it_returned])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from centrosome import propagate\n",
    "\n",
    "\n",
    "# get the flattened\n",
    "_cellmask = cellmask_obj.sum(axis=0) \n",
    "_nuclei = apply_mask(nuclei_obj,cellmask_obj).sum(axis=0)\n",
    "d_to_edge = distance_to_edge( label(_cellmask) )\n",
    "\n",
    "\n",
    "# _lyso = organelles[0].sum(axis=0) \n",
    "\n",
    "_lyso = (apply_mask( organelles[0],cellmask_obj)>0).sum(axis=0)\n",
    "\n",
    "\n",
    "organelle_ = organelles[0]\n",
    "organelle_name =organelle_names[0]\n",
    "intensity_img = apply_mask(img_data[0], cyto_mask)\n",
    "\n",
    "\n",
    "n_bins = 6\n",
    "scale_bins = True \n",
    "center_choice = C_EDGES_OF_OTHER\n",
    "\n",
    "\n",
    "max_radius = 60 # not used\n",
    "\n",
    "center_object_name = nuclei_obj if nuclei_obj is None else \"nuclei\" \n",
    "\n",
    "\n",
    "# get the flattened\n",
    "_cellmask = (cellmask_obj>0).sum(axis=0) \n",
    "_nuclei = (apply_mask(nuclei_obj,cellmask_obj)>0).sum(axis=0)\n",
    "\n",
    "_org = (organelle_>0).sum(axis=0) \n",
    "_img = intensity_img.sum(axis=0) \n",
    "\n",
    "nobjects = label(organelle_>0).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = (_cellmask>0).astype(np.uint16)\n",
    "\n",
    "d_to_edge = distance_to_edge(labels) # made a local version\n",
    "\n",
    "center_objects = (_nuclei>0).astype(np.uint16)\n",
    "\n",
    "\n",
    "center_labels, cmask = size_similarly(labels, center_objects)\n",
    "pixel_counts = fixup_scipy_ndimage_result(\n",
    "    ndi_sum(\n",
    "        np.ones(center_labels.shape),\n",
    "        center_labels,\n",
    "        np.arange(\n",
    "            1, np.max(center_labels) + 1, dtype=np.int32\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "good = pixel_counts > 0\n",
    "i, j = ( centers_of_labels(center_labels) + 0.5).astype(int)\n",
    "ig = i[good]\n",
    "jg = j[good]\n",
    "lg = np.arange(1, len(i) + 1)[good]\n",
    "if (center_choice == C_CENTERS_OF_OTHER):  # Reduce the propagation labels to the centers of the centering objects\n",
    "    center_labels = np.zeros(center_labels.shape, int)\n",
    "    center_labels[ig, jg] = lg\n",
    "\n",
    "cl, d_from_center = propagate.propagate(  np.zeros(center_labels.shape), center_labels, labels != 0, 1)\n",
    "cl[labels == 0] = 0            # Erase the centers that fall outside of labels\n",
    "\n",
    "\n",
    "# If objects are hollow or crescent-shaped, there may be objects without center labels. As a backup, find the\n",
    "# center that is the closest to the center of mass.\n",
    "missing_mask = (labels != 0) & (cl == 0)\n",
    "missing_labels = np.unique(labels[missing_mask])\n",
    "\n",
    "if len(missing_labels):\n",
    "    all_centers = centers_of_labels(labels)\n",
    "    missing_i_centers, missing_j_centers = all_centers[:, missing_labels-1]\n",
    "    di = missing_i_centers[:, np.newaxis] - ig[np.newaxis, :]\n",
    "    dj = missing_j_centers[:, np.newaxis] - jg[np.newaxis, :]\n",
    "    missing_best = lg[np.argsort(di * di + dj * dj)[:, 0]]\n",
    "    best = np.zeros(np.max(labels) + 1, int)\n",
    "    best[missing_labels] = missing_best\n",
    "    cl[missing_mask] = best[labels[missing_mask]]\n",
    "\n",
    "    # Now compute the crow-flies distance to the centers of these pixels from whatever center was assigned to the object.\n",
    "    iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "    di = iii[missing_mask] - i[cl[missing_mask] - 1]\n",
    "    dj = jjj[missing_mask] - j[cl[missing_mask] - 1]\n",
    "    d_from_center[missing_mask] = np.sqrt(di * di + dj * dj)\n",
    "\n",
    "# # ELSE     if center_objects is  None:\n",
    "# i, j = maximum_position_of_labels(   d_to_edge, labels, objects.indices )\n",
    "# center_labels = np.zeros(labels.shape, int)\n",
    "# center_labels[i, j] = labels[i, j]\n",
    "# # Use the coloring trick here to process touching objectsin separate operations\n",
    "# colors = color_labels(labels)\n",
    "# ncolors = np.max(colors)\n",
    "# d_from_center = np.zeros(labels.shape)\n",
    "# cl = np.zeros(labels.shape, int)\n",
    "\n",
    "# for color in range(1, ncolors + 1):\n",
    "#     mask = colors == color\n",
    "#     l, d = centrosome.propagate.propagate( np.zeros(center_labels.shape), center_labels, mask, 1)\n",
    "#     d_from_center[mask] = d[mask]\n",
    "#     cl[mask] = l[mask]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_mask = cl > 0\n",
    "\n",
    "if (center_choice == C_EDGES_OF_OTHER):\n",
    "    # Exclude pixels within the centering objects\n",
    "    # when performing calculations from the centers\n",
    "    good_mask = good_mask & (center_labels == 0)\n",
    "i_center = np.zeros(cl.shape)\n",
    "i_center[good_mask] = i[cl[good_mask] - 1]\n",
    "j_center = np.zeros(cl.shape)\n",
    "j_center[good_mask] = j[cl[good_mask] - 1]\n",
    "normalized_distance = np.zeros(labels.shape)\n",
    "\n",
    "if wants_scaled:\n",
    "    total_distance = d_from_center + d_to_edge\n",
    "    normalized_distance[good_mask] = d_from_center[good_mask] / ( total_distance[good_mask] + 0.001 )\n",
    "else:\n",
    "    normalized_distance[good_mask] = (d_from_center[good_mask] / maximum_radius)\n",
    "\n",
    "dd[name] = [normalized_distance, i_center, j_center, good_mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########  if / else\n",
    "ngood_pixels = np.sum(good_mask)\n",
    "good_labels = labels[good_mask]\n",
    "bin_indexes = (normalized_distance * bin_count).astype(int)\n",
    "bin_indexes[bin_indexes > bin_count] = bin_count\n",
    "labels_and_bins = (good_labels - 1, bin_indexes[good_mask])\n",
    "\n",
    "histogram = coo_matrix( (pixel_data[good_mask], labels_and_bins), (nobjects, bin_count + 1) ).toarray()\n",
    "\n",
    "sum_by_object = np.sum(histogram, 1)\n",
    "sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "fraction_at_distance = histogram / sum_by_object_per_bin\n",
    "number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\n",
    "\n",
    "object_mask = number_at_distance > 0\n",
    "sum_by_object = np.sum(number_at_distance, 1)\n",
    "sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "fraction_at_bin = number_at_distance / sum_by_object_per_bin\n",
    "mean_pixel_fraction = fraction_at_distance / ( fraction_at_bin + np.finfo(float).eps    )\n",
    "masked_fraction_at_distance = np.ma.masked_array( fraction_at_distance, ~object_mask )\n",
    "masked_mean_pixel_fraction = np.ma.masked_array(mean_pixel_fraction, ~object_mask)\n",
    "\n",
    "# Anisotropy calculation.  Split each cell into eight wedges, then compute coefficient of variation of the wedges' mean intensities\n",
    "# in each ring. Compute each pixel's delta from the center object's centroid\n",
    "i, j = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "imask = i[good_mask] > i_center[good_mask]\n",
    "jmask = j[good_mask] > j_center[good_mask]\n",
    "absmask = abs(i[good_mask] - i_center[good_mask]) > abs(\n",
    "    j[good_mask] - j_center[good_mask]\n",
    ")\n",
    "radial_index = (\n",
    "    imask.astype(int) + jmask.astype(int) * 2 + absmask.astype(int) * 4\n",
    ")\n",
    "statistics = []\n",
    "\n",
    "for bin in range(bin_count + (0 if wants_scaled else 1)):\n",
    "    bin_mask = good_mask & (bin_indexes == bin)\n",
    "    bin_pixels = np.sum(bin_mask)\n",
    "    bin_labels = labels[bin_mask]\n",
    "    bin_radial_index = radial_index[bin_indexes[good_mask] == bin]\n",
    "    labels_and_radii = (bin_labels - 1, bin_radial_index)\n",
    "    radial_values = coo_matrix( (pixel_data[bin_mask], labels_and_radii), (nobjects, 8) ).toarray()\n",
    "    pixel_count = coo_matrix( (np.ones(bin_pixels), labels_and_radii), (nobjects, 8) ).toarray()\n",
    "\n",
    "    mask = pixel_count == 0\n",
    "    radial_means = np.ma.masked_array(radial_values / pixel_count, mask)\n",
    "    radial_cv = np.std(radial_means, 1) / np.mean(radial_means, 1)\n",
    "    radial_cv[np.sum(~mask, 1) == 0] = 0\n",
    "\n",
    "    for measurement, feature, overflow_feature in (\n",
    "        (fraction_at_distance[:, bin], MF_FRAC_AT_D, OF_FRAC_AT_D),\n",
    "        (mean_pixel_fraction[:, bin], MF_MEAN_FRAC, OF_MEAN_FRAC),\n",
    "        (np.array(radial_cv), MF_RADIAL_CV, OF_RADIAL_CV),\n",
    "    ):\n",
    "        if bin == bin_count:\n",
    "            measurement_name = overflow_feature % image_name\n",
    "        else:\n",
    "            measurement_name = feature % (image_name, bin + 1, bin_count)\n",
    "\n",
    "        measurements.add_measurement(object_name, measurement_name, measurement)\n",
    "\n",
    "        # if feature in heatmaps:\n",
    "        #     heatmaps[feature][bin_mask] = measurement[bin_labels - 1]\n",
    "\n",
    "    radial_cv.mask = np.sum(~mask, 1) == 0\n",
    "    bin_name = str(bin + 1) if bin < bin_count else \"Overflow\"\n",
    "\n",
    "    statistics += [\n",
    "        (image_name,\n",
    "            object_name,\n",
    "            bin_name,\n",
    "            str(bin_count),\n",
    "            np.round(np.mean(masked_fraction_at_distance[:, bin]), 4),\n",
    "            np.round(np.mean(masked_mean_pixel_fraction[:, bin]), 4),\n",
    "            np.round(np.mean(radial_cv), 4) )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'cl [1]' at 0x1b8ae4af0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def get_radial_distribution(\n",
    "        cellmask_obj: np.ndarray,\n",
    "        nuclei_obj: Union[np.ndarray, None],\n",
    "        organelle_:np.ndarray,\n",
    "        organelle_name: str,\n",
    "        intensity_img: np.ndarray,\n",
    "    ):\n",
    "    \"\"\"Perform the radial measurements on the image set\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    cellmask_obj: np.ndarray,\n",
    "    nuclei_obj: Union[np.ndarray, None],\n",
    "    organelle_:np.ndarray,\n",
    "    organelle_name: str,\n",
    "    intensity_img: np.ndarray,\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    returns one statistics tuple per ring.\n",
    "    \"\"\"\n",
    "    # TODO: make these arguments\n",
    "    n_bins = 6\n",
    "    scale_bins = True \n",
    "    \n",
    "    max_radius = 60 # not used\n",
    "    \n",
    "    center_object_name = nuclei_obj if nuclie_obj is None else \"nuclei\" \n",
    "\n",
    "    # get the flattened\n",
    "    _cellmask = (cellmask_obj>0).sum(axis=0) \n",
    "    _nuclei = (apply_mask(nuclei_obj,cellmask_obj)>0).sum(axis=0)\n",
    "    _org = (organelle_>0).sum(axis=0) \n",
    "\n",
    "    nobjects = np.max(organelle_)\n",
    "\n",
    "    labels = _cellmask\n",
    "\n",
    "    d_to_edge = distance_to_edge(labels) # made a local version\n",
    "    center_objects = _nuclei\n",
    "\n",
    "    if center_objects is not None:\n",
    "        #\n",
    "        # Use the center of the centering objects to assign a center\n",
    "        # to each labeled pixel using propagation\n",
    "        #\n",
    "\n",
    "        center_labels, cmask = size_similarly(labels, center_objects.segmented)\n",
    "        pixel_counts = fixup_scipy_ndimage_result(\n",
    "            ndi_sum(\n",
    "                np.ones(center_labels.shape),\n",
    "                center_labels,\n",
    "                np.arange(\n",
    "                    1, np.max(center_labels) + 1, dtype=np.int32\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        good = pixel_counts > 0\n",
    "        i, j = ( centers_of_labels(center_labels) + 0.5).astype(int)\n",
    "        ig = i[good]\n",
    "        jg = j[good]\n",
    "        lg = np.arange(1, len(i) + 1)[good]\n",
    "        if (center_choice == C_CENTERS_OF_OTHERS):  # Reduce the propagation labels to the centers of the centering objects\n",
    "            center_labels = np.zeros(center_labels.shape, int)\n",
    "            center_labels[ig, jg] = lg\n",
    "\n",
    "        cl, d_from_center = centrosome.propagate.propagate(  np.zeros(center_labels.shape), center_labels, labels != 0, 1)\n",
    "        cl[labels == 0] = 0            # Erase the centers that fall outside of labels\n",
    "\n",
    "        # If objects are hollow or crescent-shaped, there may be objects without center labels. As a backup, find the\n",
    "        # center that is the closest to the center of mass.\n",
    "        missing_mask = (labels != 0) & (cl == 0)\n",
    "        missing_labels = np.unique(labels[missing_mask])\n",
    "\n",
    "        if len(missing_labels):\n",
    "            all_centers = centers_of_labels(labels)\n",
    "            missing_i_centers, missing_j_centers = all_centers[:, missing_labels-1]\n",
    "            di = missing_i_centers[:, np.newaxis] - ig[np.newaxis, :]\n",
    "            dj = missing_j_centers[:, np.newaxis] - jg[np.newaxis, :]\n",
    "            missing_best = lg[np.argsort(di * di + dj * dj)[:, 0]]\n",
    "            best = np.zeros(np.max(labels) + 1, int)\n",
    "            best[missing_labels] = missing_best\n",
    "            cl[missing_mask] = best[labels[missing_mask]]\n",
    "\n",
    "            # Now compute the crow-flies distance to the centers of these pixels from whatever center was assigned to the object.\n",
    "            iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "            di = iii[missing_mask] - i[cl[missing_mask] - 1]\n",
    "            dj = jjj[missing_mask] - j[cl[missing_mask] - 1]\n",
    "            d_from_center[missing_mask] = np.sqrt(di * di + dj * dj)\n",
    "    else:\n",
    "        # Find the point in each object farthest away from the edge.\n",
    "        # This does better than the centroid:\n",
    "        # * The center is within the object\n",
    "        # * The center tends to be an interesting point, like the center of the nucleus or the center of one or the other of two touching cells.\n",
    "        i, j = maximum_position_of_labels(   d_to_edge, labels, objects.indices )\n",
    "        center_labels = np.zeros(labels.shape, int)\n",
    "        center_labels[i, j] = labels[i, j]\n",
    "        # Use the coloring trick here to process touching objectsin separate operations\n",
    "        colors = color_labels(labels)\n",
    "        ncolors = np.max(colors)\n",
    "        d_from_center = np.zeros(labels.shape)\n",
    "        cl = np.zeros(labels.shape, int)\n",
    "\n",
    "        for color in range(1, ncolors + 1):\n",
    "            mask = colors == color\n",
    "            l, d = centrosome.propagate.propagate( np.zeros(center_labels.shape), center_labels, mask, 1)\n",
    "            d_from_center[mask] = d[mask]\n",
    "            cl[mask] = l[mask]\n",
    "\n",
    "        good_mask = cl > 0\n",
    "\n",
    "        if (center_choice == C_EDGES_OF_OTHER):\n",
    "            # Exclude pixels within the centering objects\n",
    "            # when performing calculations from the centers\n",
    "            good_mask = good_mask & (center_labels == 0)\n",
    "        i_center = np.zeros(cl.shape)\n",
    "        i_center[good_mask] = i[cl[good_mask] - 1]\n",
    "        j_center = np.zeros(cl.shape)\n",
    "        j_center[good_mask] = j[cl[good_mask] - 1]\n",
    "        normalized_distance = np.zeros(labels.shape)\n",
    "\n",
    "        if wants_scaled:\n",
    "            total_distance = d_from_center + d_to_edge\n",
    "            normalized_distance[good_mask] = d_from_center[good_mask] / ( total_distance[good_mask] + 0.001 )\n",
    "        else:\n",
    "            normalized_distance[good_mask] = (d_from_center[good_mask] / maximum_radius)\n",
    "        dd[name] = [normalized_distance, i_center, j_center, good_mask]\n",
    "\n",
    "\n",
    "\n",
    "    ngood_pixels = np.sum(good_mask)\n",
    "    good_labels = labels[good_mask]\n",
    "    bin_indexes = (normalized_distance * bin_count).astype(int)\n",
    "    bin_indexes[bin_indexes > bin_count] = bin_count\n",
    "    labels_and_bins = (good_labels - 1, bin_indexes[good_mask])\n",
    "\n",
    "    histogram = coo_matrix( (pixel_data[good_mask], labels_and_bins), (nobjects, bin_count + 1) ).toarray()\n",
    "\n",
    "    sum_by_object = np.sum(histogram, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_distance = histogram / sum_by_object_per_bin\n",
    "    number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\n",
    "\n",
    "    object_mask = number_at_distance > 0\n",
    "    sum_by_object = np.sum(number_at_distance, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_bin = number_at_distance / sum_by_object_per_bin\n",
    "    mean_pixel_fraction = fraction_at_distance / ( fraction_at_bin + np.finfo(float).eps    )\n",
    "    masked_fraction_at_distance = np.ma.masked_array( fraction_at_distance, ~object_mask )\n",
    "    masked_mean_pixel_fraction = np.ma.masked_array(mean_pixel_fraction, ~object_mask)\n",
    "\n",
    "    # Anisotropy calculation.  Split each cell into eight wedges, then compute coefficient of variation of the wedges' mean intensities\n",
    "    # in each ring. Compute each pixel's delta from the center object's centroid\n",
    "    i, j = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "    imask = i[good_mask] > i_center[good_mask]\n",
    "    jmask = j[good_mask] > j_center[good_mask]\n",
    "    absmask = abs(i[good_mask] - i_center[good_mask]) > abs(\n",
    "        j[good_mask] - j_center[good_mask]\n",
    "    )\n",
    "    radial_index = (\n",
    "        imask.astype(int) + jmask.astype(int) * 2 + absmask.astype(int) * 4\n",
    "    )\n",
    "    statistics = []\n",
    "\n",
    "    for bin in range(bin_count + (0 if wants_scaled else 1)):\n",
    "        bin_mask = good_mask & (bin_indexes == bin)\n",
    "        bin_pixels = np.sum(bin_mask)\n",
    "        bin_labels = labels[bin_mask]\n",
    "        bin_radial_index = radial_index[bin_indexes[good_mask] == bin]\n",
    "        labels_and_radii = (bin_labels - 1, bin_radial_index)\n",
    "        radial_values = coo_matrix( (pixel_data[bin_mask], labels_and_radii), (nobjects, 8) ).toarray()\n",
    "        pixel_count = coo_matrix( (np.ones(bin_pixels), labels_and_radii), (nobjects, 8) ).toarray()\n",
    "\n",
    "        mask = pixel_count == 0\n",
    "        radial_means = np.ma.masked_array(radial_values / pixel_count, mask)\n",
    "        radial_cv = np.std(radial_means, 1) / np.mean(radial_means, 1)\n",
    "        radial_cv[np.sum(~mask, 1) == 0] = 0\n",
    "\n",
    "        for measurement, feature, overflow_feature in (\n",
    "            (fraction_at_distance[:, bin], MF_FRAC_AT_D, OF_FRAC_AT_D),\n",
    "            (mean_pixel_fraction[:, bin], MF_MEAN_FRAC, OF_MEAN_FRAC),\n",
    "            (np.array(radial_cv), MF_RADIAL_CV, OF_RADIAL_CV),\n",
    "        ):\n",
    "            if bin == bin_count:\n",
    "                measurement_name = overflow_feature % image_name\n",
    "            else:\n",
    "                measurement_name = feature % (image_name, bin + 1, bin_count)\n",
    " \n",
    "           measurements.add_measurement(object_name, measurement_name, measurement)\n",
    "\n",
    "            # if feature in heatmaps:\n",
    "            #     heatmaps[feature][bin_mask] = measurement[bin_labels - 1]\n",
    "\n",
    "        radial_cv.mask = np.sum(~mask, 1) == 0\n",
    "        bin_name = str(bin + 1) if bin < bin_count else \"Overflow\"\n",
    "\n",
    "        statistics += [\n",
    "            (image_name,\n",
    "                object_name,\n",
    "                bin_name,\n",
    "                str(bin_count),\n",
    "                np.round(np.mean(masked_fraction_at_distance[:, bin]), 4),\n",
    "                np.round(np.mean(masked_mean_pixel_fraction[:, bin]), 4),\n",
    "                np.round(np.mean(radial_cv), 4) )\n",
    "        ]\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2857032193.py, line 143)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 143\u001b[0;36m\u001b[0m\n\u001b[0;31m    number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def get_radial_distribution(\n",
    "        cellmask: np.ndarray,\n",
    "        nuclei: Union[np.ndarray, None],\n",
    "        organelle:np.ndarray,\n",
    "        organelle_name: str,\n",
    "    ):\n",
    "    \"\"\"Perform the radial measurements on the image set\n",
    "\n",
    "    cellmask\n",
    "    image_name - make measurements on this image\n",
    "    object_name - make measurements on these objects\n",
    "    center_object_name - if None use the centers of these related objects as\n",
    "                    the centers for radial measurements. None to use the\n",
    "                    objects themselves.\n",
    "    nuclei -  if none use the user's center choice for this object:\n",
    "                    C_SELF, C_CENTERS_OF_OBJECTS or C_EDGES_OF_OBJECTS.\n",
    "    bin_count_settings - the bin count settings group\n",
    "    dd - a dictionary for saving reusable partial results\n",
    "\n",
    "    returns one statistics tuple per ring.\n",
    "    \"\"\"\n",
    "    # TODO: make these arguments\n",
    "    n_bins = 5\n",
    "    \n",
    "    bin_count = bin_count_settings.bin_count.value\n",
    "    wants_scaled = bin_count_settings.wants_scaled.value\n",
    "\n",
    "\n",
    "    maximum_radius = bin_count_settings.maximum_radius.value\n",
    "    image = workspace.image_set.get_image(image_name, must_be_grayscale=True)\n",
    "    objects = workspace.object_set.get_objects(object_name)\n",
    "    labels, pixel_data = crop_labels_and_image(objects.segmented, image.pixel_data)\n",
    "\n",
    "    nobjects = np.max(organelle)\n",
    "\n",
    "\n",
    "    d_to_edge = distance_to_edge(labels) # made a local version\n",
    "    if center_object_name is not None:\n",
    "        #\n",
    "        # Use the center of the centering objects to assign a center\n",
    "        # to each labeled pixel using propagation\n",
    "        #\n",
    "        center_objects = workspace.object_set.get_objects(center_object_name)\n",
    "\n",
    "        center_labels, cmask = size_similarly(labels, center_objects.segmented)\n",
    "        pixel_counts = fixup_scipy_ndimage_result(\n",
    "            ndi_sum(\n",
    "                np.ones(center_labels.shape),\n",
    "                center_labels,\n",
    "                np.arange(\n",
    "                    1, np.max(center_labels) + 1, dtype=np.int32\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        good = pixel_counts > 0\n",
    "        i, j = ( centers_of_labels(center_labels) + 0.5).astype(int)\n",
    "        ig = i[good]\n",
    "        jg = j[good]\n",
    "        lg = np.arange(1, len(i) + 1)[good]\n",
    "        if (center_choice == C_CENTERS_OF_OTHERS):  # Reduce the propagation labels to the centers of the centering objects\n",
    "            center_labels = np.zeros(center_labels.shape, int)\n",
    "            center_labels[ig, jg] = lg\n",
    "\n",
    "        cl, d_from_center = centrosome.propagate.propagate(  np.zeros(center_labels.shape), center_labels, labels != 0, 1)\n",
    "        cl[labels == 0] = 0            # Erase the centers that fall outside of labels\n",
    "\n",
    "        # If objects are hollow or crescent-shaped, there may be objects without center labels. As a backup, find the\n",
    "        # center that is the closest to the center of mass.\n",
    "        missing_mask = (labels != 0) & (cl == 0)\n",
    "        missing_labels = np.unique(labels[missing_mask])\n",
    "\n",
    "        if len(missing_labels):\n",
    "            all_centers = centers_of_labels(labels)\n",
    "            missing_i_centers, missing_j_centers = all_centers[:, missing_labels-1]\n",
    "            di = missing_i_centers[:, np.newaxis] - ig[np.newaxis, :]\n",
    "            dj = missing_j_centers[:, np.newaxis] - jg[np.newaxis, :]\n",
    "            missing_best = lg[np.argsort(di * di + dj * dj)[:, 0]]\n",
    "            best = np.zeros(np.max(labels) + 1, int)\n",
    "            best[missing_labels] = missing_best\n",
    "            cl[missing_mask] = best[labels[missing_mask]]\n",
    "\n",
    "            # Now compute the crow-flies distance to the centers of these pixels from whatever center was assigned to the object.\n",
    "            iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "            di = iii[missing_mask] - i[cl[missing_mask] - 1]\n",
    "            dj = jjj[missing_mask] - j[cl[missing_mask] - 1]\n",
    "            d_from_center[missing_mask] = np.sqrt(di * di + dj * dj)\n",
    "    else:\n",
    "        # Find the point in each object farthest away from the edge.\n",
    "        # This does better than the centroid:\n",
    "        # * The center is within the object\n",
    "        # * The center tends to be an interesting point, like the center of the nucleus or the center of one or the other of two touching cells.\n",
    "        i, j = maximum_position_of_labels(   d_to_edge, labels, objects.indices )\n",
    "        center_labels = np.zeros(labels.shape, int)\n",
    "        center_labels[i, j] = labels[i, j]\n",
    "        # Use the coloring trick here to process touching objectsin separate operations\n",
    "        colors = color_labels(labels)\n",
    "        ncolors = np.max(colors)\n",
    "        d_from_center = np.zeros(labels.shape)\n",
    "        cl = np.zeros(labels.shape, int)\n",
    "\n",
    "        for color in range(1, ncolors + 1):\n",
    "            mask = colors == color\n",
    "            l, d = centrosome.propagate.propagate( np.zeros(center_labels.shape), center_labels, mask, 1)\n",
    "            d_from_center[mask] = d[mask]\n",
    "            cl[mask] = l[mask]\n",
    "\n",
    "        good_mask = cl > 0\n",
    "\n",
    "        if (center_choice == C_EDGES_OF_OTHER):\n",
    "            # Exclude pixels within the centering objects\n",
    "            # when performing calculations from the centers\n",
    "            good_mask = good_mask & (center_labels == 0)\n",
    "        i_center = np.zeros(cl.shape)\n",
    "        i_center[good_mask] = i[cl[good_mask] - 1]\n",
    "        j_center = np.zeros(cl.shape)\n",
    "        j_center[good_mask] = j[cl[good_mask] - 1]\n",
    "        normalized_distance = np.zeros(labels.shape)\n",
    "\n",
    "        if wants_scaled:\n",
    "            total_distance = d_from_center + d_to_edge\n",
    "            normalized_distance[good_mask] = d_from_center[good_mask] / ( total_distance[good_mask] + 0.001 )\n",
    "        else:\n",
    "            normalized_distance[good_mask] = (d_from_center[good_mask] / maximum_radius)\n",
    "        dd[name] = [normalized_distance, i_center, j_center, good_mask]\n",
    "\n",
    "\n",
    "\n",
    "    ngood_pixels = np.sum(good_mask)\n",
    "    good_labels = labels[good_mask]\n",
    "    bin_indexes = (normalized_distance * bin_count).astype(int)\n",
    "    bin_indexes[bin_indexes > bin_count] = bin_count\n",
    "    labels_and_bins = (good_labels - 1, bin_indexes[good_mask])\n",
    "\n",
    "    histogram = coo_matrix( (pixel_data[good_mask], labels_and_bins), (nobjects, bin_count + 1) ).toarray()\n",
    "\n",
    "    sum_by_object = np.sum(histogram, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_distance = histogram / sum_by_object_per_bin\n",
    "    number_at_distance = coo_matrix)(np.ones(ngood_pixels), labels_and_bins), (nobjects, bin_count + 1)).toarray()\n",
    "\n",
    "    object_mask = number_at_distance > 0\n",
    "    sum_by_object = np.sum(number_at_distance, 1)\n",
    "    sum_by_object_per_bin = np.dstack([sum_by_object] * (bin_count + 1))[0]\n",
    "    fraction_at_bin = number_at_distance / sum_by_object_per_bin\n",
    "    mean_pixel_fraction = fraction_at_distance / ( fraction_at_bin + np.finfo(float).eps    )\n",
    "    masked_fraction_at_distance = np.ma.masked_array( fraction_at_distance, ~object_mask )\n",
    "    masked_mean_pixel_fraction = np.ma.masked_array(mean_pixel_fraction, ~object_mask)\n",
    "\n",
    "    # Anisotropy calculation.  Split each cell into eight wedges, then compute coefficient of variation of the wedges' mean intensities\n",
    "    # in each ring. Compute each pixel's delta from the center object's centroid\n",
    "    i, j = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "    imask = i[good_mask] > i_center[good_mask]\n",
    "    jmask = j[good_mask] > j_center[good_mask]\n",
    "    absmask = abs(i[good_mask] - i_center[good_mask]) > abs(\n",
    "        j[good_mask] - j_center[good_mask]\n",
    "    )\n",
    "    radial_index = (\n",
    "        imask.astype(int) + jmask.astype(int) * 2 + absmask.astype(int) * 4\n",
    "    )\n",
    "    statistics = []\n",
    "\n",
    "    for bin in range(bin_count + (0 if wants_scaled else 1)):\n",
    "        bin_mask = good_mask & (bin_indexes == bin)\n",
    "        bin_pixels = np.sum(bin_mask)\n",
    "        bin_labels = labels[bin_mask]\n",
    "        bin_radial_index = radial_index[bin_indexes[good_mask] == bin]\n",
    "        labels_and_radii = (bin_labels - 1, bin_radial_index)\n",
    "        radial_values = coo_matrix( (pixel_data[bin_mask], labels_and_radii), (nobjects, 8) ).toarray()\n",
    "        pixel_count = coo_matrix( (np.ones(bin_pixels), labels_and_radii), (nobjects, 8) ).toarray()\n",
    "\n",
    "        mask = pixel_count == 0\n",
    "        radial_means = np.ma.masked_array(radial_values / pixel_count, mask)\n",
    "        radial_cv = np.std(radial_means, 1) / np.mean(radial_means, 1)\n",
    "        radial_cv[np.sum(~mask, 1) == 0] = 0\n",
    "\n",
    "        for measurement, feature, overflow_feature in (\n",
    "            (fraction_at_distance[:, bin], MF_FRAC_AT_D, OF_FRAC_AT_D),\n",
    "            (mean_pixel_fraction[:, bin], MF_MEAN_FRAC, OF_MEAN_FRAC),\n",
    "            (np.array(radial_cv), MF_RADIAL_CV, OF_RADIAL_CV),\n",
    "        ):\n",
    "            if bin == bin_count:\n",
    "                measurement_name = overflow_feature % image_name\n",
    "            else:\n",
    "                measurement_name = feature % (image_name, bin + 1, bin_count)\n",
    " \n",
    "           measurements.add_measurement(object_name, measurement_name, measurement)\n",
    "\n",
    "            # if feature in heatmaps:\n",
    "            #     heatmaps[feature][bin_mask] = measurement[bin_labels - 1]\n",
    "\n",
    "        radial_cv.mask = np.sum(~mask, 1) == 0\n",
    "        bin_name = str(bin + 1) if bin < bin_count else \"Overflow\"\n",
    "\n",
    "        statistics += [\n",
    "            (image_name,\n",
    "                object_name,\n",
    "                bin_name,\n",
    "                str(bin_count),\n",
    "                np.round(np.mean(masked_fraction_at_distance[:, bin]), 4),\n",
    "                np.round(np.mean(masked_mean_pixel_fraction[:, bin]), 4),\n",
    "                np.round(np.mean(radial_cv), 4) )\n",
    "        ]\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# MITOCONDRIA\n",
    "###################\n",
    "mito_obj  = get_mito(img_data,meta_dict, out_data_path)\n",
    "mito_table = get_summary_stats_3D( mito_obj, img_data[MITO_CH],cytoplasm_mask)\n",
    "\n",
    "###################\n",
    "#  GOLGI\n",
    "###################\n",
    "golgi_obj = get_golgi(img_data,meta_dict, out_data_path)\n",
    "golgi_obj = get_summary_stats_3D( golgi_obj, img_data[GOLGI_CH],cytoplasm_mask)\n",
    "\n",
    "###################\n",
    "#  PEROXISOME\n",
    "###################\n",
    "perox_obj  = get_perox(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  ER\n",
    "###################\n",
    "er_obj  = get_ER(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  LIPID BODIES\n",
    "###################\n",
    "LD_obj  =  get_LD(img_data,meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(lyso_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(florescence)\n",
    "viewer.add_image(cytoplasm_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi as PI\n",
    "\n",
    "table['equivalent_diameter'], table['area'], (2 * 3 *  table['area'] / PI) ** (1 /3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SOMA, NUCLEI, CYTOSOL, NUCLEUS\n",
    "###################\n",
    "nuclei_obj =  infer_and_export_nuclei(img_data,meta_dict, out_data_path)\n",
    "\n",
    "soma_obj = infer_and_export_soma(img_data, nuclei,meta_dict, out_data_path)\n",
    "cytoplasm_mask =  infer_and_export_cytoplasm(soma_obj, nuclei_obj, meta_dict, out_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(cytoplasm_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LYSOSOME\n",
    "###################\n",
    "lyso_obj  = get_lyso(img_data,meta_dict, out_data_path)\n",
    "florescence = apply_mask(img_data[LYSO_CH],cytoplasm_mask )  \n",
    "lyso_table = get_summary_stats_3D(lyso_obj, florescence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# LYSOSOME\n",
    "###################\n",
    "lyso = infer_and_export_lyso(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "# MITOCONDRIA\n",
    "###################\n",
    "mitochondria = infer_and_export_mito(img_data,meta_dict, out_data_path)\n",
    "###################\n",
    "#  GOLGI\n",
    "###################\n",
    "golgi = infer_and_export_golgi(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  PEROXISOME\n",
    "###################\n",
    "peroxisome = infer_and_export_perox(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  ER\n",
    "###################\n",
    "er = infer_and_export_ER(img_data,meta_dict, out_data_path)\n",
    "\n",
    "###################\n",
    "#  LIPID BODIES\n",
    "###################\n",
    "lipid =  infer_and_export_LD(img_data,meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CHOOSE which inferred organelle to \n",
    "if organelle == NUC_CH: #0\n",
    "    organelle_name = 'nucleus'\n",
    "elif organelle == LYSO_CH: #1 \n",
    "    organelle_name = 'lyso'\n",
    "elif organelle == MITO_CH: #2\n",
    "    organelle_name = 'mitochondria'\n",
    "elif organelle == GOLGI_CH: #3\n",
    "    organelle_name = 'golgi'\n",
    "elif organelle == PEROX_CH: #4\n",
    "    organelle_name = 'peroxisome'\n",
    "elif organelle == ER_CH: #5\n",
    "    organelle_name = 'ER'\n",
    "elif organelle == LD_CH: #6 \n",
    "    organelle_name = 'lipid'\n",
    "elif organelle == RESIDUAL_CH: #7\n",
    "    organelle_name = 'residual'\n",
    "\n",
    "print(organelle_name)\n",
    "\n",
    "target = segmentation[organelle].squeeze()\n",
    "target = apply_mask(target, mask.squeeze())    \n",
    "target_intensity = florescence[organelle].squeeze()\n",
    "\n",
    "labels = label(target).astype(\"int\").squeeze()\n",
    "\n",
    "\n",
    "summary_stats = collect_organelle_stats(\n",
    "                                target, \n",
    "                                target_intensity\n",
    "                                )\n",
    "# target.shape, target_intensity.shape, labels.shape\n",
    "\n",
    "labels.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "run a batch of ALL the images\n",
    "\n",
    "First get all the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now build a function to loop over them all and export\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tiffs = batch_process_all_czi(data_root_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93c02d17d940b07f2fdb039339d8f031bbdf819bb53303e166c2960587ec682b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
