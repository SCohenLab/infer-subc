{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline Setup\n",
    "\n",
    "SCohenLab 3D Image Processing notebook 00.1 - Pipeline Setup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW\n",
    "\n",
    "The first thing we need to be able to do is access the data files and interact with them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS\n",
    "\n",
    "The convention with notebooks (and python in general) is to import the nescessary packages as the first thing.\n",
    "\n",
    "We are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science `aicssegmentation`.\n",
    "\n",
    "### NOTES: \n",
    "<code style=\"background:yellow;color:black\">This needs to be updated to reflect an infer_subc_3d module - what specifics will need to be in place for this transition to happen?</code>\n",
    "\n",
    "There are a few conventions used here worth explanation.  Note the `imports.py` and `constants.py` files in the base level of the `infer_subc_2d` module.  These provide sortcuts for keeping track of imports and constants.   cf. the bottom of the imports below.  A second thing to note is the use of the \"magics\" ([[ link to magics info %%]]) `%load_ext autoreload` `%autoreload 2`, which tells the notebook to reload any changes made in the source code of the module on change; hence, avoid re-executing the imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from typing import Union, List, Tuple, Any\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.pre_processing_utils import (intensity_normalization, \n",
    "                                                        image_smoothing_gaussian_slice_by_slice )\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_czi_image,\n",
    "                                        list_image_files)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles import fixed_get_optimal_Z_image, get_optimal_Z_image\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                     NUC_CH ,\n",
    "                                     LYSO_CH ,\n",
    "                                     MITO_CH ,\n",
    "                                     GOLGI_CH ,\n",
    "                                     PEROXI_CH ,\n",
    "                                     ER_CH ,\n",
    "                                     LIPID_CH ,\n",
    "                                     RESIDUAL_CH , \n",
    "                                     ALL_CHANNELS)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get and load Image for processing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read the data into memeory from the `.czi` files.  (Note: there is also the 2D slice .tif file read for later comparision).  We will also collect metatdata here.\n",
    "\n",
    "> the `data_path` variable should have the full path to the set of images wrapped in a `Path()`.   Below the path is built in 3 stages\n",
    "> 1. my user directory \"~\" plus\n",
    "> 2. general imaging data directory \"Projects/Imaging/data\" plus\n",
    "> 3. \"raw\" where the linearly unmixed zstacks are\n",
    "\n",
    "The image \"type\" is also set by `im_type = \".czi\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shannon\\\\Documents\\\\Python Scripts\\\\Infer-subc-2D\\\\raw\\\\24hrs-Ctrl_14_Unmixing.czi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will be the example for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents\\Python Scripts\\Infer-subc-2D\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files in \"raw\"\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "test_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 17, 704, 704)\n",
      "{'name': ['0 :: None :: Nuclei_Jan22', '0 :: None :: Lyso+405_Jan22', '0 :: None :: Mito+405_Jan22', '0 :: None :: Golgi+405_Jan22', '0 :: None :: Peroxy+405_Jan22', '0 :: None :: ER+405_Jan22', '0 :: None :: BODIPY+405low_Jan22', '0 :: None :: Residuals'], 'channel_axis': 0, 'scale': (0.3891184878080979, 0.07987165184837317, 0.07987165184837318), 'metadata': {'aicsimage': <AICSImage [Reader: CziReader, Image-is-in-Memory: False]>, 'raw_image_metadata': <Element 'ImageDocument' at 0x000002885E3EC810>}, 'file_name': 'C:\\\\Users\\\\Shannon\\\\Documents\\\\Python Scripts\\\\Infer-subc-2D\\\\raw\\\\24hrs-Ctrl_14_Unmixing.czi'}\n"
     ]
    }
   ],
   "source": [
    "# isolate image as an ndarray and metadata as a dictionary\n",
    "img_data, meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "print(img_data.shape)\n",
    "print(meta_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## SUMMARY\n",
    "\n",
    "The above shows the general procedure for importing the relavent modules, setting up the file I/O and finally reading in the `img_data` multichannel 3D flourescence image.\n",
    "\n",
    "### NEXT:  CHOOZE Z-SLICE\n",
    "\n",
    "proceed to [01_infer_soma_3D.ipynb](./01_infer_soma_3D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
