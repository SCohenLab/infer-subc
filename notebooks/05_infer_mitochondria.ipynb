{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer MITOCHONDRIA - part 5\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component  MITOCHONDRIA  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The MITOCHONDRIA  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.utils.file_io import read_input_image, list_image_files, export_ome_tiff\n",
    "from infer_subc.utils.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from infer_subc.organelles.mitochondria import infer_MITOCHONDRIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 5:  infer MITOCHONDRIA\n",
    "> Back to  [OUTLINE: Objective #5](#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  3\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  segment objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object MITOCHONDRIA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "CY_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "CY_object = CY_bioim.image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    "> Using Allen Cell Segmenter Tom20as a potential Mitochondrian segmenter to start with  start from [Allen Cell](https://www.allencell.org/cell-observations/category/mitochondria).   using [seg_tomm20.py](\"../../../../aics-segmentation/aicssegmentation/structure_wrapper/seg_tomm20.py\")\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel  2\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  'vesselness' enhancement\n",
    "-  threshold objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object MITOCHONDRIA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[2,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# dot and filiment enhancement - 2D\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "vesselness_sigma = [1.5]\n",
    "vesselness_cutoff = 0.16\n",
    "# 2d vesselness slice by slice\n",
    "response = vesselnessSliceBySlice(structure_img_smooth, sigmas=vesselness_sigma, tau=1, whiteonblack=True)\n",
    "bw = response > vesselness_cutoff\n",
    "\n",
    "\n",
    "# # from Sec61b workflows - playground references Tom20\n",
    "# f2_param = [[1.5, 0.16]]\n",
    "# bw = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 3D\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "min_area = 10\n",
    "################################\n",
    "\n",
    "MT_object = remove_small_objects(bw > 0, min_size=min_area, connectivity=1, in_place=False)\n",
    "cleaned_img = size_filter(bw, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= min_area**2, \n",
    "                                                         method = \"3D\" ,\n",
    "                                                         connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    MT_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_MITOCHONDRIA` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_MITOCHONDRIA\n",
    "##########################\n",
    "def _infer_MITOCHONDRIA(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer MITOCHONDRIA  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the MITOCHONDRIA signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of MITOCHONDRIA\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    scaling_param =  [0,9]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    structure_img = median_filter(struct_img,    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.3\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    # log_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization( log_img ,  scaling_param=[0] )  \n",
    "    # struct_img = intensity_normalization( struct_img ,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    vesselness_sigma = [1.5]\n",
    "    vesselness_cutoff = 0.16\n",
    "    # 2d vesselness slice by slice\n",
    "    response = vesselnessSliceBySlice(structure_img_smooth, sigmas=vesselness_sigma, tau=1, whiteonblack=True)\n",
    "    bw = response > vesselness_cutoff\n",
    "\n",
    "    out_p[\"vesselness_sigma\"] = vesselness_sigma \n",
    "    out_p[\"vesselness_cutoff\"] = vesselness_cutoff \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # MT_object = remove_small_objects(bw > 0, min_size=small_object_max**2, connectivity=1, in_place=False)\n",
    "    small_object_max = 10\n",
    "    struct_obj = size_filter(bw, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #2 (WIP)\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " > ADAPTIVE... not sure exactly how to impliment this...\n",
    "\n",
    "  >ReduceNoise performs non-local means noise reduction. Instead of only using a neighborhood of pixels around a central pixel for denoising, such as in GaussianFilter, multiple neighborhoods are pooled together. The neighborhood pool is determined by scanning the image for regions similar to the area around the central pixel using a correlation metric and a cutoff value.\n",
    "   \n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- ch 3\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  non-local noise reduction\n",
    "  - size:4, distance:2, cut-off:0.1\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - adaptive Otsu\n",
    "    - diameter: (2,200)\n",
    "  - two classes\n",
    "    - threshold smoothing scale: 0\n",
    "    - threshold correction factor: .1\n",
    "    - threshold bounds: (0.14 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "POST-PROCESSING\n",
    "  - N/A\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[2,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0] # \n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "def _enhance_speckles(image, radius, volumetric=True):\n",
    "    radius = radius / 2\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "\n",
    "    # if radius >10:\n",
    "    #         minimum = scipy.ndimage.minimum_filter(image, footprint=selem)\n",
    "    #         maximum = scipy.ndimage.maximum_filter(minimum, footprint=selem)\n",
    "    #         result = data - maximum\n",
    "    # else:\n",
    "    result =  white_tophat(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "def enhance_neurites(image, radius, volumetric = True):\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "    white = white_tophat(image,selem)\n",
    "    black = black_tophat(image, selem)\n",
    "    result = image + white - black\n",
    "    result[result > 1] = 1\n",
    "    result[result < 0] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = _enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = _enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n",
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_MITOCHONDRIA_CP` function (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "# mangle so we can call from base.py\n",
    "def _infer_MITOCHONDRIA_CP(struct_img: np.ndarray,  CY_object:np.array,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer MITOCHONDRIA from linearly unmixed input as per CellProfiler procedure\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the MITOCHONDRIA signal (should be CY masked)\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "    \n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.25\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    # 3D cleaning\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "\n",
    "\n",
    "    retval = (struct_obj, out_p)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `infer_MITOCHONDRIA` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "CY_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "CY_object = CY_bioim.image\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[2,:,:,:].copy()\n",
    "\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "\n",
    "MT_object, out_p =  infer_MITOCHONDRIA(raw_mito.copy(), CY_object, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'MT_object'\n",
    "\n",
    "MT_object_filen = export_ome_tiff(MT_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_mito,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    MT_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
