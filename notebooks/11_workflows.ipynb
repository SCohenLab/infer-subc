{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCohenLab 2D  Image Processing Workflows notebook (Simplified MCZ)\n",
    "\n",
    "--------------\n",
    "# WORKFLOWS OVERVIEW\n",
    "In order to manage efficient batch processing and UI interaction via Napari we want to leverage `aics-segmentation`s `workflow` tools.  (See also [`napari-allencell-segmenter`](https://github.com/AllenCell/napari-allencell-segmenter)).   This notebook does some initial tests out how to use these tools to build some workflows.  Hopefully these can be eaisily adjusted via a napari plugin.\n",
    "\n",
    "UPDATE (Dec 2022):  the plugin `organelle-segmenter-plugin' (creates object organelle_segmenter_plugin) was developed largely outside of this notebook.  Hence this notebook has limited expository value.\n",
    "\n",
    "\n",
    "## Workflow Levels\n",
    "\n",
    "> BATCH - an \"experiments\" worth of multi-channel images\n",
    "> SEGMENTATION WORKFLOWS \n",
    "## \"Other\" organizing principles\n",
    "\n",
    "Categories\n",
    "- Extract\n",
    "- Pre\n",
    "- Core\n",
    "- Post \n",
    "- Post-post\n",
    "\n",
    "## future organizing principles\n",
    "IO\n",
    "- import: reads file and returns array image\n",
    "- choose:  i.e. a single Z-slice or ROI -> returns slices, coordinates, indixes\n",
    "- extract: i.e. select structur channel or create aggregate signal -> returns array image\n",
    "- export: creates file\n",
    "- quantify:  returns table of stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2D Workflow example \n",
    "- IMAGE\n",
    "  - ùüò  _import_ image from .czi file\n",
    "    - input: file_path\n",
    "    - output: 4D array, metadata\n",
    "  - ùüô  _extract_ optimal Z-slice from \n",
    "    - input: 4D array (CH,Z,X,Y)\n",
    "    - output: 4D array with \"chosen\" `z_opt` (7,1,nX,nY)\n",
    "  - ùüö  binarize STRUCTURE Channel workflows\n",
    "     - 1Ô∏è‚É£ _SOMA_ workflow\n",
    "       - input: 4D array (CH,Z,X,Y)  \n",
    "       - output: SOMA mask (1,1,nX,nY)\n",
    "     - 2Ô∏è‚É£ _NUCLEI_ workflow\n",
    "       - input: 4D array (CH,Z,X,Y)  \n",
    "       - output: NU object(1,1,nX,nY)\n",
    "     - 3Ô∏è‚É£ _CYTOSOL_ workflow\n",
    "       - input: SOMA_mask, NU_mask\n",
    "       - output: CYTO mask (1,1,nX,nY)\n",
    "     - 4Ô∏è‚É£ _LYSOSOMES_ workflow\n",
    "        - input: 4D array (CH,Z,X,Y),CYTO_mask\n",
    "        - output:  LY object\n",
    "     - 5Ô∏è‚É£ _MITOCHONDRIA_ workflow\n",
    "        - input: 4D array (CH,z_slice,X,Y),CYTO_mask\n",
    "        - output:  MT object\n",
    "     - 6Ô∏è‚É£ _GOLGI complex_ workflow\n",
    "        - input: 4D array (CH,Z,X,Y),CYTO_mask\n",
    "        - output:  GL object\n",
    "     - 7Ô∏è‚É£ _PEROXISOMES_ workflow\n",
    "        - input: 4D array (CH,Z,X,Y),CYTO_mask\n",
    "        - output:  PX object\n",
    "     - 8Ô∏è‚É£ _ENDOPLASMIC RETICULUM_ workflow\n",
    "        - input: 4D array (CH,Z,X,Y),CYTO_mask\n",
    "        - output:  ER object\n",
    "     - 9Ô∏è‚É£ _LIPID BODY_ workflow\n",
    "        - input: 4D array (CH,Z,X,Y),CYTO_mask\n",
    "        - output:  LB object \n",
    "  - ùüõ  export_ binarized organelle objects\n",
    "  - 4  quantify binarized organelles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## CHOOSE Z workflow examples\n",
    "ùüô  _CHOOSE_ optimal Z-slice from \n",
    "- inputs: 4D array (CH,Z,X,Y)\n",
    " - EXTRACT:\n",
    "   - create SIG \"non-nuclei\" signal by adding ch 1-6 \n",
    "   - create NU signal aggregate\n",
    "   - return: soma(1,1,nX,nY),\n",
    "- PRE\n",
    "    - NU: intensity normalization\n",
    "    - NU: smoothing\n",
    "- CORE\n",
    "  - NU: segmentation\n",
    "- POST\n",
    "  - mask total signal to set segmented nuclei pixels to 0\n",
    "- POST-POST\n",
    "  - sum over X & Y\n",
    "  - choose maximum Z\n",
    "- output:  Z_opt slice\n",
    "\n",
    "\n",
    "\n",
    "## Structure Channel workflow examples\n",
    "1Ô∏è‚É£ _SOMA_ workflow\n",
    " - inputs: 4D array (CH,Z,X,Y)\n",
    " - EXTRACT:\n",
    "     - create \"soma\" CH aggregate\n",
    "     - return: soma(1,1,nX,nY),\n",
    "  - PRE\n",
    "    - intensity normalization\n",
    "    - smoothing\n",
    "  - CORE\n",
    "    - segmentation\n",
    "  - POST\n",
    "    - filter binarized objects\n",
    "  - output:  MT object\n",
    "\n",
    "\n",
    "5Ô∏è‚É£ _MITOCHONDRIA_ workflow\n",
    " - inputs: 4D array (CH,Z,X,Y), CYTO_mask\n",
    "  - EXTRACT:\n",
    "     - choose mitochondria CH\n",
    "     - return: (1,1,nX,nY)\n",
    "  - PRE\n",
    "    - intensity normalization\n",
    "    - smoothing\n",
    "  - CORE\n",
    "    - segmentation\n",
    "  - POST\n",
    "    - filter binarized objects\n",
    "  - output:  MT object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ù∏. IMAGE PROCESSING ‚öôÔ∏èü©ªüî¨\n",
    "### INFERENCE OF SUB-CELLULAR OBJECTS\n",
    "The imported images have already been pre-processed to transform the 32 channel spectral measuremnts into \"linearly unmixed\" images which estimate independently labeled sub-cellular components.  Thes 7 channels (plus a residual \"non-linear\" signal) will be used to infer the shapes and extents of these sub-cellular components.   \n",
    "We will perform computational image analysis on the pictures (in 2D an 3D) to _segment_ the components of interest for measurement.  In other prcoedures we can used these labels as \"ground truth\" labels to train machine learning models to automatically perform the inference of these objects.\n",
    "Pseudo-independent processing of the imported multi-channel image to acheive each of the 9 objecives stated above.  i.e. infering: NUCLEI, SOMA, CYTOSOL, LYSOSOME, MITOCHONDRIA, GOLGI COMPLEX, PEROZISOMES, ENDOPLASMIC RETICULUM, and LIPID BODIES\n",
    "\n",
    "### General flow for infering objects via segmentation\n",
    "- Pre-processing üåí\n",
    "- Core-processing (thresholding) üåï\n",
    "- Post-processing  üåò\n",
    "\n",
    "### QC üöß WIP üöß \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ‚ùπ. QUANTIFICATION üìèüìêüßÆ\n",
    "\n",
    "SUBCELLULAR COMPONENT METRICS\n",
    "-  extent \n",
    "-  size\n",
    "-  shape\n",
    "-  position\n",
    "\n",
    "\n",
    "\n",
    "### NOTE: PIPELINE TOOL AND DESIGN CHOICES?\n",
    "We want to leverage the Allen Cell & Structure Setmenter.  It has been wrapped as a [napari-plugin](https://www.napari-hub.org/plugins/napari-allencell-segmenter) but fore the workflow we are proving out here we will want to call the `aicssegmentation` [package](https://github.com/AllenCell/aics-segmentation) directly.\n",
    "\n",
    "#### ‚ÄãThe Allen Cell & Structure Segmenter \n",
    "‚ÄãThe Allen Cell & Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.\n",
    "\n",
    "More details about Segmenter can be found at https://allencell.org/segmenter\n",
    "In order to leverage the A\n",
    "# IMPORTS\n",
    "\n",
    "import  all nescessary packages\n",
    "\n",
    "we are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import median_filter\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice, edge_preserving_smoothing_3d )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_czi_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray,\n",
    "                                                                    napari_aiscimageio_reader_fn)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles import *\n",
    "\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROXI_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LIPID_CH ,\n",
    "                                                                    RESIDUAL_CH )\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out, meta_out, layer_type = napari_aiscimageio_reader_fn(test_img_name)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': ['0 :: None :: Nuclei_Jan22',\n",
       "   '0 :: None :: Lyso+405_Jan22',\n",
       "   '0 :: None :: Mito+405_Jan22',\n",
       "   '0 :: None :: Golgi+405_Jan22',\n",
       "   '0 :: None :: Peroxy+405_Jan22',\n",
       "   '0 :: None :: ER+405_Jan22',\n",
       "   '0 :: None :: BODIPY+405low_Jan22',\n",
       "   '0 :: None :: Residuals'],\n",
       "  'channel_axis': 0,\n",
       "  'scale': (0.5804527163320905, 0.07987165184837318, 0.07987165184837318),\n",
       "  'metadata': {'aicsimage': <AICSImage [Reader: CziReader, Image-is-in-Memory: False]>,\n",
       "   'raw_image_metadata': <Element 'ImageDocument' at 0x155ab0720>}},\n",
       " (8, 16, 768, 768),\n",
       " 'image')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_out, data_out.shape, layer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_name.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'data_out' at 0x17beeb5b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(\n",
    "    data_out,\n",
    "    scale=scale,\n",
    "    colormap='blue', \n",
    "    blending='additive'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x17e8e94c0>,\n",
       " <Image layer 'Image [1]' at 0x17ea4cdc0>,\n",
       " <Image layer 'Image [2]' at 0x1886c2340>,\n",
       " <Image layer 'Image [3]' at 0x18872dcd0>,\n",
       " <Image layer 'Image [4]' at 0x1887ea160>,\n",
       " <Image layer 'Image [5]' at 0x188858f70>,\n",
       " <Image layer 'Image [6]' at 0x1889131c0>,\n",
       " <Image layer 'Image [7]' at 0x188984ee0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    data_out,\n",
    "    channel_axis=meta_out['channel_axis'],\n",
    "    scale=scale,\n",
    "    colormap='red', \n",
    "    blending='additive'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_engine = InferSubC2dWorkflowEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(workflow_engine.workflow_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = workflow_engine.get_executable_workflow_from_config_file(\n",
    "        \"../infer_subc_2d/organelles_config/conf_actb.json\",\n",
    "        img_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aicssegmentation.workflow.workflow.Workflow"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wf.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = wf.execute_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functions = workflow_engine._workflow_config.get_all_functions()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_definition = wf.workflow_definition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
