{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***cellmask*** from a composite image -  2️⃣ \n",
    "\n",
    "--------------\n",
    "\n",
    "## OVERVIEW\n",
    "In this notebook, we will continue segmenting the different cell regions - the nucleus, cell, and cytoplasm - since they will be necessary for determining which organelle are in which cell. This is integral to our single cell analysis approach.\n",
    "\n",
    "This notebook goes through the workflow steps to segment the ***cell*** from a composite image made from a combination of fluorescent organelle marker.\n",
    "\n",
    "> WARNING: 🚨🚨🚨🚨\n",
    ">> Because we do NOT have a direct cell membrane or cell-fill signal, this segmentation is difficult and potentially problematic. The cell mask will be used to determine the area of each single in our single cell analysis.\n",
    "\n",
    "\n",
    "\n",
    "## OBJECTIVE: \n",
    "### ✅ Infer sub-cellular component #2: ***cellmask***\n",
    "Segment the cell area -- the ***cellmask*** -- from a composite image of multiple organelle markers combined. This method is used in the case where there is no cell fill/membrane marker.\n",
    "\n",
    "In this example, there are multiple cells per field of view, but some of the cells do not contain all of the fluorescent markers (due to the transfection protocol used). Therefore, we will use a single cell selection process to identify the cell with the highest total fluorescence after all markers are combined. This assumption could lead to the selection of the \"wrong\" cell, but in pratice it has worked reasonably well. *In the future, more sophisticated quality control methods could be implemented to select cells with all of the labels.*\n",
    "\n",
    "The cellmask will be necessary for determining the area of individual cells in our single cell analysis approach.\n",
    "\n",
    "> ***Biological relevance:*** \n",
    "> The combination of organelle markers used to create the composite image for the cellmask segmentation depends on the organelle labeles used and the cell type. In this example, the current selection includes the lysosomes, ER, and Golgi (e.g., Ch = 1, 3, 5) which have some intracellular background fluorescence - likely from off target marker localization. The lipid droplet channel (e.g., `ch = 6`) could also be included to produce a more unbiased selection of the entire cellmask as it binds to all cellular membranes to a small extent. However, the drawback of this is that it is present in every cell which makes downstream cell selection of a single cell more challenging. \n",
    ">\n",
    "> *It is important to consider specifics of your system as the cell type and labeling method may differ from the example above.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed, clear_border\n",
    "from skimage.morphology import remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                     read_ome_image,\n",
    "                                     import_inferred_organelle,\n",
    "                                     export_inferred_organelle,\n",
    "                                     list_image_files)\n",
    "\n",
    "                                             \n",
    "from infer_subc.core.img import *\n",
    "from infer_subc.organelles import (get_nuclei, \n",
    "                                   non_linear_cellmask_transform,\n",
    "                                   choose_max_label_cellmask_union_nucleus)\n",
    "from infer_subc.constants import (TEST_IMG_N,\n",
    "                                  NUC_CH ,\n",
    "                                  LYSO_CH ,\n",
    "                                  MITO_CH ,\n",
    "                                  GOLGI_CH ,\n",
    "                                  PEROX_CH ,\n",
    "                                  ER_CH ,\n",
    "                                  LD_CH ,\n",
    "                                  RESIDUAL_CH) \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and load Image for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents/Python Scripts/Infer-subc-2D\"\n",
    "\n",
    "in_data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "out_data_path = data_root_path / \"out\"\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shannon\\anaconda3\\envs\\infer-subc\\lib\\site-packages\\ome_types\\_convenience.py:112: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "##  infer ***cellmask***\n",
    "\n",
    "### summary of steps\n",
    "\n",
    "➡️ INPUT (extract)\n",
    "- segmented nuclei object (from [01_infer_nuclei](./02_infer_cellmask_from-composite.ipynb))\n",
    "- create composite image from multiple organelle channels\n",
    "\n",
    "PRE-PROCESSING\n",
    "- rescale image intensities: \n",
    "    - min=0, max=1\n",
    "- smooth image:\n",
    "    - median filter (media size = user input)\n",
    "    - gaussian filter (sigma = user input)\n",
    "- log transform image\n",
    "- apply scharr edge detection filter \n",
    "- combine log imge + scharr edge filtered intensity\n",
    "\n",
    "CORE PROCESSING\n",
    "- apply MO thresholding method from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes (hole size = user input)\n",
    "  - remove small objects (object size = user input)\n",
    "\n",
    "OUTPUT ➡️ \n",
    "  - label unique cell objects based on watershed seeded from the nuclei objects\n",
    "  - select the single cell with the highest combined fluorescence \n",
    "  - save single ***cellmask*** (cell, CM) at unsigned integer 8-bit tif files\n",
    "\n",
    "\n",
    "> ***Note:*** this pipeline will eventually include a selection step to identify the cellmask that are properly labeled with all fluorescent markers. This could be one single cell per image, or more if applicable data is available.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET nuclei segmentation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  inferred 3D `nuclei`  from C:\\Users\\Shannon\\Documents\\Python Scripts\\Infer-subc-2D\\out \n"
     ]
    }
   ],
   "source": [
    "# Import nuclei segmentation from output folder, or \n",
    "# run nuclei segmentation with hard coded segmentation settings (not ideal for most scenarios)\n",
    "nuclei_labels = get_nuclei(img_data, meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the the image was correctly saved as uint16\n",
    "nuclei_labels.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTION prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "# add channels together with different weights\n",
    "struct_img_raw = (6. * img_data[LYSO_CH].copy().astype(np.double) +\n",
    "                  1. * img_data[ER_CH].copy().astype(np.double) + \n",
    "                  2. * img_data[GOLGI_CH].copy().astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1386., 1045.,  760., 1137., 1011., 1808.,    0., 1538., 1783.,\n",
       "        5187.]),\n",
       " array([1386., 1045.,  760., 1137., 1011., 1808.,    0., 1538., 1783.,\n",
       "        5187.]),\n",
       " array([1386., 1045.,  760., 1137., 1011., 1808.,    0., 1538., 1783.,\n",
       "        5187.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function to create composite image:\n",
    "weights =  [0,6,0,2,0,1]\n",
    "struct_img_raw2 = weighted_aggregate(img_data, *weights)\n",
    "\n",
    "# use splat so we can also break out the arguments for our napari widget later\n",
    "struct_img_raw3 = weighted_aggregate(img_data, 0,6,0,2,0,1)\n",
    "\n",
    "\n",
    "# Comfirming the results are the same:\n",
    "struct_img_raw[0,0:10,0], struct_img_raw2[0,0:10,0], struct_img_raw3[0,0:10,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING prototype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "med_filter_size = 15  \n",
    "gaussian_smoothing_sigma = 1.34\n",
    "\n",
    "structure_img_smooth = scale_and_smooth(struct_img_raw2,\n",
    "                                        median_size = med_filter_size, \n",
    "                                        gauss_sigma = gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scale the image, apply the scharr edge detection filter to logged image, add the two images together\n",
    "composite_cellmask = non_linear_cellmask_transform(structure_img_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1090x686+1040+172 (frame: 1108x733+1031+134) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1365x859+1041+179 (frame: 1383x906+1032+141) margins: 9, 38, 9, 9 minimum size: 612x589 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=630,636 maxtrack=0,0)\n",
      "26-May-23 17:49:52 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 1090x686+1040+172 (frame: 1108x733+1031+134) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1365x859+1041+179 (frame: 1383x906+1032+141) margins: 9, 38, 9, 9 minimum size: 612x589 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=630,636 maxtrack=0,0)\n",
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 3844x1339+1041+179 (frame: 3860x1378+1033+148) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY2\". Resulting geometry: 3074x1070+1040+172 (frame: 3090x1109+1032+141) margins: 8, 31, 8, 8 minimum size: 612x587 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=628,626 maxtrack=0,0)\n",
      "26-May-23 17:49:52 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 3844x1339+1041+179 (frame: 3860x1378+1033+148) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY2\". Resulting geometry: 3074x1070+1040+172 (frame: 3090x1109+1032+141) margins: 8, 31, 8, 8 minimum size: 612x587 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=628,626 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'composite_cellmask' at 0x18b62bf03a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(structure_img_smooth)\n",
    "viewer.add_image(composite_cellmask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# threshold the composite image after log/edge detection using the MO filter function from aicssegmentation - this applies a global threshold, then a local threshold to produce a semantic segmentation\n",
    "thresh_method = 'ave'\n",
    "cutoff_size =  150\n",
    "thresh_adj = 0.5\n",
    "\n",
    "bw = masked_object_thresh(composite_cellmask, \n",
    "                          global_method=thresh_method, \n",
    "                          cutoff_size=cutoff_size, \n",
    "                          local_adjust=thresh_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'bw' at 0x18b8a4d76d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(bw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST-PROCESSING prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "hole_min_width = 0\n",
    "hole_max_width = 50\n",
    "\n",
    "small_object_width = 45\n",
    "\n",
    "# removed_holes = hole_filling_linear_size(li_thresholded, \n",
    "#                                          hole_min=hole_min_width, \n",
    "#                                          hole_max=hole_max_width)\n",
    "# \n",
    "# cleaned_img = size_filter_linear_size(removed_holes,\n",
    "#                                       min_size=small_object_width)\n",
    "\n",
    "cleaned_img2 = fill_and_filter_linear_size(bw, \n",
    "                                           hole_min=hole_min_width, \n",
    "                                           hole_max=hole_max_width, \n",
    "                                           min_size= small_object_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'cleaned_img2' at 0x18b8a59d0c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(cleaned_img2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST POST-PROCESSING prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST- POST_PROCESSING\n",
    "###################\n",
    "# apply a watershed to the inverted image using the nuclei as a seed for each cell\n",
    "watershed_method = '3D'\n",
    "cellmask_labels = masked_inverted_watershed(structure_img_smooth, \n",
    "                                            nuclei_labels, \n",
    "                                            cleaned_img2,\n",
    "                                            method=watershed_method)\n",
    "\n",
    "# find the cell with the highest total fluorescence after combining all channels together\n",
    "keep_label = get_max_label(composite_cellmask, \n",
    "                           cellmask_labels)\n",
    "\n",
    "\n",
    "# combine the above and find the nucleus associated to the highest fluorescence cell\n",
    "cellmask_out = choose_max_label_cellmask_union_nucleus(structure_img_smooth,\n",
    "                                                       cleaned_img2, \n",
    "                                                       nuclei_labels,\n",
    "                                                       watershed_method=watershed_method)\n",
    "\n",
    "cellmask = cellmask_out.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellmask.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABELING prototype\n",
    "\n",
    "No labeling steps needed for this workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with `napari` 1\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(cleaned_img2, \n",
    "                           scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(\n",
    "    cellmask, \n",
    "    scale=scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE inferred nuclei to .tif file\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer nuclei.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_n = export_inferred_organelle(cellmask, \"cell\", meta_dict, out_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## DEFINE `infer_cellmask_fromcomposite` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer nuclei. \n",
    "\n",
    "> NOTE: these functions mainly serve for downstream prototyping in the notebooks. Each step above has an independent function that is implemented in the plugin for easy of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 1. infer_cellmask_fromaggr\n",
    "##########################\n",
    "def _infer_cellmask_fromcomposite(in_img: np.ndarray,\n",
    "                                  weights: list[int],\n",
    "                                  nuclei_labels: np.ndarray,\n",
    "                                  median_sz: int,\n",
    "                                  gauss_sig: float,\n",
    "                                  mo_method: str,\n",
    "                                  mo_adjust: float,\n",
    "                                  mo_cutoff_size: int,\n",
    "                                  min_hole_w: int,\n",
    "                                  max_hole_w: int,\n",
    "                                  small_obj_w: int,\n",
    "                                  watershed_method: str\n",
    "                                  ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer cellmask from linear unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "    weights:\n",
    "        a list of int that corresond to the weights for each channel in the composite; use 0 if a channel should not be included in the composite image\n",
    "    nuclei_labels: \n",
    "        a 3d image containing the inferred nuclei labels\n",
    "    median_sz: \n",
    "        width of median filter for _cellmask_ signal\n",
    "    gauss_sig: \n",
    "        sigma for gaussian smoothing of _cellmask_ signal\n",
    "    mo_method: \n",
    "         which method to use for calculating global threshold. Options include:\n",
    "         \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").\n",
    "         \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n",
    "    mo_adjust: \n",
    "        Masked Object threshold `local_adjust`\n",
    "    mo_cutoff_size: \n",
    "        Masked Object threshold `size_min`\n",
    "    max_hole_w: \n",
    "        hole filling cutoff for cellmask signal post-processing\n",
    "    small_obj_w: \n",
    "        minimu object size cutoff for cellmask signal post-processing\n",
    "    watershed_method:\n",
    "        determines if the watershed should be run 'sice-by-slice' or in '3D' \n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    cellmask_mask:\n",
    "        a logical/labels object defining boundaries of cellmask\n",
    "\n",
    "    \"\"\"\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################\n",
    "    struct_img = weighted_aggregate(in_img, *weights)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    struct_img =  scale_and_smooth(struct_img,\n",
    "                                   median_sz = median_sz, \n",
    "                                   gauss_sig = gauss_sig)\n",
    "    \n",
    "\n",
    "    struct_img_non_lin = non_linear_cellmask_transform(struct_img)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    struct_obj = masked_object_thresh(struct_img_non_lin, \n",
    "                                      global_method=mo_method, \n",
    "                                      cutoff_size=mo_cutoff_size, \n",
    "                                      local_adjust=mo_adjust)               \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    struct_obj = fill_and_filter_linear_size(struct_obj, \n",
    "                                             hole_min=min_hole_w, \n",
    "                                             hole_max=max_hole_w, \n",
    "                                             min_size= small_obj_w)\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    cellmask_out = choose_max_label_cellmask_union_nucleus(struct_img, \n",
    "                                                           struct_obj, \n",
    "                                                           nuclei_labels, \n",
    "                                                           watershed_method=watershed_method) \n",
    "\n",
    "    return cellmask_out.astype(bool)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_fixed_infer_cellmask_fromcomposite` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer cellmask. with a *fixed* set of parameters for each step in the procedure.  That is they are all \"hard coded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 1. fixed_infer_cellmask_fromaggr\n",
    "##########################\n",
    "def _fixed_infer_cellmask_fromcomposite(in_img: np.ndarray, nuclei_labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer cellmask from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "    nuclei_labels: \n",
    "        a 3d image containing the inferred nuclei\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    cellmask_mask:\n",
    "        a logical/labels object defining boundaries of cellmask\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    ###################\n",
    "    # PARAMETERS\n",
    "    ###################   \n",
    "    weights = [0,6,0,2,0,1]\n",
    "    median_sz = 15\n",
    "    gauss_sig = 1.34\n",
    "    mo_method = \"ave\"\n",
    "    mo_adjust = 0.5\n",
    "    mo_cutoff_size = 150\n",
    "    hole_min_width = 0\n",
    "    hole_max_width = 50\n",
    "    small_obj_w = 45\n",
    "    watershed_method = '3D'\n",
    "\n",
    "    cellmask_out = _infer_cellmask_fromcomposite(in_img,\n",
    "                                                weights,\n",
    "                                                nuclei_labels,\n",
    "                                                median_sz,\n",
    "                                                gauss_sig,\n",
    "                                                mo_method,\n",
    "                                                mo_adjust,\n",
    "                                                mo_cutoff_size,\n",
    "                                                hole_min_width,\n",
    "                                                hole_max_width,\n",
    "                                                small_obj_w,\n",
    "                                                watershed_method) \n",
    "\n",
    "    return cellmask_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST `_infer_cellmask_fromcomposite`  function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CM_object =  _fixed_infer_cellmask_fromcomposite(img_data, nuclei_labels) \n",
    "\n",
    "_CM_object.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(cellmask == _CM_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# TEST `infer_cellmask_fromcomposite` exported functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles import fixed_infer_cellmask_fromcomposite\n",
    "\n",
    "cellmask_mask =  fixed_infer_cellmask_fromcomposite(img_data, nuclei_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(cellmask_out == cellmask_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize  2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(\n",
    "    cellmask_mask,\n",
    "    scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## SUMMARY\n",
    "\n",
    "The above details how the nuclei object is inferred.  \n",
    "\n",
    "### NEXT: INFER CYTOPLASM\n",
    "\n",
    "proceed to [03_infer_cytoplasm.ipynb](./03_infer_cytoplasm.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
