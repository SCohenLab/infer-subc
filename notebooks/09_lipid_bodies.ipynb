{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer LIPID BODIES - part 8\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component LIPID BODIES  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The ER  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be organzied to explain the imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "# function for core algorithm\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, hole_filling\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters, img_as_float\n",
    "from skimage import morphology\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball, disk, dilation, white_tophat, black_tophat   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "# from aicsimageio import AICSImage\n",
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "    from infer_subc.base import *\n",
    "else:\n",
    "    from infer_subc.base import *\n",
    "\n",
    "viewer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 9:  infer LIPID BODIES \n",
    "> Back to  [OUTLINE: Objective #5](#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- ch 7\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- rescale \n",
    "-  median, window 2\n",
    "-  \n",
    "CORE-PROCESSING\n",
    "   - \"robust background\" 2 STD\n",
    "\n",
    "POST-PROCESSING\n",
    "  - n/a\n",
    "\n",
    "OUTPUT\n",
    "- object BD\n",
    "\n",
    "\n",
    "NOTE:  consider using [Fibrillarin](https://www.allencell.org/cell-observations/category/fibrillarin) (nucleous marker) workflow from AllenCell.  playground_spotty.ipynb  or maybe [centrin](https://www.allencell.org/cell-observations/category/centrin)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "##  set up files\n",
    "\n",
    "data_path = Path( f\"{os.getenv('HOME')}/Projects/Imaging/mcz_subcell/data\")\n",
    "czi_img_folder = data_path/\"raw\"\n",
    "\n",
    "list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "\n",
    "img_file_list = list_img_files(czi_img_folder,'.czi')\n",
    "print(img_file_list[5])\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "img_data, meta_dict = read_input_image(test_img_name)\n",
    "\n",
    "raw_meta_data, ome_types = get_raw_meta_data(meta_dict)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 :: None :: Nuclei_Jan22',\n",
       " '0 :: None :: Lyso+405_Jan22',\n",
       " '0 :: None :: Mito+405_Jan22',\n",
       " '0 :: None :: Golgi+405_Jan22',\n",
       " '0 :: None :: Peroxy+405_Jan22',\n",
       " '0 :: None :: ER+405_Jan22',\n",
       " '0 :: None :: BODIPY+405low_Jan22',\n",
       " '0 :: None :: Residuals']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "# CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n",
    "channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Not a good thing to follow from  the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "\n",
    "INPUT\n",
    "- ch 6\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- median width = 2\n",
    "\n",
    "CORE-PROCESSING\n",
    "- global thresholding (robust background)\n",
    "- 4,40 (2,40 6/28)\n",
    "- outlier fraction 0.05, 0.05\n",
    "- 3 standard deviations (2)\n",
    "- .18,1 (.5, 1)\n",
    "- intensity de-clumping\n",
    "- smoothe 2\n",
    "\n",
    "POST-PROCESSING\n",
    "  - S  - remove objects less than 2x2 pixels (area = 4)\n",
    "\n",
    "OUTPUT\n",
    "- object PEROXISOMES \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = DEFAULT_PARAMS\n",
    "\n",
    "\n",
    "################################\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 927.0447633531359\n",
      "the standard deviation of intensity of the stack: 965.1801115030788\n",
      "0.9999 percentile of the stack intensity is: 11286.563399996608\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 11.0, which is 11544.025989887004\n",
      "suggested lower range is 0.5, which is 444.45470760159645\n",
      "So, suggested parameter for normalization is [0.5, 11.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT ER\n",
    "###################\n",
    "raw_lb = img_data[6,:,:,:].copy()\n",
    "\n",
    "#LB_object, out_p =  infer_LIPID_BODY(raw_er.copy(), CY_object, out_p) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size = 4  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3448\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(raw_lb) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "intensity_norm_param = [0]  # CHECK THIS\n",
    "# Linear-ish smoothing\n",
    "struct_img = intensity_normalization( raw_lb ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "# edge-preserving smoothing (Option 2, used for Sec61B)\n",
    "#structure_img_smooth = edge_preserving_smoothing_3d(struct_img)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                struct_img,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "threshold =  get_threshold_robust_background(structure_img_smooth, num_dev = 3.5)\n",
    "\n",
    "bw = np.zeros_like(struct_img)\n",
    "bw[struct_img >= threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0444796571381049, 0.01408403789254324, 0.013679285693589229)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold, struct_img.mean(),struct_img.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw[:10,:10]>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "hole_max = 4 \n",
    "struct_obj = aicssegmentation.core.utils.hole_filling(bw>0, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 4 # 4\n",
    "################################\n",
    "LB_object = remove_small_objects(struct_obj, min_size=minArea, connectivity=1, in_place=False)\n",
    "\n",
    "\n",
    "    # 3D cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'LB_object [2]' at 0x17cf9dfd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# viewer = napari.view_image(\n",
    "#     struct_img,\n",
    "#     scale=scale \n",
    "# )\n",
    "\n",
    "viewer.add_image(\n",
    "    struct_img,\n",
    "    scale=scale \n",
    ")\n",
    "viewer.add_image(\n",
    "    raw_lb,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    bw,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    LB_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_LIBID_BODIES` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  ### DEFINE `infer_LIBID_BODIES` function\n",
    "##########################\n",
    "def infer_LIBID_BODIES(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer LIPID BODIES  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the LIPID BODIES   signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of LIPID BODIES  \n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    intensity_norm_param = [0]  # CHECK THIS\n",
    "\n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=intensity_norm_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 4   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.344\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    num_dev = 4.0\n",
    "\n",
    "    threshold =  get_threshold_robust_background(structure_img_smooth, num_dev = num_dev)\n",
    "\n",
    "    struct_obj  = np.zeros_like(struct_img)\n",
    "    struct_obj [struct_img >= threshold] = 1\n",
    "\n",
    "    out_p[\"num_dev\"] = num_dev \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    " ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 20  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 20\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `LIPID BODIES  ` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "mean intensity of the stack: 927.0447633531359\n",
      "the standard deviation of intensity of the stack: 965.1801115030788\n",
      "0.9999 percentile of the stack intensity is: 11286.563399996608\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 11.0, which is 11544.025989887004\n",
      "suggested lower range is 0.5, which is 444.45470760159645\n",
      "So, suggested parameter for normalization is [0.5, 11.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "['LB_object']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[6,:,:,:].copy()\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_lb= intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n",
    "\n",
    "\n",
    "LB_object, out_p =  infer_LIBID_BODIES(raw_lb.copy(), CY_object, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'LB_object'\n",
    "\n",
    "LB_object_filen = export_ome_tiff(LB_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
