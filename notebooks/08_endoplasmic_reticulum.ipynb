{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ENDOPLASMIC RETICULUM - part 8\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component ENDOPLASMIC RETICULUM (ER) in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The ER  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be organzied to explain the imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "# function for core algorithm\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, hole_filling\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters, img_as_float\n",
    "from skimage import morphology\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball, disk, dilation, white_tophat, black_tophat   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "# from aicsimageio import AICSImage\n",
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#import .infer_subc.base\n",
    "from infer_subc.base import *\n",
    "\n",
    "viewer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 8:  infer ER\n",
    "> Back to  [OUTLINE: Objective #5](#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  6\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  segment objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - n/a\n",
    "\n",
    "OUTPUT\n",
    "- object PEROXISOMES \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  set up files\n",
    "\n",
    "data_path = Path( f\"{os.getenv('HOME')}/Projects/Imaging/mcz_subcell/data\")\n",
    "czi_img_folder = data_path/\"raw\"\n",
    "\n",
    "list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "\n",
    "img_file_list = list_img_files(czi_img_folder,'.czi')\n",
    "print(img_file_list[5])\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "img_data, meta_dict = read_input_image(test_img_name)\n",
    "\n",
    "raw_meta_data, ome_types = get_raw_meta_data(meta_dict)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    ">sec61beta  is  good start for ER  as per from [Allen Cell](https://www.allencell.org/cell-observations/category/endoplasmic-reticulum).    \n",
    "\n",
    "using [seg_sec61b.py](\"../../../../aics-segmentation/aicssegmentation/structure_wrapper/seg_sec61b.py\")\n",
    "[seg_sec61b_dual.py](\"../../../../aics-segmentation/aicssegmentation/structure_wrapper/seg_sec61b_dual.py\")\n",
    "\n",
    "[playground_Sec61b.ipynb](\"../../../../aics-segmentation/lookup_table_demo/playground_Sec61b.ipynb\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "\n",
    "INPUT\n",
    "- ch 4\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- edge preserving scaling\n",
    "\n",
    "CORE-PROCESSING\n",
    "- vesselness slice-by-slice\n",
    "\n",
    "POST-PROCESSING\n",
    "  - S  - remove objects less than 2x2 pixels (area = 4)\n",
    "\n",
    "OUTPUT\n",
    "- object PEROXISOMES \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[5,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "intensity_norm_param = [0]  # CHECK THIS\n",
    "# Linear-ish smoothing\n",
    "struct_img = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "# edge-preserving smoothing (Option 2, used for Sec61B)\n",
    "structure_img_smooth = edge_preserving_smoothing_3d(struct_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "\n",
    "bw = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 20\n",
    "################################\n",
    "GO_object = remove_small_objects(bw>0, min_size=minArea, connectivity=1, in_place=False)\n",
    "\n",
    "# ################################\n",
    "# ## PARAMETERS for this step ## from seg_sec61b.py\n",
    "# min_area = 15\n",
    "# ################################\n",
    "# bw = remove_small_objects(bw > 0, min_size=min_area, connectivity=1, in_place=False)\n",
    "# # prune slice by slice\n",
    "# for zz in range(bw.shape[0]):\n",
    "#     bw[zz, :, :] = remove_small_objects(bw[zz, :, :], min_size=3, connectivity=1, in_place=False)\n",
    "\n",
    "# ER_object = remove_small_objects(bw > 0, min_size=min_area, connectivity=1, in_place=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        bw_combine,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        bw_combine,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    GO_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_ENDOPLASMIC_RETICULUM` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_ENDOPLASMIC_RETICULUM\n",
    "##########################\n",
    "def infer_ENDOPLASMIC_RETICULUM(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer PEROXISOME  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the PEROXISOME signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of PEROXISOME\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    intensity_norm_param = [0]  # CHECK THIS\n",
    "\n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=intensity_norm_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    # edge-preserving smoothing (Option 2, used for Sec61B)\n",
    "    structure_img_smooth = edge_preserving_smoothing_3d(struct_img)\n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    f2_param = [[1, 0.15]]\n",
    "    ################################\n",
    "\n",
    "    struct_obj = filament_2d_wrapper(struct_img, f2_param)\n",
    "    out_p[\"f2_param\"] = f2_param \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    " \n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    min_area = 20\n",
    "    ################################\n",
    "    struct_obj = remove_small_objects(struct_obj>0, min_size=min_area, connectivity=1, in_place=False)\n",
    "    out_p[\"min_area\"] = min_area \n",
    "\n",
    "\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #2 (WIP)\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " \n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- ch 6\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- rescale \n",
    "- median window:4\n",
    "- non-local noise reduction\n",
    "  - size:5, distance:1, cut-off:0.1\n",
    "- identify \"TUBES\"\n",
    "  - enhance neurites\n",
    "    - > Neurites: Neurites are taken to be long, thin features of enhanced intensity. Choose this option to enhance the intensity of the neurites using the Line structures or Tubeness methods described in a later setting.  \n",
    "    - method: tubeness\n",
    "    - > Tubeness: This method is an adaptation of the method used by the ImageJ Tubeness plugin. The image is smoothed with a Gaussian. The Hessian is then computed at every point to measure the intensity gradient and the eigenvalues of the Hessian are computed to determine the magnitude of the intensity. The absolute maximum of the two eigenvalues gives a measure of the ratio of the intensity of the gradient in the direction of its most rapid descent versus in the orthogonal direction. The output image is the absolute magnitude of the highest eigenvalue if that eigenvalue is negative (white neurite on dark background), otherwise, zero. \n",
    "    - smoothing: 2 pix\n",
    "\n",
    "CORE-PROCESSING\n",
    "- identify primary objects \"TUBES\"\n",
    "    - adaptive Sauvola\n",
    "      - threshold smoothing scale: 0\n",
    "      - threshold correction factor: .6\n",
    "      - threshold bounds: (0. ,1.0)\n",
    "      - adaptive window: 20 pixels\n",
    "- identify primary objects \"SHEETS\"\n",
    "  - ER masked w/ CY\n",
    "  - adaptive Otsu\n",
    "      - diameter: (2,50)\n",
    "    - two classes\n",
    "      - threshold smoothing scale: 0\n",
    "      - threshold correction factor: 1\n",
    "      - threshold bounds: (0.18, .25)\n",
    "      - adaptive window: 10 pixels\n",
    "- combine \"TUBES\" and \"SHEETS\"\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- object ER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[3,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0] # \n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "def _enhance_speckles(image, radius, volumetric=True):\n",
    "    radius = radius / 2\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "\n",
    "    # if radius >10:\n",
    "    #         minimum = scipy.ndimage.minimum_filter(image, footprint=selem)\n",
    "    #         maximum = scipy.ndimage.maximum_filter(minimum, footprint=selem)\n",
    "    #         result = data - maximum\n",
    "    # else:\n",
    "    result =  white_tophat(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "def enhance_neurites(image, radius, volumetric = True):\n",
    "    if volumetric:\n",
    "        selem = ball(radius)\n",
    "    else:\n",
    "        selem = disk(radius)     \n",
    "    white = white_tophat(image,selem)\n",
    "    black = black_tophat(image, selem)\n",
    "    result = image + white - black\n",
    "    result[result > 1] = 1\n",
    "    result[result < 0] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = _enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = _enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n",
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `_infer_PEROXISOME_CP` function (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "# mangle so we can call from base.py\n",
    "def _infer_PEROXISOME_CP(struct_img: np.ndarray,  CY_object:np.array,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer GOLGI from linearly unmixed input as per CellProfiler procedure\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the GOLGI signal (should be CY masked)\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "    \n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.25\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    # 3D cleaning\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "\n",
    "\n",
    "    retval = (struct_obj, out_p)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `infer_PEROXISOME` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[4,:,:,:].copy()\n",
    "\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_peroxi = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "\n",
    "PO_object, PO_label, out_p =  infer_PEROXISOME(raw_peroxi.copy(), CY_object, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'PO_object'\n",
    "\n",
    "PO_object_filen = export_ome_tiff(PO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_golgi,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    GL_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
