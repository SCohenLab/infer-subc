{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ENDOPLASMIC RETICULUM - part 8️⃣\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  ✅ Infer sub-cellular component ENDOPLASMIC RETICULUM (ER) in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The ER  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice, edge_preserving_smoothing_3d )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_input_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles.nuclei import infer_NUCLEI\n",
    "from infer_subc_2d.organelles.soma import infer_SOMA\n",
    "from infer_subc_2d.organelles.cytosol import infer_CYTOSOL\n",
    "from infer_subc_2d.constants import TEST_IMG_N\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 8:  infer ER\n",
    "> Back to  [OUTLINE: Objective #5](00_pipeline_setup.ipynb#summary-of-objectives)\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  6\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  segment objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - n/a\n",
    "\n",
    "OUTPUT\n",
    "- object PEROXISOMES \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default parameters, including  \"optimal\" Z\n",
    "\n",
    "takes ~ 4 seconds to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_Z_from_params = False\n",
    "\n",
    "\n",
    "if load_Z_from_params:\n",
    "\n",
    "    default_params = load_parameters( test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "\n",
    "    ch_to_agg = default_params[\"ch_to_agg\"]\n",
    "    nuc_ch = default_params['nuc_ch']\n",
    "    optimal_Z = default_params[\"optimal_Z\"] #find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "else:\n",
    "    ch_to_agg = (1,2,3,4,5,6)\n",
    "    nuc_ch = 0\n",
    "    optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "\n",
    "    default_params = defaultdict(str, **{\n",
    "        #\"intensity_norm_param\" : [0.5, 15]\n",
    "        \"intensity_norm_param\" : [0],\n",
    "        \"gaussian_smoothing_sigma\" : 1.34,\n",
    "        \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "        \"dot_2d_sigma\" : 2,\n",
    "        \"dot_2d_sigma_extra\" : 1,\n",
    "        \"dot_2d_cutoff\" : 0.025,\n",
    "        \"min_area\" : 10,\n",
    "        \"low_level_min_size\" :  100,\n",
    "        \"median_filter_size\" : 4,\n",
    "        \"ch_to_agg\" : (1,2,3,4,5,6), # exclude residual\n",
    "        \"nuc_ch\" : 0,\n",
    "        \"optimal_Z\": optimal_Z,\n",
    "    })\n",
    "    save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "# make sure we have removed Z\n",
    "if len(scale)>2:\n",
    "    scale = scale[1:]\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred nuclei object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_nuclei = img_2D[0].copy()\n",
    "NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred soma object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_soma = (4. * img_2D[1].copy() + \n",
    "                               1. * img_2D[5].copy() + \n",
    "                               1. * img_2D[7].copy() )\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA(raw_soma.copy(), NU_label, default_params) \n",
    "CY_object =  infer_CYTOSOL(SO_object, NU_object) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    ">sec61beta  is  good start for ER  as per from [Allen Cell](https://www.allencell.org/cell-observations/category/endoplasmic-reticulum).    \n",
    "\n",
    "using [seg_sec61b.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aics-segmentation/aicssegmentation/structure_wrapper/seg_sec61b.py)\n",
    "[seg_sec61b_dual.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/structure_wrapper/seg_sec61b_dual.py)\n",
    "\n",
    "[playground_Sec61b.ipynb](https://github.com/AllenInstitute/aics-segmentation/blob/master/lookup_table_demo/playground_Sec61b.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "\n",
    "INPUT\n",
    "- ch 4\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- edge preserving scaling\n",
    "\n",
    "CORE-PROCESSING\n",
    "- vesselness slice-by-slice\n",
    "\n",
    "POST-PROCESSING\n",
    "  - S  - remove objects less than 2x2 pixels (area = 4)\n",
    "\n",
    "OUTPUT\n",
    "- object PEROXISOMES \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_er   = img_2D[5].copy()\n",
    "\n",
    "# mask object\n",
    "masked_er = apply_mask(raw_er, CY_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "intensity_norm_param = [0]  # CHECK THIS\n",
    "# Linear-ish smoothing\n",
    "struct_img = intensity_normalization( masked_er ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "# edge-preserving smoothing (Option 2, used for Sec61B)\n",
    "structure_img_smooth = edge_preserving_smoothing_3d(struct_img)\n",
    "# 10 seconds!!!!  tooooo slow... for maybe no good reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "\n",
    "bw = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "small_object_max = 4\n",
    "################################\n",
    "GO_object = size_filter_2D(bw, \n",
    "                                                min_size= small_object_max**2, \n",
    "                                                connectivity=1)\n",
    "# ################################\n",
    "# ## PARAMETERS for this step ## from seg_sec61b.py\n",
    "# min_area = 15\n",
    "# ################################\n",
    "# bw = remove_small_objects(bw > 0, min_size=min_area, connectivity=1, in_place=False)\n",
    "# # prune slice by slice\n",
    "# for zz in range(bw.shape[0]):\n",
    "#     bw[zz, :, :] = remove_small_objects(bw[zz, :, :], min_size=3, connectivity=1, in_place=False)\n",
    "\n",
    "# ER_object = remove_small_objects(bw > 0, min_size=min_area, connectivity=1, in_place=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "    bw,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    GO_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_ENDOPLASMIC_RETICULUM` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_ENDOPLASMIC_RETICULUM\n",
    "##########################\n",
    "def _infer_ENDOPLASMIC_RETICULUM(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer ER  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 2d image containing the ER signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 2d (3D with 1 Z) image containing the cytosol mask\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of ER\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "    struct_img = apply_mask(struct_img,CY_object)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    intensity_norm_param = [0]  # CHECK THIS\n",
    "\n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=intensity_norm_param)\n",
    "    out_p[\"intensity_norm_param\"] = intensity_norm_param\n",
    "\n",
    "    # edge-preserving smoothing (Option 2, used for Sec61B)\n",
    "    structure_img_smooth = edge_preserving_smoothing_3d(struct_img)\n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    f2_param = [[1, 0.15]]\n",
    "    ################################\n",
    "\n",
    "    struct_obj = filament_2d_wrapper(struct_img, f2_param)\n",
    "    out_p[\"f2_param\"] = f2_param \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    " \n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    small_object_max = 2 \n",
    "    ################################\n",
    "    # struct_obj = remove_small_objects(struct_obj>0, min_size=min_area, connectivity=1, in_place=False)\n",
    "    # out_p[\"min_area\"] = min_area \n",
    "\n",
    "    struct_obj = size_filter_2D(struct_obj, \n",
    "                                                    min_size= small_object_max**2, \n",
    "                                                    connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `_infer_ENDOPLASMIC_RETICULUM` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_er  = img_2D[5].copy()\n",
    "\n",
    "ER_object, out_p =  _infer_ENDOPLASMIC_RETICULUM(raw_er, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    ER_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_labels(\n",
    "    label(ER_object),\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles.er import infer_ENDOPLASMIC_RETICULUM\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "raw_er  = img_2D[5].copy()\n",
    "\n",
    "ER_object, out_p =  infer_ENDOPLASMIC_RETICULUM(raw_er, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated parameters for ongoing testing\n",
    "save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    " 🚧 WIP 🚧 (🚨🚨🚨🚨 )\n",
    "\n",
    "# WORKFLOW #2 (WIP)\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " \n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- ch 6\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "- rescale \n",
    "- median window:4\n",
    "- non-local noise reduction\n",
    "  - size:5, distance:1, cut-off:0.1\n",
    "- identify \"TUBES\"\n",
    "  - enhance neurites\n",
    "    - > Neurites: Neurites are taken to be long, thin features of enhanced intensity. Choose this option to enhance the intensity of the neurites using the Line structures or Tubeness methods described in a later setting.  \n",
    "    - method: tubeness\n",
    "    - > Tubeness: This method is an adaptation of the method used by the ImageJ Tubeness plugin. The image is smoothed with a Gaussian. The Hessian is then computed at every point to measure the intensity gradient and the eigenvalues of the Hessian are computed to determine the magnitude of the intensity. The absolute maximum of the two eigenvalues gives a measure of the ratio of the intensity of the gradient in the direction of its most rapid descent versus in the orthogonal direction. The output image is the absolute magnitude of the highest eigenvalue if that eigenvalue is negative (white neurite on dark background), otherwise, zero. \n",
    "    - smoothing: 2 pix\n",
    "\n",
    "CORE-PROCESSING\n",
    "- identify primary objects \"TUBES\"\n",
    "    - adaptive Sauvola\n",
    "      - threshold smoothing scale: 0\n",
    "      - threshold correction factor: .6\n",
    "      - threshold bounds: (0. ,1.0)\n",
    "      - adaptive window: 20 pixels\n",
    "- identify primary objects \"SHEETS\"\n",
    "  - ER masked w/ CY\n",
    "  - adaptive Otsu\n",
    "      - diameter: (2,50)\n",
    "    - two classes\n",
    "      - threshold smoothing scale: 0\n",
    "      - threshold correction factor: 1\n",
    "      - threshold bounds: (0.18, .25)\n",
    "      - adaptive window: 10 pixels\n",
    "- combine \"TUBES\" and \"SHEETS\"\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- object ER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[5,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0] # \n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = _enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = _enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n",
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST  `infer_ENDOPLASMIC_RETICULUM` function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
