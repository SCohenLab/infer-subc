{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking segmentation outputs from Organelle-Segmenter-Plugin\n",
    "\n",
    "### How to use:\n",
    "- advance through each block of code sequentially by pressing Shift+Enter\n",
    "- if a block of code has \"#### USER INPUT REQUIRED ###\" in it, fill in the blanks below that line before running it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "## INPUTS\n",
    "This section of code blocks loads all of the necessary python packages and functions you will need to run through this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from typing import Optional, Union, Dict, List\n",
    "import itertools \n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                        export_inferred_organelle,\n",
    "                                        import_inferred_organelle,\n",
    "                                        export_tiff,\n",
    "                                        list_image_files,\n",
    "                                        read_tiff_image)\n",
    "\n",
    "\n",
    "\n",
    "from infer_subc.constants import *\n",
    "from infer_subc.utils.stats import *\n",
    "from infer_subc.utils.stats_helpers import *\n",
    "from infer_subc.utils.stats import _assert_uint16_labels\n",
    "from infer_subc.core.img import label_uint16\n",
    "\n",
    "\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to edit this function for a specific case below, so editing locally\n",
    "def _import_inferred_organelle(name: str, meta_dict: Dict, out_data_path: Path) -> Union[np.ndarray, None]:\n",
    "    \"\"\"\n",
    "    read inferred organelle from ome.tif file\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    name: str\n",
    "        name of organelle.  i.e. nuc, lyso, etc.\n",
    "    meta_dict:\n",
    "        dictionary of meta-data (ome) from original file\n",
    "    out_data_path:\n",
    "        Path object of directory where tiffs are read from\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    exported file name\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # copy the original file name to meta\n",
    "    img_name = Path(meta_dict[\"file_name\"])  #\n",
    "    # add params to metadata\n",
    "\n",
    "    organelle_fname = f\"{img_name.stem}-{name}.tif\"\n",
    "\n",
    "    organelle_path = out_data_path / organelle_fname\n",
    "\n",
    "    if Path.exists(organelle_path):\n",
    "        # organelle_obj, _meta_dict = read_ome_image(organelle_path)\n",
    "        organelle_obj = read_tiff_image(organelle_path)  # .squeeze()\n",
    "        print(f\"loaded  inferred {len(organelle_obj.shape)}D `{name}`  from {out_data_path} \")\n",
    "        return organelle_obj\n",
    "    else:\n",
    "        print(f\"`{name}` object not found: {organelle_path}\")\n",
    "        raise FileNotFoundError(f\"`{name}` object not found: {organelle_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Opening a Napari window -\n",
    "> #### A new window should pop up when the line of code below is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 2172x1322-1152-1608 (frame: 2194x1378-1163-1653) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY2\". Resulting geometry: 2606x1587-1150-1601 (frame: 2628x1643-1161-1646) margins: 11, 45, 11, 11 minimum size: 385x498 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1052 maxtrack=0,0)\n",
      "15-Feb-24 13:18:40 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 2172x1322-1152-1608 (frame: 2194x1378-1163-1653) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY2\". Resulting geometry: 2606x1587-1150-1601 (frame: 2628x1643-1161-1646) margins: 11, 45, 11, 11 minimum size: 385x498 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1052 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________\n",
    "## Quality checking segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this list to determine the index of the image you would like to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "\n",
    "# Copy and paste the paths to the folders where your data is saved inside the quotation marks below. \n",
    "# If you have more than one segmentation data folder, include it in the segmentation_data_2 line. If not, type None wihtout quotation marks\n",
    "# NOTE: for windows, use \"/\" \n",
    "raw_data = \"D:/Experiments (C2-117 - current)/C2-121\"\n",
    "segmentation_data = \"D:/Experiments (C2-117 - current)/C2-121/20230921_C2-121_3D-analysis/20230921_C2-121_segmentation\"\n",
    "segmentation_data_2 = None\n",
    "location_tosave_edited_segmentations = \"  \"\n",
    "location_to_save_gooddata = \"  \"\n",
    "\n",
    "# Inside of the quotation marks, write the suffix associated to each segmentation file\n",
    "mask_suffix = \"masks_A\"\n",
    "lyso_suffix = \"lyso\"\n",
    "mito_suffix = \"mito\"\n",
    "golgi_suffix = \"golgi\"\n",
    "perox_suffix = \"perox\"\n",
    "ER_suffix = \"ER\"\n",
    "LD_suffix = \"LD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_21de3_row0_col0, #T_21de3_row1_col0, #T_21de3_row2_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_21de3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_21de3_level0_col0\" class=\"col_heading level0 col0\" >Image Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_21de3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_21de3_row0_col0\" class=\"data row0 col0\" >D:\\Experiments (C2-117 - current)\\C2-121\\C2-121_deconvolution\\needs analysis\\20230727_C2-121_unconditioned_well 10_cell 5_25nM TG_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21de3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_21de3_row1_col0\" class=\"data row1 col0\" >D:\\Experiments (C2-117 - current)\\C2-121\\C2-121_deconvolution\\needs analysis\\20230727_C2-121_unconditioned_well 11_cell 2_50uM NaAsO_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21de3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_21de3_row2_col0\" class=\"data row2 col0\" >D:\\Experiments (C2-117 - current)\\C2-121\\C2-121_deconvolution\\needs analysis\\20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2001da6b850>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root_path = Path(\"D:/Experiments (C2-117 - current)/C2-121\")\n",
    "\n",
    "raw_data_path = data_root_path / \"C2-121_deconvolution/needs analysis\"\n",
    "raw_file_list = list_image_files(raw_data_path,\".tiff\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame({\"Image Name\":raw_file_list}).style.set_properties(**{'text-align':'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT REQUIRED ###\n",
    "\n",
    "# Utilizing the list above as reference, change this index number (left column in table) to select a specific image\n",
    "num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_img_data, raw_meta_dict = read_czi_image(raw_file_list[num])\n",
    "name = raw_meta_dict['name']\n",
    "name[0].split(\" :: \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  inferred 4D `masks_A`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n",
      "loaded  inferred 3D `mito`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n",
      "loaded  inferred 3D `golgi`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n",
      "loaded  inferred 3D `perox`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n",
      "loaded  inferred 3D `ER`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n",
      "loaded  inferred 3D `LD`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20230921_C2-121_segmentation \n"
     ]
    }
   ],
   "source": [
    "seg_data_path = data_root_path / \"20230921_C2-121_3D-analysis/20230921_C2-121_segmentation\"\n",
    "\n",
    "mask_seg = import_inferred_organelle(\"masks_A\", raw_meta_dict, seg_data_path)\n",
    "# lyso_seg = import_inferred_organelle(\"lyso\", raw_meta_dict, seg_data_path)\n",
    "mito_seg = import_inferred_organelle(\"mito\", raw_meta_dict, seg_data_path)\n",
    "golgi_seg = import_inferred_organelle(\"golgi\", raw_meta_dict, seg_data_path)\n",
    "perox_seg = import_inferred_organelle(\"perox\", raw_meta_dict, seg_data_path)\n",
    "ER_seg = import_inferred_organelle(\"ER\", raw_meta_dict, seg_data_path)\n",
    "LD_seg = import_inferred_organelle(\"LD\", raw_meta_dict, seg_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  inferred 3D `lyso`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20240109_C2-121_segmentation \n"
     ]
    }
   ],
   "source": [
    "### NEED TO FIX THIS TO INCLUDE AN OPTION TO SELECT WHICH THINGS ARE TO BE SELECTED FROM SECOND FOLDER\n",
    "# if from a different seg path\n",
    "seg_data_path = data_root_path / \"20230921_C2-121_3D-analysis/20240109_C2-121_segmentation\"\n",
    "\n",
    "# nuc_seg = import_inferred_organelle(\"20230426_test_nuc\", raw_meta_dict, seg_data_path)\n",
    "# cell_seg = import_inferred_organelle(\"20230426_test_cell\", raw_meta_dict, seg_data_path)\n",
    "# cyto_seg = import_inferred_organelle(\"20230426_test_cyto\", raw_meta_dict, seg_data_path)\n",
    "# mask_seg = import_inferred_organelle(\"masks_A\", raw_meta_dict, seg_data_path)\n",
    "lyso_seg = import_inferred_organelle(\"lyso\", raw_meta_dict, seg_data_path)\n",
    "# mito_seg = import_inferred_organelle(\"mito\", raw_meta_dict, seg_data_path)\n",
    "# golgi_seg = import_inferred_organelle(\"golgi\", raw_meta_dict, seg_data_path)\n",
    "# perox_seg = import_inferred_organelle(\"perox\", raw_meta_dict, seg_data_path)\n",
    "# ER_seg = import_inferred_organelle(\"ER\", raw_meta_dict, seg_data_path)\n",
    "# LD_seg = import_inferred_organelle(\"LD\", raw_meta_dict, seg_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'mask_seg' at 0x202096771f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(raw_img_data[0], name='LD_raw', blending='additive')\n",
    "viewer.add_image(LD_seg, opacity=0.3, colormap='magenta', blending='additive')\n",
    "viewer.add_image(raw_img_data[1], name='ER_raw', blending='additive')\n",
    "viewer.add_image(ER_seg, opacity=0.3, colormap='red', blending='additive')\n",
    "viewer.add_image(raw_img_data[2], name='GL_raw', blending='additive')\n",
    "viewer.add_image(golgi_seg, opacity=0.3, colormap='yellow', blending='additive')\n",
    "viewer.add_image(raw_img_data[3], name='LS_raw', blending='additive')\n",
    "viewer.add_image(lyso_seg, opacity=0.3, colormap='cyan', blending='additive')\n",
    "viewer.add_image(raw_img_data[4], name='MT_raw', blending='additive')\n",
    "viewer.add_image(mito_seg, opacity=0.3, colormap='green', blending='additive')\n",
    "viewer.add_image(raw_img_data[5], name='PO_raw', blending='additive')\n",
    "viewer.add_image(perox_seg, opacity=0.3, colormap='bop orange', blending='additive')\n",
    "viewer.add_image(mask_seg, opacity=0.3, blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP: Review all of the segmentations in Napari window before continuing\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'raw_img_data' at 0x201be971000>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting 0: raw_img_data:masks_A\n",
      "btn_run_clicked - 0: {'rescale': True, 'weight_ch0': 1, 'weight_ch1': 4, 'weight_ch2': 1, 'weight_ch3': 1, 'weight_ch4': 0, 'weight_ch5': 2, 'weight_ch6': 0, 'weight_ch7': 0, 'weight_ch8': 0, 'weight_ch9': 0}\n",
      "selecting 1: Create composite image\n",
      "btn_run_clicked - 1: {'gauss_sigma': 0.0, 'median_size': 0}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 2: None\n",
      "selecting 3: Log transform + Scharr edge detection\n",
      "btn_run_clicked - 3: {'cutoff_size': 50, 'global_method': 'ave_tri_med', 'local_adjust': 0.05}\n",
      "btn_run_clicked - 3: {'cutoff_size': 50, 'global_method': 'ave_tri_med', 'local_adjust': 0.05}\n",
      "selecting 4: Global + local threshold (AICSSeg - MO)\n",
      "btn_run_clicked - 4: {'hole_max': 30, 'hole_min': 0, 'method': '3D', 'min_size': 10}\n",
      "selecting 4.1: Remove small holes and objects\n",
      "btn_run_clicked - 4: {'hole_max': 30, 'hole_min': 0, 'method': '3D', 'min_size': 10}\n",
      "selecting 5.1: Remove small holes and objects\n",
      "btn_run_clicked - 5: {'fill_filter_method': '3D', 'nuc_max_width': 400, 'nuc_min_width': 0, 'small_obj_width': 20}\n",
      "selecting 5.1: Remove small holes and objects\n",
      "selecting 6: Create nucleus mask from cytoplasm mask\n",
      "btn_run_clicked - 6: {'fill_filter_method': '3D', 'max_hole_width': 0, 'min_hole_width': 0, 'small_obj_width': 0}\n",
      "selecting 0: raw_img_data:ER\n",
      "btn_run_clicked - 0: {'chan': 1}\n",
      "selecting 1: Select a channel for segmentation\n",
      "btn_run_clicked - 1: {'gauss_sigma': 0.0, 'median_size': 0}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 2: {'cutoff_size': 1200, 'global_method': 'triangle', 'local_adjust': 0.5}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.001, 'filament_cutoff_2': 0.001, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.001, 'filament_cutoff_2': 0.001, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.005, 'filament_cutoff_2': 0.005, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.005, 'filament_cutoff_2': 0.005, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.05, 'filament_cutoff_2': 0.05, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.05, 'filament_cutoff_2': 0.07, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.5, 'filament_scale_2': 1.0, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 3: Global + local threshold (AICSSeg - MO)\n",
      "selecting 4.3: 'Filament' thresholding method (AICSSeg)\n",
      "btn_run_clicked - 4: None\n",
      "selecting 5: Combine segmentations (logical or)\n",
      "btn_run_clicked - 5: {'hole_max': 0, 'hole_min': 0, 'method': '3D', 'min_size': 1}\n",
      "selecting 6: Remove small holes and objects\n",
      "btn_run_clicked - 6: None\n",
      "selecting 0: raw_img_data:mito\n",
      "btn_run_clicked - 0: {'chan': 4}\n",
      "selecting 1: Select a channel for segmentation\n",
      "btn_run_clicked - 1: {'gauss_sigma': 0.0, 'median_size': 0}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 2: {'dot_cutoff_1': 0.08, 'dot_cutoff_2': 0.0, 'dot_cutoff_3': 0.0, 'dot_scale_1': 1.5, 'dot_scale_2': 0.0, 'dot_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 2: {'dot_cutoff_1': 0.05, 'dot_cutoff_2': 0.0, 'dot_cutoff_3': 0.0, 'dot_scale_1': 1.5, 'dot_scale_2': 0.0, 'dot_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 2: {'dot_cutoff_1': 0.06, 'dot_cutoff_2': 0.0, 'dot_cutoff_3': 0.0, 'dot_scale_1': 1.5, 'dot_scale_2': 0.0, 'dot_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.01, 'filament_cutoff_2': 0.01, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.0, 'filament_scale_2': 0.05, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.01, 'filament_cutoff_2': 0.01, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.0, 'filament_scale_2': 0.05, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 2: Rescale and smooth image\n",
      "btn_run_clicked - 3: {'filament_cutoff_1': 0.005, 'filament_cutoff_2': 0.005, 'filament_cutoff_3': 0.0, 'filament_scale_1': 1.0, 'filament_scale_2': 0.05, 'filament_scale_3': 0.0, 'method': '3D'}\n",
      "selecting 3.2: 'Dot' thresholding method (AICSSeg)\n",
      "selecting 4.1: 'Filament' thresholding method (AICSSeg)\n",
      "btn_run_clicked - 4: None\n",
      "selecting 5: Combine segmentations (logical or)\n",
      "btn_run_clicked - 5: {'hole_max': 0, 'hole_min': 0, 'method': '3D', 'min_size': 2}\n",
      "selecting 6: Remove small holes and objects\n",
      "btn_run_clicked - 6: None\n"
     ]
    }
   ],
   "source": [
    "# for editing cell mask\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(raw_img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "# Saving segmentations for analysis to a common folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for all images that didn't require editing, I am going to separate the nuclei and cell masks and save them to a new file location with the correct organelle segementation files.\n",
    "# # everything will be saved as a copy\n",
    "\n",
    "# # GOOD ORIGINALS\n",
    "nuc_seg = mask_seg[2]\n",
    "# cell_seg = mask_seg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  inferred 3D `cell`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20240102_C2-121_segmentation-edits \n",
      "loaded  inferred 3D `mito`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20240102_C2-121_segmentation-edits \n",
      "loaded  inferred 3D `ER`  from D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20240102_C2-121_segmentation-edits \n"
     ]
    }
   ],
   "source": [
    "# # identifying new masks for the images that required editing\n",
    "seg_data_path = data_root_path / \"20230921_C2-121_3D-analysis/20240102_C2-121_segmentation-edits\"\n",
    "\n",
    "# UPDATED\n",
    "# nuc_seg = _import_inferred_organelle(\"nuc\", raw_meta_dict, seg_data_path)\n",
    "cell_seg = _import_inferred_organelle(\"cell\", raw_meta_dict, seg_data_path)\n",
    "# perox_seg = _import_inferred_organelle(\"perox\", raw_meta_dict, seg_data_path)\n",
    "mito_seg = _import_inferred_organelle(\"mito\", raw_meta_dict, seg_data_path)\n",
    "ER_seg = _import_inferred_organelle(\"ER\", raw_meta_dict, seg_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-cell\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-nuc\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-LD\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-ER\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-golgi\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-lyso\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-mito\n",
      "saved file: 20230727_C2-121_unconditioned_well 9_cell 1_50uM NaAsO  washout_Linear unmixing_0_cmle.ome-perox\n"
     ]
    }
   ],
   "source": [
    "# copying all good segmentations to a new location\n",
    "path_for_quant = data_root_path / \"20230921_C2-121_3D-analysis/C2-121_good-segs\"\n",
    "\n",
    "out_file_n = export_inferred_organelle(cell_seg, \"cell\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(nuc_seg, \"nuc\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(LD_seg, \"LD\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(ER_seg, \"ER\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(golgi_seg, \"golgi\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(lyso_seg, \"lyso\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(mito_seg, \"mito\", raw_meta_dict, path_for_quant)\n",
    "out_file_n = export_inferred_organelle(perox_seg, \"perox\", raw_meta_dict, path_for_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________\n",
    "## Quantifying segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_segmentation_tiff_files(prototype:Union[Path,str],\n",
    "                                  name_list:List[str], \n",
    "                                  seg_path:Union[Path,str],\n",
    "                                  suffix:Union[str, None]=None) -> Dict:\n",
    "    \"\"\"\n",
    "    Find the matching segmentation files to the raw image file based on the raw image file path.\n",
    "\n",
    "    Paramters:\n",
    "    ---------\n",
    "    prototype:Union[Path,str]\n",
    "        the file path (as a string) for one raw image file; this file should have matching segmentation \n",
    "        output files with the same file name root and different file name ending that match the strings \n",
    "        provided in name_list\n",
    "    name_list:List[str]\n",
    "        a list of file name endings related to what segmentation is that file\n",
    "    seg_path:Union[Path,str]\n",
    "        the path (as a string) to the matching segmentation files.\n",
    "    suffix:Union[str, None]=None\n",
    "        any additional text that exists between the file root and the name_list ending\n",
    "        Ex) Prototype = \"C:/Users/Shannon/Documents/Python_Scripts/Infer-subc/raw/a48hrs-Ctrl_9_Unmixing.czi\"\n",
    "            Name of organelle file = a48hrs-Ctrl_9_Unmixing-20230426_test_cell.tiff\n",
    "            result of .stem = \"a48hrs-Ctrl_9_Unmixing\"\n",
    "            organelle/cell area type = \"cell\"\n",
    "            suffix = \"-20230426_test_\"\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    a dictionary of file paths for each image type (raw and all the different segmentations)\n",
    "\n",
    "    \"\"\"\n",
    "    # raw\n",
    "    prototype = Path(prototype)\n",
    "    if not prototype.exists():\n",
    "        print(f\"bad prototype. please choose an existing `raw` file as prototype\")\n",
    "        return dict()\n",
    "\n",
    "    out_files = {\"raw\":prototype}\n",
    "    seg_path = Path(seg_path) \n",
    "\n",
    "    # raw\n",
    "    if not seg_path.is_dir():\n",
    "        print(f\"bad path argument. please choose an existing path containing organelle segmentations\")\n",
    "        return out_files\n",
    "\n",
    "    # segmentations\n",
    "    for org_n in name_list:\n",
    "        org_name = Path(seg_path) / f\"{prototype.stem}{suffix}{org_n}.tiff\"\n",
    "        if org_name.exists(): \n",
    "            out_files[org_n] = org_name\n",
    "        elif org_name.exists() == False: \n",
    "            org_name = Path(seg_path) / f\"{prototype.stem}{suffix}{org_n}.tif\"\n",
    "            out_files[org_n] = org_name\n",
    "        else: \n",
    "            print(f\"{org_n} .tiff file not found in {seg_path} returning\")\n",
    "            out_files[org_n] = None\n",
    "    \n",
    "    return out_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convex hull errors\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "def _batch_process_quantification(out_file_name: str,\n",
    "                                  seg_path: Union[Path,str],\n",
    "                                  out_path: Union[Path, str], \n",
    "                                  raw_path: Union[Path,str], \n",
    "                                  raw_file_type: str,\n",
    "                                  organelle_names: List[str],\n",
    "                                  organelle_channels: List[int],\n",
    "                                  region_names: List[str],\n",
    "                                  masks_file_name: [str],\n",
    "                                  mask: str,\n",
    "                                  dist_centering_obj:str, \n",
    "                                  dist_num_bins: int,\n",
    "                                  dist_center_on: bool=False,\n",
    "                                  dist_keep_center_as_bin: bool=True,\n",
    "                                  dist_zernike_degrees: Union[int, None]=None,\n",
    "                                  include_contact_dist: bool = True,\n",
    "                                  scale:bool=True,\n",
    "                                  seg_suffix:Union[str, None]=None) -> int :\n",
    "    \"\"\"  \n",
    "    batch process segmentation quantification (morphology, distribution, contacts); this function is currently optimized to process images from one file folder per image type (e.g., raw, segmentation)\n",
    "    the output csv files are saved to the indicated out_path folder\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    out_file_name: str\n",
    "        the prefix to use when naming the output datatables\n",
    "    seg_path: Union[Path,str]\n",
    "        Path or str to the folder that contains the segmentation tiff files\n",
    "    out_path: Union[Path, str]\n",
    "        Path or str to the folder that the output datatables will be saved to\n",
    "    raw_path: Union[Path,str]\n",
    "        Path or str to the folder that contains the raw image files\n",
    "    raw_file_type: str\n",
    "        the file type of the raw data; ex - \".tiff\", \".czi\"\n",
    "    organelle_names: List[str]\n",
    "        a list of all organelle names that will be analyzed; the names should be the same as the suffix used to name each of the tiff segmentation files\n",
    "        Note: the intensity measurements collect per region (from get_region_morphology_3D function) will only be from channels associated to these organelles \n",
    "    organelle_channels: List[int]\n",
    "        a list of channel indices associated to respective organelle staining in the raw image; the indices should listed in same order in which the respective segmentation name is listed in organelle_names\n",
    "    region_names: List[str]\n",
    "        a list of regions, or masks, to measure; the order should correlate to the order of the channels in the \"masks\" output segmentation file\n",
    "    masks_file_name: str\n",
    "        the suffix of the \"masks\" segmentation file; ex- \"masks_B\", \"masks\", etc.\n",
    "        this function currently does not accept indivial region segmentations \n",
    "    mask: str\n",
    "        the name of the region to use as the mask when measuring the organelles; this should be one of the names listed in regions list; usually this will be the \"cell\" mask\n",
    "    dist_centering_obj:str\n",
    "        the name of the region or object to use as the centering object in the get_XY_distribution function\n",
    "    dist_num_bins: int\n",
    "        the number of bins for the get_XY_distribution function\n",
    "    dist_center_on: bool=False,\n",
    "        for get_XY_distribution:\n",
    "        True = distribute the bins from the center of the centering object\n",
    "        False = distribute the bins from the edge of the centering object\n",
    "    dist_keep_center_as_bin: bool=True\n",
    "        for get_XY_distribution:\n",
    "        True = include the centering object area when creating the bins\n",
    "        False = do not include the centering object area when creating the bins\n",
    "    dist_zernike_degrees: Union[int, None]=None\n",
    "        for get_XY_distribution:\n",
    "        the number of zernike degrees to include for the zernike shape descriptors; if None, the zernike measurements will not \n",
    "        be included in the output\n",
    "    include_contact_dist:bool=True\n",
    "        whether to include the distribution of contact sites in get_contact_metrics_3d(); True = include contact distribution\n",
    "    scale:bool=True\n",
    "        a tuple that contains the real world dimensions for each dimension in the image (Z, Y, X)\n",
    "    seg_suffix:Union[str, None]=None\n",
    "        any additional text that is included in the segmentation tiff files between the file stem and the segmentation suffix\n",
    "        TODO: this can't be None!!! need to update!!!\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    count: int\n",
    "        the number of images processed\n",
    "        \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "\n",
    "    if isinstance(raw_path, str): raw_path = Path(raw_path)\n",
    "    if isinstance(seg_path, str): seg_path = Path(seg_path)\n",
    "    if isinstance(out_path, str): out_path = Path(out_path)\n",
    "    \n",
    "    if not Path.exists(out_path):\n",
    "        Path.mkdir(out_path)\n",
    "        print(f\"making {out_path}\")\n",
    "    \n",
    "    # reading list of files from the raw path\n",
    "    img_file_list = list_image_files(raw_path, raw_file_type)\n",
    "\n",
    "    # list of segmentation files to collect\n",
    "    segs_to_collect = organelle_names + masks_file_name\n",
    "\n",
    "    # containers to collect data tabels\n",
    "    org_tabs = []\n",
    "    contact_tabs = []\n",
    "    dist_tabs = []\n",
    "    region_tabs = []\n",
    "    for img_f in img_file_list:\n",
    "        count = count + 1\n",
    "        filez = _find_segmentation_tiff_files(img_f, segs_to_collect, seg_path, seg_suffix)\n",
    "\n",
    "        # read in raw file and metadata\n",
    "        img_data, meta_dict = read_czi_image(filez[\"raw\"])\n",
    "\n",
    "        # create intensities from raw file as list based on the channel order provided\n",
    "        intensities = [img_data[ch] for ch in organelle_channels]\n",
    "\n",
    "        # define the scale\n",
    "        if scale is True:\n",
    "            scale_tup = meta_dict['scale']\n",
    "        else:\n",
    "            scale_tup = None\n",
    "\n",
    "        # load regions as a list based on order in list (should match order in \"masks\" file)\n",
    "        # masks = read_tiff_image(filez[masks_file_name]) \n",
    "        # regions = [masks[r] for r, region in enumerate(region_names)]\n",
    "        regions= [read_tiff_image(filez[masks_file_name[0]]), read_tiff_image(filez[masks_file_name[1]])]\n",
    "\n",
    "        # store organelle images as list\n",
    "        organelles = [read_tiff_image(filez[org]) for org in organelle_names]\n",
    "\n",
    "        org_metrics, contact_metrics, dist_metrics, region_metrics = make_all_metrics_tables(source_file=img_f,\n",
    "                                                                                             list_obj_names=organelle_names,\n",
    "                                                                                             list_obj_segs=organelles,\n",
    "                                                                                             list_intensity_img=intensities, \n",
    "                                                                                             list_region_names=region_names,\n",
    "                                                                                             list_region_segs=regions, \n",
    "                                                                                             mask=mask,\n",
    "                                                                                             dist_centering_obj=dist_centering_obj,\n",
    "                                                                                             dist_num_bins=dist_num_bins,\n",
    "                                                                                             dist_center_on=dist_center_on,\n",
    "                                                                                             dist_keep_center_as_bin=dist_keep_center_as_bin,\n",
    "                                                                                             dist_zernike_degrees=dist_zernike_degrees,\n",
    "                                                                                             scale=scale_tup,\n",
    "                                                                                             include_contact_dist=include_contact_dist)\n",
    "\n",
    "        org_tabs.append(org_metrics)\n",
    "        contact_tabs.append(contact_metrics)\n",
    "        dist_tabs.append(dist_metrics)\n",
    "        region_tabs.append(region_metrics)\n",
    "        end2 = time.time()\n",
    "        print(f\"Completed processing for {count} images in {(end2-start)/60} mins.\")\n",
    "\n",
    "    final_org = pd.concat(org_tabs, ignore_index=True)\n",
    "    final_contact = pd.concat(contact_tabs, ignore_index=True)\n",
    "    final_dist = pd.concat(dist_tabs, ignore_index=True)\n",
    "    final_region = pd.concat(region_tabs, ignore_index=True)\n",
    "\n",
    "    org_csv_path = out_path / f\"{out_file_name}organelles.csv\"\n",
    "    final_org.to_csv(org_csv_path)\n",
    "\n",
    "    contact_csv_path = out_path / f\"{out_file_name}contacts.csv\"\n",
    "    final_contact.to_csv(contact_csv_path)\n",
    "\n",
    "    dist_csv_path = out_path / f\"{out_file_name}distributions.csv\"\n",
    "    final_dist.to_csv(dist_csv_path)\n",
    "\n",
    "    region_csv_path = out_path / f\"{out_file_name}regions.csv\"\n",
    "    final_region.to_csv(region_csv_path)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Quantification for {count} files is COMPLETE! Files saved to '{out_path}'.\")\n",
    "    print(f\"It took {(end - start)/60} minutes to quantify these files.\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 12.85111653804779 minutes to quantify one image.\n",
      "Completed processing for 1 images in 13.633693202336628 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.029443720976511 minutes to quantify one image.\n",
      "Completed processing for 2 images in 25.351052129268645 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.769019142786663 minutes to quantify one image.\n",
      "Completed processing for 3 images in 40.07484122117361 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 10.123363280296326 minutes to quantify one image.\n",
      "Completed processing for 4 images in 51.05860336224238 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 10.687337398529053 minutes to quantify one image.\n",
      "Completed processing for 5 images in 62.5649227142334 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 18.65947043498357 minutes to quantify one image.\n",
      "Completed processing for 6 images in 82.23818347851436 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 10.90061636765798 minutes to quantify one image.\n",
      "Completed processing for 7 images in 94.12582974831263 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 14.191140687465667 minutes to quantify one image.\n",
      "Completed processing for 8 images in 109.36302841504416 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 10.786302944024404 minutes to quantify one image.\n",
      "Completed processing for 9 images in 120.98962778647741 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 12.241323840618133 minutes to quantify one image.\n",
      "Completed processing for 10 images in 134.06715418497723 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 10.593359808127085 minutes to quantify one image.\n",
      "Completed processing for 11 images in 145.54131996234258 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.848494136333466 minutes to quantify one image.\n",
      "Completed processing for 12 images in 158.17075064182282 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.172446624437969 minutes to quantify one image.\n",
      "Completed processing for 13 images in 170.20890146096548 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 17.169872772693633 minutes to quantify one image.\n",
      "Completed processing for 14 images in 188.37914669911066 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.594340606530507 minutes to quantify one image.\n",
      "Completed processing for 15 images in 202.88150216341018 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 19.230043383439384 minutes to quantify one image.\n",
      "Completed processing for 16 images in 223.08613642056784 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 19.02303326924642 minutes to quantify one image.\n",
      "Completed processing for 17 images in 243.28065021832785 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 21.186208359400432 minutes to quantify one image.\n",
      "Completed processing for 18 images in 265.3551258007685 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 14.032004626592 minutes to quantify one image.\n",
      "Completed processing for 19 images in 280.4096624652545 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 8.572596224149068 minutes to quantify one image.\n",
      "Completed processing for 20 images in 289.83561989466347 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 14.307064696153004 minutes to quantify one image.\n",
      "Completed processing for 21 images in 305.2384168108304 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 19.773787347475686 minutes to quantify one image.\n",
      "Completed processing for 22 images in 326.06257402102153 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 18.509592469533285 minutes to quantify one image.\n",
      "Completed processing for 23 images in 345.67844277620316 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 14.443653750419617 minutes to quantify one image.\n",
      "Completed processing for 24 images in 361.0092085440954 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.84193088610967 minutes to quantify one image.\n",
      "Completed processing for 25 images in 375.78825400273007 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.065636424223582 minutes to quantify one image.\n",
      "Completed processing for 26 images in 389.8779928525289 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.20872967640559 minutes to quantify one image.\n",
      "Completed processing for 27 images in 401.90909975767136 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 25.15701001485189 minutes to quantify one image.\n",
      "Completed processing for 28 images in 427.98285402059554 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.441836945215861 minutes to quantify one image.\n",
      "Completed processing for 29 images in 442.31130364735924 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.532536971569062 minutes to quantify one image.\n",
      "Completed processing for 30 images in 454.69742594162625 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 15.621255604426066 minutes to quantify one image.\n",
      "Completed processing for 31 images in 471.3294980287552 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.797216141223908 minutes to quantify one image.\n",
      "Completed processing for 32 images in 483.94362528324126 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 16.138768963019054 minutes to quantify one image.\n",
      "Completed processing for 33 images in 500.8158786376317 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.98778957525889 minutes to quantify one image.\n",
      "Completed processing for 34 images in 513.6234324534734 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 16.107837982972462 minutes to quantify one image.\n",
      "Completed processing for 35 images in 530.8198182900746 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 12.269408357143401 minutes to quantify one image.\n",
      "Completed processing for 36 images in 544.0644442081451 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.217210710048676 minutes to quantify one image.\n",
      "Completed processing for 37 images in 555.977413880825 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 14.407258625825246 minutes to quantify one image.\n",
      "Completed processing for 38 images in 571.3044382015864 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 9.226699189345043 minutes to quantify one image.\n",
      "Completed processing for 39 images in 581.2938677191735 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 16.201046725114185 minutes to quantify one image.\n",
      "Completed processing for 40 images in 598.5561292211215 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.320047489802043 minutes to quantify one image.\n",
      "Completed processing for 41 images in 612.9693816542625 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.43185642560323 minutes to quantify one image.\n",
      "Completed processing for 42 images in 625.339998948574 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 8.499480732282002 minutes to quantify one image.\n",
      "Completed processing for 43 images in 634.6366313060124 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 9.673209861914318 minutes to quantify one image.\n",
      "Completed processing for 44 images in 645.0758331775666 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 11.49382688999176 minutes to quantify one image.\n",
      "Completed processing for 45 images in 657.8262346545855 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.543826846281688 minutes to quantify one image.\n",
      "Completed processing for 46 images in 672.4430633425712 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 13.424273796876271 minutes to quantify one image.\n",
      "Completed processing for 47 images in 686.7701002438863 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 16.401899154980978 minutes to quantify one image.\n",
      "Completed processing for 48 images in 704.181669151783 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 9.892387608687082 minutes to quantify one image.\n",
      "Completed processing for 49 images in 715.0072945356369 mins.\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "WTF!!  how did we have missing labels?\n",
      "It took 9.600856769084931 minutes to quantify one image.\n",
      "Completed processing for 50 images in 725.4921672900517 mins.\n",
      "Quantification for 50 files is COMPLETE! Files saved to 'D:\\Experiments (C2-117 - current)\\C2-121\\20230921_C2-121_3D-analysis\\20240221_C2-121_quantification_10per'.\n",
      "It took 725.9212815960249 minutes to quantify these files.\n"
     ]
    }
   ],
   "source": [
    "seg=_batch_process_quantification(out_file_name= \"20240118_C2-121_quant\",\n",
    "                                  seg_path=\"D:/Experiments (C2-117 - current)/C2-121/20230921_C2-121_3D-analysis/C2-121_good-segs\",\n",
    "                                  out_path=\"D:/Experiments (C2-117 - current)/C2-121/20230921_C2-121_3D-analysis/20240221_C2-121_quantification_10per\", \n",
    "                                  raw_path=\"D:/Experiments (C2-117 - current)/C2-121/C2-121_deconvolution\",\n",
    "                                  raw_file_type = \".tiff\",\n",
    "                                  organelle_names = ['LD', 'ER', 'golgi', 'lyso', 'mito', 'perox'],\n",
    "                                  organelle_channels= [0,1,2,3,4,5],\n",
    "                                  region_names= ['nuc', 'cell'],\n",
    "                                  masks_file_name= ['nuc', 'cell'],\n",
    "                                  mask= 'cell',\n",
    "                                  dist_centering_obj='nuc', \n",
    "                                  dist_num_bins=5,\n",
    "                                  dist_center_on=False,\n",
    "                                  dist_keep_center_as_bin=True,\n",
    "                                  dist_zernike_degrees=None,\n",
    "                                  include_contact_dist= True,\n",
    "                                  scale=True,\n",
    "                                  seg_suffix=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
