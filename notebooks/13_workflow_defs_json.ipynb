{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export workflow definitions\n",
    "\n",
    "We need to compose workflows and place the function prototypes into their proper place."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer_subc_2d.constants\n",
    "\n",
    "from typing import Dict, List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## WORKFLOW COMPOSITION HELPRES\n",
    "\n",
    "- function to take parameters and make a workflow\n",
    "- function to chain workflows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict\n",
    "\n",
    "def compose_workflow(prototype: Dict, parameters: Dict):\n",
    "    \"\"\"\n",
    "    map  parameters onto a workflow (i.e. replace params) \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def merge_workflow(workflows: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    map  parameters onto a workflow (i.e. replace params) \n",
    "    \"\"\"\n",
    "    wf1,wf_rest, = workflows[0], workflows[1:]\n",
    "    indices = [int(w) for w in wf1.keys()]\n",
    "    last_ = indices[-1]\n",
    "    new_wf = wf1.copy()  # do i need copy?\n",
    "\n",
    "    # assume 0 is the same for all workflows\n",
    "    def incriment_parent(parent: Union[int,List[int]], inc:int) -> Union[int,List[int]]:\n",
    "        if isinstance(parent, list):\n",
    "            new_parent = [p+inc-1 for p in parent]\n",
    "        else:\n",
    "            new_parent = parent-1+inc\n",
    "        print(f\"from {parent} to {new_parent}\")\n",
    "        return new_parent\n",
    "\n",
    "    for wf2 in wf_rest: \n",
    "        for step, add_step in enumerate(wf2.keys()):\n",
    "            add_entry = wf2[add_step]\n",
    "            if step > 0:\n",
    "                add_entry['parent']=incriment_parent(add_entry['parent'],last_)\n",
    "            \n",
    "            new_index = str(last_+step)\n",
    "            new_wf[new_index]=add_entry\n",
    "            print(add_entry)\n",
    "    return new_wf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'extraction', 'function': 'select_channel_from_raw', 'parameter_values': {'chan': 1}, 'parent': 0, 'annotation': 'basic lyso segmentation: 1'}\n",
      "from 1 to 9\n",
      "{'category': 'preprocessing', 'function': 'scale_and_smooth', 'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4}, 'parent': 9, 'annotation': 'basic lyso segmentation: 2'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'spot_filter_3', 'parameter_values': {'dot_scale_1': 5, 'dot_cut_1': 0.09, 'dot_scale_2': 2.5, 'dot_cut_2': 0.07, 'dot_scale_3': 1, 'dot_cut_3': 0.01}, 'parent': 10, 'annotation': 'basic lyso - spot filter: 3'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'filament_filter', 'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.15}, 'parent': 10, 'annotation': 'basic lyso - filament filter: 4'}\n",
      "from [3, 4] to [11, 12]\n",
      "{'category': 'core', 'function': 'logical_or', 'parent': [11, 12], 'annotation': 'basic lyso - combine spot+filament: 5'}\n",
      "from 5 to 13\n",
      "{'category': 'postprocessing', 'function': 'fill_and_filter_linear_size', 'parameter_values': {'hole_min': 0, 'hole_max': 25, 'min_size': 15, 'method': 'slice_by_slice'}, 'parent': 13, 'annotation': 'basic lyso - fill/filter: 6'}\n",
      "{'category': 'extraction', 'function': 'select_channel_from_raw', 'parameter_values': {'chan': 3}, 'parent': 0, 'annotation': 'basic golgi segmentation: 1'}\n",
      "from 1 to 9\n",
      "{'category': 'preprocessing', 'function': 'scale_and_smooth', 'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4}, 'parent': 9, 'annotation': 'basic golgi segmentation: 2'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'masked_object_thresh', 'parameter_values': {'th_method': 'triangle', 'cutoff_size': 1200, 'th_adjust': 0.5}, 'parent': 10, 'annotation': 'basic golgi - mo: 3'}\n",
      "from 3 to 11\n",
      "{'category': 'core', 'function': 'topology_preserving_thinning', 'parameter_values': {'min_thickness': 1.6, 'thin': 1}, 'parent': 11, 'annotation': 'basic golgi - thinning filter: 4'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'spot_filter_3', 'parameter_values': {'dot_scale_1': 1.6, 'dot_cut_1': 0.02, 'dot_scale_2': 0, 'dot_cut_2': 0.1, 'dot_scale_3': 0, 'dot_cut_3': 0.1}, 'parent': 10, 'annotation': 'basic golgi - spot filter: 5'}\n",
      "from [5, 4] to [13, 12]\n",
      "{'category': 'core', 'function': 'logical_or', 'parent': [13, 12], 'annotation': 'basic golgi - combine spot+thinned: 6'}\n",
      "from 6 to 14\n",
      "{'category': 'postprocessing', 'function': 'fill_and_filter_linear_size', 'parameter_values': {'hole_min': 0, 'hole_max': 25, 'min_size': 15, 'method': 'slice_by_slice'}, 'parent': 14, 'annotation': 'basic mito - fill/filter: 7'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'category': 'extraction',\n",
       "  'function': 'infer_nuclei_fromlabel',\n",
       "  'parameter_values': {'nuc_ch': 0,\n",
       "   'median_sz': 3,\n",
       "   'gauss_sig': 5.0,\n",
       "   'thresh_factor': 0.8,\n",
       "   'thresh_min': 0.1,\n",
       "   'thresh_max': 1.0,\n",
       "   'max_hole_w': 35,\n",
       "   'small_obj_w': 15},\n",
       "  'parent': 0,\n",
       "  'annotation': 'get  nuclei segmentation: 1'},\n",
       " '2': {'category': 'extraction',\n",
       "  'function': 'raw_cellmask_fromaggr',\n",
       "  'parameter_values': {'scale_min_max': True},\n",
       "  'parent': 0,\n",
       "  'annotation': ' this creates an aggregate signal for the cellmask'},\n",
       " '3': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 3.4},\n",
       "  'parent': 2,\n",
       "  'annotation': 'cellmask segmentation: 3'},\n",
       " '4': {'category': 'preprocessing',\n",
       "  'function': 'non_linear_cellmask_transform_MCZ',\n",
       "  'parent': 3,\n",
       "  'annotation': 'cellmask segmentation: 4'},\n",
       " '5': {'category': 'core',\n",
       "  'function': 'masked_object_thresh',\n",
       "  'parameter_values': {'th_method': 'ave_tri_med',\n",
       "   'cutoff_size': 100,\n",
       "   'th_adjust': 0.8},\n",
       "  'parent': 4,\n",
       "  'annotation': 'cellmask segmentation: 5'},\n",
       " '6': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 45,\n",
       "   'min_size': 25,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 5,\n",
       "  'annotation': 'cellmask segmentation: 6'},\n",
       " '7': {'category': 'postpostprocessing',\n",
       "  'function': 'choose_max_label_cellmask_union_nucleus',\n",
       "  'parent': [3, 6, 1],\n",
       "  'annotation': 'cellmask segmentation: 7'},\n",
       " '8': {'category': 'postpostprocessing',\n",
       "  'function': 'infer_cytoplasm',\n",
       "  'parameter_values': {'erode_nuclei': True},\n",
       "  'parent': [1, 7],\n",
       "  'annotation': 'infer cytoplasm: 8'},\n",
       " '9': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 3},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic golgi segmentation: 1'},\n",
       " '10': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "  'parent': 9,\n",
       "  'annotation': 'basic golgi segmentation: 2'},\n",
       " '11': {'category': 'core',\n",
       "  'function': 'masked_object_thresh',\n",
       "  'parameter_values': {'th_method': 'triangle',\n",
       "   'cutoff_size': 1200,\n",
       "   'th_adjust': 0.5},\n",
       "  'parent': 10,\n",
       "  'annotation': 'basic golgi - mo: 3'},\n",
       " '12': {'category': 'core',\n",
       "  'function': 'topology_preserving_thinning',\n",
       "  'parameter_values': {'min_thickness': 1.6, 'thin': 1},\n",
       "  'parent': 11,\n",
       "  'annotation': 'basic golgi - thinning filter: 4'},\n",
       " '13': {'category': 'core',\n",
       "  'function': 'spot_filter_3',\n",
       "  'parameter_values': {'dot_scale_1': 1.6,\n",
       "   'dot_cut_1': 0.02,\n",
       "   'dot_scale_2': 0,\n",
       "   'dot_cut_2': 0.1,\n",
       "   'dot_scale_3': 0,\n",
       "   'dot_cut_3': 0.1},\n",
       "  'parent': 10,\n",
       "  'annotation': 'basic golgi - spot filter: 5'},\n",
       " '14': {'category': 'core',\n",
       "  'function': 'logical_or',\n",
       "  'parent': [13, 12],\n",
       "  'annotation': 'basic golgi - combine spot+thinned: 6'},\n",
       " '15': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 25,\n",
       "   'min_size': 15,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 14,\n",
       "  'annotation': 'basic mito - fill/filter: 7'}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf1 = make_infer_masks_fromaggr_MCZ()\n",
    "wf2 = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "wf3 = make_infer_golgi_step_by_step_from_raw_dict()\n",
    "agg_wf = merge_workflow([wf1, wf2,wf3])\n",
    "\n",
    "agg_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf1 = make_infer_masks_fromaggr_MCZ()\n",
    "wf2 = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "\n",
    "# get a list of keys just in case things get un-ordered  \n",
    "# should we use ordered dictionaries?  named tuples?\n",
    "\n",
    "indices = [int(w) for w in wf1.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'extraction', 'function': 'select_channel_from_raw', 'parameter_values': {'chan': 1}, 'parent': 0, 'annotation': 'basic lyso segmentation: 1'}\n",
      "from 1 to 9\n",
      "{'category': 'preprocessing', 'function': 'scale_and_smooth', 'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4}, 'parent': 9, 'annotation': 'basic lyso segmentation: 2'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'spot_filter_3', 'parameter_values': {'dot_scale_1': 5, 'dot_cut_1': 0.09, 'dot_scale_2': 2.5, 'dot_cut_2': 0.07, 'dot_scale_3': 1, 'dot_cut_3': 0.01}, 'parent': 10, 'annotation': 'basic lyso - spot filter: 3'}\n",
      "from 2 to 10\n",
      "{'category': 'core', 'function': 'filament_filter', 'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.15}, 'parent': 10, 'annotation': 'basic lyso - filament filter: 4'}\n",
      "from [3, 4] to [11, 12]\n",
      "{'category': 'core', 'function': 'logical_or', 'parent': [11, 12], 'annotation': 'basic lyso - combine spot+filament: 5'}\n",
      "from 5 to 13\n",
      "{'category': 'postprocessing', 'function': 'fill_and_filter_linear_size', 'parameter_values': {'hole_min': 0, 'hole_max': 25, 'min_size': 15, 'method': 'slice_by_slice'}, 'parent': 13, 'annotation': 'basic lyso - fill/filter: 6'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'category': 'extraction',\n",
       "  'function': 'infer_nuclei_fromlabel',\n",
       "  'parameter_values': {'nuc_ch': 0,\n",
       "   'median_sz': 3,\n",
       "   'gauss_sig': 5.0,\n",
       "   'thresh_factor': 0.8,\n",
       "   'thresh_min': 0.1,\n",
       "   'thresh_max': 1.0,\n",
       "   'max_hole_w': 35,\n",
       "   'small_obj_w': 15},\n",
       "  'parent': 0,\n",
       "  'annotation': 'get  nuclei segmentation: 1'},\n",
       " '2': {'category': 'extraction',\n",
       "  'function': 'raw_cellmask_fromaggr',\n",
       "  'parameter_values': {'scale_min_max': True},\n",
       "  'parent': 0,\n",
       "  'annotation': ' this creates an aggregate signal for the cellmask'},\n",
       " '3': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 3.4},\n",
       "  'parent': 2,\n",
       "  'annotation': 'cellmask segmentation: 3'},\n",
       " '4': {'category': 'preprocessing',\n",
       "  'function': 'non_linear_cellmask_transform_MCZ',\n",
       "  'parent': 3,\n",
       "  'annotation': 'cellmask segmentation: 4'},\n",
       " '5': {'category': 'core',\n",
       "  'function': 'masked_object_thresh',\n",
       "  'parameter_values': {'th_method': 'ave_tri_med',\n",
       "   'cutoff_size': 100,\n",
       "   'th_adjust': 0.8},\n",
       "  'parent': 4,\n",
       "  'annotation': 'cellmask segmentation: 5'},\n",
       " '6': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 45,\n",
       "   'min_size': 25,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 5,\n",
       "  'annotation': 'cellmask segmentation: 6'},\n",
       " '7': {'category': 'postpostprocessing',\n",
       "  'function': 'choose_max_label_cellmask_union_nucleus',\n",
       "  'parent': [3, 6, 1],\n",
       "  'annotation': 'cellmask segmentation: 7'},\n",
       " '8': {'category': 'postpostprocessing',\n",
       "  'function': 'infer_cytoplasm',\n",
       "  'parameter_values': {'erode_nuclei': True},\n",
       "  'parent': [1, 7],\n",
       "  'annotation': 'infer cytoplasm: 8'},\n",
       " '9': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 1},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic lyso segmentation: 1'},\n",
       " '10': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "  'parent': 9,\n",
       "  'annotation': 'basic lyso segmentation: 2'},\n",
       " '11': {'category': 'core',\n",
       "  'function': 'spot_filter_3',\n",
       "  'parameter_values': {'dot_scale_1': 5,\n",
       "   'dot_cut_1': 0.09,\n",
       "   'dot_scale_2': 2.5,\n",
       "   'dot_cut_2': 0.07,\n",
       "   'dot_scale_3': 1,\n",
       "   'dot_cut_3': 0.01},\n",
       "  'parent': 10,\n",
       "  'annotation': 'basic lyso - spot filter: 3'},\n",
       " '12': {'category': 'core',\n",
       "  'function': 'filament_filter',\n",
       "  'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.15},\n",
       "  'parent': 10,\n",
       "  'annotation': 'basic lyso - filament filter: 4'},\n",
       " '13': {'category': 'core',\n",
       "  'function': 'logical_or',\n",
       "  'parent': [11, 12],\n",
       "  'annotation': 'basic lyso - combine spot+filament: 5'},\n",
       " '14': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 25,\n",
       "   'min_size': 15,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 13,\n",
       "  'annotation': 'basic lyso - fill/filter: 6'}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_ = indices[-1]\n",
    "new_wf = wf1.copy()  # do i need copy?\n",
    "\n",
    "def incriment_parent(parent: Union[int,List[int]], inc:int) -> Union[int,List[int]]:\n",
    "    if isinstance(parent, list):\n",
    "        new_parent = [p+inc-1 for p in parent]\n",
    "    else:\n",
    "        new_parent = parent-1+inc\n",
    "    print(f\"from {parent} to {new_parent}\")\n",
    "    return new_parent\n",
    "\n",
    "\n",
    "for step, add_step in enumerate(wf2.keys()):\n",
    "    add_entry = wf2[add_step]\n",
    "    if step > 0:\n",
    "        add_entry['parent']=incriment_parent(add_entry['parent'],last_)\n",
    "    \n",
    "    new_index = str(last_+step)\n",
    "    new_wf[new_index]=add_entry\n",
    "    print(add_entry)\n",
    "\n",
    "# new_wf\n",
    "\n",
    "new_wf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## WORKFLOWS\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "\n",
    "##  MASKS, NUCLEI, CELLMASK, CYTOSOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_masks_fromaggr_MCZ():\n",
    "    \"\"\"\n",
    "    crete .json version workflow for gettnig masks (using cellmask from MCZ)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 3,\n",
    "                                gauss_sig = 5.,\n",
    "                                thresh_factor = 0.8,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 35,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "                                \n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"raw_cellmask_fromaggr\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(scale_min_max=True))\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=3.4 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.8))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 45, \n",
    "                                  min_size = 25,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"stack_masks\")\n",
    "    category.append(\"export\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([nuc_step, cellmask_step, cyto_step])\n",
    "    annotation.append(f\"export  canonical masks (nuc,cellmask, cyto) {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i])\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.1.masks_MCZ.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_masks_MCZ_dict = make_infer_masks_fromaggr_MCZ()\n",
    "\n",
    "\n",
    "write_workflow_json(\"conf_0.1.masks_MCZ\", infer_masks_MCZ_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import NUC_CH\n",
    "\n",
    "def make_infer_mask_fromaggr_step_by_step_dict():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_cellmask_fromaggr\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "    step_n = 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"make_aggregate\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(w0=0,\n",
    "                                    w1=6,\n",
    "                                    w2=0,\n",
    "                                    w3=2,\n",
    "                                    w4=0,\n",
    "                                    w5=1,\n",
    "                                    w6=0,\n",
    "                                    w7=0,\n",
    "                                    w8=0,\n",
    "                                    w9=0,\n",
    "                                    scale_min_max = True) \n",
    "                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                   \n",
    "\n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    cyto_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"stack_masks\")\n",
    "    category.append(\"export\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([nuc_step, cellmask_step, cyto_step])\n",
    "    annotation.append(f\"export  canonical masks (nuc,cellmask, cyto) {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.1.masks.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_cellmask_fromaggr_stepbystep_dict = make_infer_mask_fromaggr_step_by_step_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.1.masks\", infer_cellmask_fromaggr_stepbystep_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LYSOSOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import LYSO_CH\n",
    "def make_infer_lyso_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lysosome from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LYSO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 5,\n",
    "                                dot_cut_1 = 0.09,\n",
    "                                dot_scale_2 = 2.5,\n",
    "                                dot_cut_2 = 0.07,\n",
    "                                dot_scale_3 = 1,\n",
    "                                dot_cut_3 = 0.01))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.15))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic lyso - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic lyso - combine spot+filament: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.2.lyso.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_lyso_stepbystep_from_raw_dict = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.2.lyso\", infer_lyso_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## MITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import MITO_CH \n",
    "\n",
    "def make_infer_mito_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = MITO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"vesselness_slice_by_slice\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( dict( sigma=1.5, cutoff=0.05))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - vesselness filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.3.mito.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_mito_stepbystep_from_raw_dict = make_infer_mito_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.3.mito\", infer_mito_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## GOLGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import GOLGI_CH\n",
    "def make_infer_golgi_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = GOLGI_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(th_method= \"triangle\", \n",
    "                                                            cutoff_size=1200,\n",
    "                                                            th_adjust = 0.5) )\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - mo: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"topology_preserving_thinning\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(    \n",
    "                                                min_thickness = 1.6,\n",
    "                                                thin = 1) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi - thinning filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.6,\n",
    "                                dot_cut_1 = 0.02,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic golgi - combine spot+thinned: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.4.golgi.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_golgi_stepbystep_from_raw_dict = make_infer_golgi_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.4.golgi\", infer_golgi_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## PEROXISOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import PEROX_CH\n",
    "\n",
    "\n",
    "def make_infer_perox_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = PEROX_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.0,\n",
    "                                dot_cut_1 = 0.01,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - spot filter (1 scale): {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.5.perox.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_perox_stepbystep_from_raw_dict = make_infer_perox_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.5.perox\", infer_perox_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## ER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import ER_CH\n",
    "def make_infer_er_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = ER_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.015))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.6.ER.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_er_stepbystep_from_raw_dict = make_infer_er_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.6.ER\", infer_er_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import LD_CH\n",
    "\n",
    "def make_infer_LD_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lipid from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    LD_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LD_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=2.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(method = \"otsu\",\n",
    "                                                        thresh_factor = 0.8, \n",
    "                                                            thresh_min = .5,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 2.5, \n",
    "                                  min_size = 4,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_0.7.LD.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_LD_stepbystep_from_raw_dict = make_infer_LD_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.7.LD\", infer_LD_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPRICATED FOR \"MASKS\".json\n",
    "-----------------\n",
    "## NUCLEI workflow\n",
    "\n",
    "Write the `infer_nuclei_fromlabel` spec to the widget json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import NUC_CH\n",
    "\n",
    "\n",
    "def make_infer_nuclei_dict():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=3.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc-2D/infer_subc_2d/organelles_config/conf_1.1.nuclei.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "infer_nuclei_dict = make_infer_nuclei_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.1.nuclei\", infer_nuclei_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## CYTOPLASM .json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_cytoplasm_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer cyto from linearly unmixed input. (logical cellmask AND NOT nucleus)\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cellmask_fromaggr_MCZ\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(\n",
    "                                                    median_sz = 15,\n",
    "                                            gauss_sig = 1.34,\n",
    "                                            mo_method = \"ave_tri_med\",\n",
    "                                            mo_adjust = 0.5,\n",
    "                                            mo_cutoff_size = 150,\n",
    "                                            max_hole_w = 50,\n",
    "                                            small_obj_w = 45\n",
    "                                            ))\n",
    "    parent.append([raw_input_step, nuc_step])\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_cytoplasm_dict = make_infer_cytoplasm_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.3.cytoplasm\", infer_cytoplasm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
