{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer SOMA -  2Ô∏è‚É£\n",
    " üöß WIP üöß (üö®üö®üö®üö® Steps 3-9 depend on establishing a good solution here.)\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: ‚úÖ Infer sub-cellular component SOMA in order to understand interactome \n",
    "\n",
    ">> WARNING:  THIS IS NOT WORKING\n",
    "\n",
    ">> Currently it just returns the entire image as SOMA.\n",
    "\n",
    "To measure shape, position, and size of the cell body -- the soma.    There are a variety of signals from which we could make this inference.  The two most promising are a composite signal including the residual from linear unmixing (e.g. `ch = [1, 4, 5,7]`) and a signal derived from the lysosome channel (`ch = 1`).    In all procdures scaling the intensities to find the lower florescence signals at the edge of the soma against baseline is employed.  \n",
    "\n",
    "In the long term we can build of a database of \"ground truth\" by sourcing additional markers which can be iteratively improved.  For example using the Allen Cell \"Label Free\" segmentation results should provide a good corroboration or constraints to the procedures outlined below.  \n",
    "\n",
    "Three possible _workflows_ are illustrated below.\n",
    "\n",
    "Dependencies:\n",
    "The CYTOSOL inference rely on the NUCLEI AND SOMA inference.  Therefore all of the sub-cellular objects rely on this segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_input_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles.nuclei import infer_NUCLEI\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING  OBJECTIVE :  infer SOMA\n",
    " \n",
    "> #### Note:  we are using the Nuclei of the brightest cell to aid in inferring the Soma and Cytosol objects.   Because we do NOT have a direct cell membrane / soma signal this is the trickiest and potentially problematic part of the overall sub-cellular component inference.   The Soma (via the Cytosol mask) will be used to define ALL subsequent sub-cellular Objects.\n",
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default parameters, including  \"optimal\" Z\n",
    "\n",
    "takes ~ 4 seconds to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_Z_from_params = False\n",
    "\n",
    "\n",
    "if load_Z_from_params:\n",
    "\n",
    "    default_params = load_parameters( test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "\n",
    "    ch_to_agg = default_params[\"ch_to_agg\"]\n",
    "    nuc_ch = default_params['nuc_ch']\n",
    "    optimal_Z = default_params[\"optimal_Z\"] #find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "else:\n",
    "    ch_to_agg = (1,2,3,4,5,6)\n",
    "    nuc_ch = 0\n",
    "    optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "\n",
    "    default_params = defaultdict(str, **{\n",
    "        #\"intensity_norm_param\" : [0.5, 15]\n",
    "        \"intensity_norm_param\" : [0],\n",
    "        \"gaussian_smoothing_sigma\" : 1.34,\n",
    "        \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "        \"dot_2d_sigma\" : 2,\n",
    "        \"dot_2d_sigma_extra\" : 1,\n",
    "        \"dot_2d_cutoff\" : 0.025,\n",
    "        \"min_area\" : 10,\n",
    "        \"low_level_min_size\" :  100,\n",
    "        \"median_filter_size\" : 4,\n",
    "        \"ch_to_agg\" : (1,2,3,4,5,6), # exclude residual\n",
    "        \"nuc_ch\" : 0,\n",
    "        \"optimal_Z\": optimal_Z,\n",
    "    })\n",
    "    save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "# make sure we have removed Z\n",
    "if len(scale)>2:\n",
    "    scale = scale[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred nuclei object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "\n",
    "raw_nuclei = img_2D[0].copy()\n",
    "NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING PROTOTYPE, Objective 2:  infer SOMA\n",
    "\n",
    ">WORKFLOW #1  - modified MCZ 3/20\n",
    "\n",
    "Segmentation on a 3 channel composite as per 3/20 pipeline from MCZ\n",
    "Summary - Starting with a linear combination of three signals,  the signal is smoothed and non-linearly combined (logrithmic and edge detected) for thresholding. \n",
    "## summary of steps\n",
    "\n",
    "‚û°Ô∏è INPUT\n",
    "- multi-channel sum (4*1,5,7)\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "- ne-noise and somoothe\n",
    "- log transform inensities\n",
    "- scale to max 1.0\n",
    "- create non-linear aggregate of log-intensity + scharr filtered \n",
    "\n",
    "CORE PROCESSING\n",
    "- mask object segmentation at bottom\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT ‚û°Ô∏è \n",
    "- mask of SOMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.07987165184837318, 0.07987165184837318), (1, 768, 768))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale, NU_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_2D[1].copy() + \n",
    "                               1. * img_2D[5].copy() + \n",
    "                               1. * img_2D[7].copy() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "#\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "med_filter_size = 15  \n",
    "\n",
    "# Linear-ish smoothing\n",
    "# raw_soma_linear = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "raw_soma_linear = simple_intensity_normalization(struct_img_raw.copy())\n",
    "\n",
    "\n",
    "# # this is SLOOOOOW.... 19 seconds!!!!\n",
    "# struct_img1 = ndi.median_filter(raw_soma_linear, size=med_filter_size)\n",
    "\n",
    "# hack it to speed up 10X\n",
    "struct_img = ndi.median_filter(raw_soma_linear.squeeze(), size=med_filter_size)[np.newaxis,:,:]\n",
    "\n",
    "\n",
    "\n",
    "structure_img_smooth = ndi.gaussian_filter( struct_img,\n",
    "                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                mode=\"nearest\", \n",
    "                                                                                truncate=gaussian_smoothing_truncate_range,\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "# NON-Linear aggregation\n",
    "log_image, d = log_transform( structure_img_smooth ) \n",
    "log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "edges = filters.scharr(log_image)\n",
    "\n",
    "composite_soma = intensity_normalization(  edges,  scaling_param=[0] ) + log_image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "low_level_min_size =  100\n",
    "\n",
    "\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# 2D \n",
    "hole_width = 80\n",
    "removed_holes = remove_small_holes(bw, hole_width ** 2 )\n",
    "\n",
    "small_object_max = 45\n",
    "cleaned_img = size_filter_2D(removed_holes, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "\n",
    "# limit the labeling to where we have soma or NUclear signal\n",
    "# watershed_mask = np.logical_or(cleaned_img, NU_labels > 0)\n",
    "watershed_mask = cleaned_img \n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "labels_out = watershed(\n",
    "            connectivity=np.ones((1, 3,3), bool),\n",
    "            image=inverted_img,\n",
    "            markers=NU_label,\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 768, 768), (1, 768, 768))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_out.shape, NU_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST- POST_PROCESSING\n",
    "###################\n",
    "# keep the \"SOMA\" label which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ raw_soma_linear[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "keep_label\n",
    "\n",
    "soma_out = np.zeros_like(labels_out)\n",
    "soma_out[labels_out==keep_label] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'soma_out' at 0x18954a940>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    soma_out,\n",
    "    scale=scale \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_infer_SOMA` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer soma.  \n",
    "\n",
    "> NOTE:  although it takes the parameters as input, they are all \"hard coded\" below, and the function returns the parameters in the same `defaultdict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 2. infer_SOMA\n",
    "##########################\n",
    "def _infer_SOMA(struct_img: np.ndarray, NU_labels: np.ndarray,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "\n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    # Linear-ish processing\n",
    "    med_filter_size = 15   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = ndi.median_filter(struct_img.squeeze(), size=med_filter_size)[np.newaxis,:,:]\n",
    "\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "    struct_img = ndi.gaussian_filter( struct_img,\n",
    "                                                                                sigma=gaussian_smoothing_sigma,\n",
    "                                                                                mode=\"nearest\", \n",
    "                                                                                truncate=gaussian_smoothing_truncate_range,\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    # non-Linear processing\n",
    "    log_img, d = log_transform( struct_img ) \n",
    "    log_img = intensity_normalization(  log_img,  scaling_param=[0] )\n",
    "\n",
    "    struct_img = intensity_normalization(  filters.scharr(log_img),  scaling_param=[0] )  + log_img\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 100\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # 2D \n",
    "    hole_max = 80  \n",
    "    # struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = remove_small_holes(struct_obj, hole_max ** 2 )\n",
    "\n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = size_filter_2D(struct_obj, \n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                connectivity=np.ones((1, 3,3), bool),\n",
    "                image=1. - struct_img,\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels > 0), #struct_obj\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "                # 2D \n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    soma_out = np.zeros_like(struct_obj)\n",
    "    soma_out[labels_out==keep_label] = 1\n",
    "\n",
    "    retval = (struct_obj,  soma_out , out_p)\n",
    "    return retval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# TEST `_infer_SOMA`  function defined above\n",
    "\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# SOMA INPUT\n",
    "###################\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "raw_soma = (4. * img_2D[1].copy() + \n",
    "                               1. * img_2D[5].copy() + \n",
    "                               1. * img_2D[7].copy() )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 768, 768), 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NU_label.shape, optimal_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SO_object, SO_label, out_p =  _infer_SOMA(raw_soma.copy(), NU_label, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'SO_object' at 0x17c179f10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.view_image(\n",
    "    raw_nuclei,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_image(\n",
    "    NU_object,\n",
    "    scale=scale,\n",
    "    colormap='blue', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.dims.ndisplay = 2\n",
    "viewer.camera.angles = (-30, 25, 120)\n",
    "\n",
    "viewer.add_image(\n",
    "    raw_soma,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    SO_object,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# TEST `infer_SOMA` exported functions\n",
    "\n",
    "\n",
    "##\n",
    "`infer_SOMA` procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SO_object, SO_label, out_p =  _infer_SOMA(raw_soma.copy(), NU_label, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles.soma import infer_SOMA\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA(struct_img.copy(), NU_label, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/data/intermediate/ZSTACK_PBTOhNGN2hiPSCs_BR3_N14_Unmixed.czi_params.pkl'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save updated parameters for ongoing testing\n",
    "save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
