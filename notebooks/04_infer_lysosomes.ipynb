{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer LYSOSOME - part 4\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE:  Infer sub-cellular component #2: LYSOSOMES  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The LYSOSOMES  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be organzied to explain the imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "# function for core algorithm\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, hole_filling\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters, img_as_float\n",
    "from skimage import morphology\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "# # package for io \n",
    "# from aicsimageio import AICSImage\n",
    "\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#import .infer_subc.base\n",
    "from infer_subc.base import *\n",
    "\n",
    "viewer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 4:  infer LYSOSOMES\n",
    "> Back to  [OUTLINE: Objective #4](#summary-of-objectives)\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel  2\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-   median filter, 2 pix window\n",
    "- gaussian  Filter window 10\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - get \"BIG\"\n",
    "  - enhance speckles \n",
    "    - > Speckles: A speckle is an area of enhanced intensity relative to its immediate neighborhood. The module enhances speckles using a white tophat filter, which is the image minus the morphological grayscale opening of the image. The opening operation first suppresses the speckles by applying a grayscale erosion to reduce everything within a given radius to the lowest value within that radius, then uses a grayscale dilation to restore objects larger than the radius to an approximation of their former shape. The white tophat filter enhances speckles by subtracting the effects of opening from the original image. \n",
    "    - feature size: 40 pix\n",
    "    - speed/accurace: slow\n",
    "  - identify primary objects \"BIG\"\n",
    "  - adaptive Otsu\n",
    "    - diameter: (10,100)\n",
    "    - three classes\n",
    "      - middle intensity is foreground\n",
    "      - threshold smoothing scale: 1.34\n",
    "      - threshold correction factor: .7\n",
    "      - threshold bounds: (0.08197, 1)\n",
    "      - adaptive window: 20 pixels\n",
    "- get \"SMALL\"\n",
    "  - enhance speckles \n",
    "    - feature size: 10 pix\n",
    "    - speed/accurace: slow\n",
    "- identify primary objects \"BIG\"\n",
    "  - adaptive Otsu\n",
    "    - diameter: (2,50)\n",
    "  - three classes\n",
    "    - middle intensity is foreground\n",
    "    - threshold smoothing scale: 1.34\n",
    "    - threshold correction factor: .75\n",
    "    - threshold bounds: (0.06, 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - embedded in CORE\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- object LYSOSOME \n",
    "\n",
    "\n",
    "NOTE:  using Allen Cell Segmenter LAMP1 [workflow](https://www.allencell.org/cell-observations/category/lamp1) might e a good place to start.  [Notebook](/Users/ahenrie/Projects/Imaging/mcz_subcell/napari/aics-segmentation/lookup_table_demo/playground_lamp1.ipynb) and [script](/Users/ahenrie/Projects/Imaging/mcz_subcell/napari/aics-segmentation/aicssegmentation/structure_wrapper/seg_lamp1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "##  set up files\n",
    "\n",
    "data_path = Path( f\"{os.getenv('HOME')}/Projects/Imaging/mcz_subcell/data\")\n",
    "czi_img_folder = data_path/\"raw\"\n",
    "\n",
    "list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "\n",
    "img_file_list = list_img_files(czi_img_folder,'.czi')\n",
    "print(img_file_list[5])\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "img_data, meta_dict = read_input_image(test_img_name)\n",
    "\n",
    "raw_meta_data, ome_types = get_raw_meta_data(meta_dict)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'CY_object'\n",
    "\n",
    "CY_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median filtering scale is ~ : [0.5804527163320905, 0.3194866073934927, 0.3194866073934927]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median filtering scale is ~ : [0.5804527163320905, 0.3194866073934927, 0.3194866073934927]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[1,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_lysosomes = intensity_normalization( struct_img_raw ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                raw_lysosomes,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# dot and filiment enhancement - 2D\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s2_param = [[5,0.09], [2.5,0.07], [1,0.01]]\n",
    "################################\n",
    "bw_spot = dot_2d_slice_by_slice_wrapper(struct_img, s2_param)\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "bw_filament = filament_2d_wrapper(struct_img, f2_param)\n",
    "\n",
    "\n",
    "bw = np.logical_or(bw_spot, bw_filament)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "fill_2d = True\n",
    "fill_max_size = 1600\n",
    "minArea = 15\n",
    "################################\n",
    "\n",
    "removed_holes = hole_filling(bw, 0, fill_max_size, fill_2d)\n",
    "\n",
    "# 3D\n",
    "cleaned_img = remove_small_objects(removed_holes>0, \n",
    "                                                            min_size=minArea, \n",
    "                                                            connectivity=1, \n",
    "                                                            in_place=False)\n",
    "width = 45  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"3D\" ,\n",
    "                                                         connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'structure_img_smooth [2]' at 0x175690af0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `infer_LYSOSOMES` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_LYSOSOMES\n",
    "##########################\n",
    "def infer_LYSOSOMES(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    log_img, d = log_transform( struct_img ) \n",
    "    struct_img = intensity_normalization(  log_img + filters.scharr(log_img) ,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 2D cleaning\n",
    "    hole_max = 100  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 30\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),  #either log_img or struct_img seem to work, but more spurious labeling to fix in post-post for struct_img\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    # 2D cleaning\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=np.abs(ndi.sobel(struct_img)),  #either log_img or struct_img seem to work, but more spurious labeling to fix in post-post for struct_img\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #2\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    "\n",
    "\n",
    "PRE-PROCESSING\n",
    "-   median filter, 2 pix window\n",
    "- gaussian  Filter window 10\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - get \"BIG\"\n",
    "  - enhance speckles \n",
    "    - > Speckles: A speckle is an area of enhanced intensity relative to its immediate neighborhood. The module enhances speckles using a white tophat filter, which is the image minus the morphological grayscale opening of the image. The opening operation first suppresses the speckles by applying a grayscale erosion to reduce everything within a given radius to the lowest value within that radius, then uses a grayscale dilation to restore objects larger than the radius to an approximation of their former shape. The white tophat filter enhances speckles by subtracting the effects of opening from the original image. \n",
    "    - feature size: 40 pix\n",
    "    - speed/accurace: slow\n",
    "  - identify primary objects \"BIG\"\n",
    "  - adaptive Otsu\n",
    "    - diameter: (10,100)\n",
    "    - three classes\n",
    "      - middle intensity is foreground\n",
    "      - threshold smoothing scale: 1.34\n",
    "      - threshold correction factor: .7\n",
    "      - threshold bounds: (0.08197, 1)\n",
    "      - adaptive window: 20 pixels\n",
    "- get \"SMALL\"\n",
    "  - enhance speckles \n",
    "    - feature size: 10 pix\n",
    "    - speed/accurace: slow\n",
    "- identify primary objects \"BIG\"\n",
    "  - adaptive Otsu\n",
    "    - diameter: (2,50)\n",
    "  - three classes\n",
    "    - middle intensity is foreground\n",
    "    - threshold smoothing scale: 1.34\n",
    "    - threshold correction factor: .75\n",
    "    - threshold bounds: (0.06, 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - embedded in CORE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = img_data[1,:,:,:].copy()\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "intensity_norm_param = [3.5, 15] # from Allen Cell Segmenter LAMP1  workflow\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "med_filter_size =2  \n",
    "\n",
    "gaussian_smoothing_sigma = 10\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(struct_img_raw) #  [0., 23]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_lysosomes = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                raw_lysosomes,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# enhance speckles\n",
    "\n",
    "\n",
    "    def enhance_speckles(self, image, radius, accuracy):\n",
    "        data = self.__mask(image.pixel_data, image.mask)\n",
    "\n",
    "        selem = self.__structuring_element(radius, image.volumetric)\n",
    "\n",
    "        if accuracy == \"Slow\" or radius <= 3:\n",
    "            result = skimage.morphology.white_tophat(data, selem=selem)\n",
    "        else:\n",
    "            #\n",
    "            # white_tophat = img - opening\n",
    "            #              = img - dilate(erode)\n",
    "            #              = img - maximum_filter(minimum_filter)\n",
    "            minimum = scipy.ndimage.filters.minimum_filter(data, footprint=selem)\n",
    "\n",
    "            maximum = scipy.ndimage.filters.maximum_filter(minimum, footprint=selem)\n",
    "\n",
    "            result = data - maximum\n",
    "\n",
    "        return self.__unmask(result, image.pixel_data, image.mask)\n",
    "\n",
    "        \n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s2_param = [[5,0.09], [2.5,0.07], [1,0.01]]\n",
    "################################\n",
    "bw_spot = dot_2d_slice_by_slice_wrapper(struct_img, s2_param)\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "bw_filament = filament_2d_wrapper(struct_img, f2_param)\n",
    "\n",
    "\n",
    "bw = np.logical_or(bw_spot, bw_filament)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "fill_2d = True\n",
    "fill_max_size = 1600\n",
    "minArea = 15\n",
    "################################\n",
    "\n",
    "removed_holes = hole_filling(bw, 0, fill_max_size, fill_2d)\n",
    "\n",
    "# 3D\n",
    "cleaned_img = remove_small_objects(removed_holes>0, \n",
    "                                                            min_size=minArea, \n",
    "                                                            connectivity=1, \n",
    "                                                            in_place=False)\n",
    "width = 45  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"3D\" ,\n",
    "                                                         connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'structure_img_smooth [2]' at 0x175690af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_LYSOSOME_CP` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy this to base.py for easy import\n",
    "# mangle so we can call from base.py\n",
    "def infer_LYSOSOME_CP(struct_img: np.ndarray, NU_labels: np.ndarray,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer LYSOSOMES from linearly unmixed input as per CellProfiler procedure\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.25\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    # 3D cleaning\n",
    "    struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=np.abs(ndi.sobel(struct_img)),\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "\n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test `infer_LYSOSOMES` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_object, meta_dict_t = read_input_image( out_path/ f\"{object_name}.ome.tiff\" )\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "#struct_img = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_LYSOSOMES(raw_soma_linear.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object2'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "# test: does this export work?\n",
    "object_name = 'SO_label2'\n",
    "SO_label_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_soma_linear,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    SO_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n",
    "viewer2.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
