{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUTATIVE WORKFLOW\n",
    "\n",
    "\n",
    "## WORKFLOW EDITOR PLUGIN\n",
    "- FINE-TUNE SEGMENTATIONS\n",
    "  - export workflow.jsons\n",
    "    - masks:\n",
    "      - nuclei\n",
    "      - cellmask\n",
    "      - cytoplasm\n",
    "    - organelles:\n",
    "      - lyso\n",
    "      - mito\n",
    "      - golgi\n",
    "      - perox\n",
    "      - ER\n",
    "      - LD\n",
    "\n",
    "\n",
    "## BATCHPROCESS WORKFLOW\n",
    "- BATCH PROCESS\n",
    "  - load workflow.jsons for: \n",
    "  1. masks\n",
    "    - export: masks .tiff as stack (nuclei, cellmask, cytoplasm)\n",
    "  2. organelles\n",
    "    - export individual .tiffs\n",
    "\n",
    "\n",
    "\n",
    "## NOTEBOOK OR ***FUTURE*** PLUGIN\n",
    "- COLLECT ORGANELLE STATS\n",
    "  - extract masks.tiffs as individual\n",
    "    - nuclei, cellmask, cytoplasm\n",
    "  - collect regionprops for all organelles\n",
    "    - export .csvs\n",
    "\n",
    "\n",
    "## NOTEBOOK OR __FUTURE__ PLUGIN\n",
    "- SUMMARIZE STUDY DATA\n",
    "  - munge .csv to create summary stats across all cells/images\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer_subc_2d.constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## EXTRACT mask stack\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "\n",
    "## TO DO\n",
    "- add \"segmentation name\" field instead of copying from workflow.json name\n",
    "\n",
    "\n",
    "- choose alternate conf_XXX.json location. \n",
    "  - strategy:  add to \"prebuilt\" list from path\n",
    "\n",
    "\n",
    "  \n",
    "  ## FILE NAME CONVENTIONS\n",
    "\n",
    "  raw file name is kept.\n",
    "\n",
    "  PREFIX = \"segmentation name\" or regionprop name.  e.g. \n",
    "  SUFFIX = \"description\" i.e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.core.file_io import (read_czi_image,\n",
    "                                                                    export_inferred_organelle,\n",
    "                                                                    import_inferred_organelle,\n",
    "                                                                    export_tiff,\n",
    "                                                                    list_image_files)\n",
    "\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example image for testing the pipeline below\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "int_data_path = data_root_path / \"intermediate\"\n",
    "im_type = \".tiff\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(int_data_path,im_type)\n",
    "\n",
    "# save output \".tiff\" files here\n",
    "out_data_path = data_root_path / \"out\"\n",
    "\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/data/intermediate/masks_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N23_Unmixed.tiff')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_path = Path(img_file_list[0])\n",
    "im_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"list\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m full_name \u001b[39m=\u001b[39m im_path\u001b[39m.\u001b[39mname\n\u001b[0;32m----> 3\u001b[0m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(im_path\u001b[39m.\u001b[39;49mparts[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m+\u001b[39;49m[full_name])\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"list\") to tuple"
     ]
    }
   ],
   "source": [
    "full_name = im_path.name\n",
    "\n",
    "\"/\".join(im_path.parts[:-1]+[full_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('masks', '_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N23_Unmixed.tiff')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = full_name.split(\"_\")[0]\n",
    "stem = full_name.lstrip(prefix)\n",
    "prefix, stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_type = full_name.split(\"_\")[0]\n",
    "\n",
    "\n",
    "if seg_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK process\n",
    "# 1. get a listof all files based on a \"prefix\" and \"suffix\" for a given path\n",
    "# dump three .tiff from teh mask multichannel tiff\n",
    "def explode_masks(root_path: Union[Path,str], prefix: str= \"masks\", postfix: str = \".tiff\"):\n",
    "    \"\"\"  \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "    from tifffile import imwrite, imread#, tiffcomment\n",
    "\n",
    "    if isinstance(root_path, str): root_path = Path(root_path)\n",
    "    img_file_list = list_image_files(root_path,im_type, prefix)\n",
    "    wrote_cnt = 0\n",
    "    for img_f in img_file_list:\n",
    "        # load image \n",
    "        full_name = Path(img_f).name\n",
    "        if full_name.startswith(prefix):\n",
    "            _prefix = full_name.split(\"_\")[0]\n",
    "            if _prefix != prefix:\n",
    "                print(f\"prefix has underscore!!- {prefix}\")\n",
    "            stem = full_name.lstrip(prefix)\n",
    "            \n",
    "            image = imread(img_f)\n",
    "            assert image.shape[0]==3\n",
    "            nuclei = image[0]\n",
    "            cellmask = image[1]\n",
    "            cytosol = image[2]\n",
    "\n",
    "            # write wasks\n",
    "            root = img_f.rstrip(full_name)\n",
    "            ret1 = imwrite(f\"{root}nuclei{stem}\", nuclei)\n",
    "            ret2 = imwrite(f\"{root}cellmask{stem}\", cellmask)\n",
    "            ret3 = imwrite(f\"{root}cytosol{stem}\", cytosol)\n",
    "            print(f\"wrote {{nuclei,cellmask,cytosol}}{stem}\")\n",
    "            wrote_cnt += 1\n",
    "        else:\n",
    "            print(f\"how thefark!!! {img_f}\")\n",
    "\n",
    "    return wrote_cnt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N23_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N03_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N04_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR3_N14_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N08_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR3_N01_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N15_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N05_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N02_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N10_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N22_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N14_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N09_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N16_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N11_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N19_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR1_N21_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N08_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N18_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N10_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR1_N16_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N02_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N05_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N09_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N15_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N12_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N07_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR2_N02_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N01_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N06_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N13_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR3_N14_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR3_N08_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N07_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N20_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N16_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N21_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N06_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR2_N01_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR3_N11_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_MCZtest_ZSTACK_PBTOhNGN2hiPSCs_BR1_N17_Unmixed.tiff\n",
      "wrote {nuclei,cellmask,cytosol}_ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.tiff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = explode_masks(int_data_path)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for a list of \"prefixes\"  collect stats + cross stats masked by cytosol (including nuclei masked by cellmask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stats(int_path: Union[Path,str], out_path: Union[Path, str], organelles: List[str]= [\"nuclei\",\"golgi\",\"peroxi\"], postfix: str = \".tiff\"):\n",
    "    \"\"\"  \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "    from tifffile import imwrite, imread#, tiffcomment\n",
    "\n",
    "    # load organelles and masks\n",
    "    \n",
    "    if isinstance(int_path, str): int_path = Path(int_path)\n",
    "    if isinstance(out_path, str): out_path = Path(out_path)\n",
    "    \n",
    "    img_file_list = list_image_files(int_path,postfix, \"cytosol\")\n",
    "\n",
    "    for img_f in img_file_list:\n",
    "        # load image \n",
    "        full_name = Path(img_f).name\n",
    "     \n",
    "        stem = full_name.lstrip(prefix)\n",
    "        root = img_f.rstrip(full_name)\n",
    "\n",
    "        # read cytosol    \n",
    "        cytosol = imread(img_f)\n",
    "        cellmask = imread(f\"{root}cellmask{stem}\") \n",
    "        \n",
    "        org_img = [ imread(f\"{root}{o}{stem}\") for o in organelles]\n",
    "\n",
    "        # dump_stats]\n",
    "        nucleus_table = dump_stats(\"nucleus\", nuclei_obj, img_data[NUC_CH], soma_obj, out_data_path, source_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "int_data_path = data_root_path / \"intermediate\"\n",
    "im_type = \".tiff\"\n",
    "# save output \".tiff\" files here\n",
    "out_data_path = data_root_path / \"out\"\n",
    "\n",
    "get_stats(int_data_path, out_data_path, organelles=[\"nuclei\", \"golgi\",\"perox\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organelles = [\"nuclei\",\"golgi\",\"peroxi\"]\n",
    "\n",
    "organelles.count(\"xxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
